
<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta charset="utf-8" />
    <title>Optimizing a NengoDL model &#8212; NengoDL 2.2.0 docs</title>
    <link rel="stylesheet" href="_static/basic.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
<link href="https://fonts.googleapis.com/css?family=IBM+Plex+Sans:400,400i,600|Rajdhani:700&display=swap" rel="stylesheet">
<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.8.2/css/all.css" integrity="sha384-oS3vJWv+0UjzBfQzYUhtDYW+Pj2yciDJxpsK1OYPAYjqT085Qq/1cq5FLXAZQ7Ay" crossorigin="anonymous">
<link rel="stylesheet" href="https://www.nengo.ai/css/bootstrap.css" type="text/css">
<style>
  body .title-bar,
  body .documentation-source h1:after {
    background-color: #ff6600;
  }
</style>

<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-GT8XEDLTMJ"></script>
<script>
 window.dataLayer = window.dataLayer || [];
 function gtag(){dataLayer.push(arguments);}
 gtag('js', new Date());
 gtag('config', 'G-GT8XEDLTMJ');
</script>
<!-- End Google tag (gtag.js) -->

<!-- Matomo -->
<script>
 var _paq = window._paq = window._paq || [];
 _paq.push(["setDocumentTitle", document.domain + "/" + document.title]);
 _paq.push(["setCookieDomain", "*.appliedbrainresearch.com"]);
 _paq.push(["setDomains", ["*.appliedbrainresearch.com","*.edge.nengo.ai","*.forum.nengo.ai","*.labs.nengo.ai","*.nengo.ai"]]);
 _paq.push(["enableCrossDomainLinking"]);
 _paq.push(["setDoNotTrack", true]);
 _paq.push(['trackPageView']);
 _paq.push(['enableLinkTracking']);
 (function() {
   var u="https://appliedbrainresearch.matomo.cloud/";
   _paq.push(['setTrackerUrl', u+'matomo.php']);
   _paq.push(['setSiteId', '3']);
   var d=document, g=d.createElement('script'), s=d.getElementsByTagName('script')[0];
   g.async=true; g.src='//cdn.matomo.cloud/appliedbrainresearch.matomo.cloud/matomo.js'; s.parentNode.insertBefore(g,s);
 })();
</script>
<!-- End Matomo Code -->
<script src="https://code.jquery.com/jquery-3.3.1.min.js" integrity="sha256-FgpCb/KJQlLNfOu91ta32o/NMZxltwRo8QtmkMRdAu8=" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.3/umd/popper.min.js" integrity="sha384-ZMP7rVo3mIykV+2+9J3UJ46jBk0WLaUAdn689aCwoqbBJiSnjAK/l8WvCWPIPm49" crossorigin="anonymous"></script>
<script src="https://unpkg.com/scrollreveal"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/stickyfill/2.1.0/stickyfill.min.js"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.1.1/js/bootstrap.min.js" integrity="sha384-smHYKdLADwkXOn1EmN1qk/HfnUcbVRZyYmZ4qpPea6sjB/pTJ0euyQp0Mk8ck+5T" crossorigin="anonymous"></script>
<!-- From basic/layout.html -->
<script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
  
  
<script type="text/javascript" src="_static/underscore.js"></script>
  
  
<script type="text/javascript" src="_static/doctools.js"></script>
  
  
<script type="text/javascript" src="_static/language_data.js"></script>
  
  
<script async="async" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
  
  
<script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true, "ignoreClass": "document", "processClass": "math|output_area"}})</script>
  
    <link rel="shortcut icon" href="_static/favicon.ico"/>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="TensorNodes" href="tensor-node.html" />
    <link rel="prev" title="NengoDL Simulator" href="simulator.html" />
<meta name="viewport" content="width=device-width, initial-scale=1, viewport-fit=cover">

  </head><body class="bg-dark">

<header class="fixed-top header-top shadow-sm">
  <nav class="navbar navbar-expand-md navbar-light bg-white">
    <a class="navbar-brand" href="https://www.nengo.ai">
      <img
        src="https://www.nengo.ai/design/_images/general-full-light.svg"
        alt="Nengo"
        class="logo"
      />
    </a>
    <button
      class="navbar-toggler"
      type="button"
      data-toggle="collapse"
      data-target="#navbar-collapse"
      aria-controls="navbar-collapse"
      aria-expanded="false"
      aria-label="Toggle navigation"
    >
      <span class="navbar-toggler-icon"></span>
    </button>
    <div class="collapse navbar-collapse" id="navbar-collapse">
      <ul class="navbar-nav ml-auto">
        <li class="nav-item">
          <a class="nav-link" href="https://www.nengo.ai">What is Nengo?</a>
        </li>
        <li class="nav-item dropdown active">
          <a
            class="nav-link dropdown-toggle"
            id="navbar-dropdown-docs"
            data-toggle="dropdown"
            aria-haspopup="true"
            aria-expanded="false"
            href="#"
            >Documentation</a
          >
          <div
            class="dropdown-menu shadow-lg border-0"
            aria-labelledby="navbar-dropdown-docs"
          >
            
            <a class="dropdown-item" href="https://www.nengo.ai/nengo/">Nengo Core</a>
            <a class="dropdown-item" href="https://github.com/nengo/nengo-gui/">Nengo GUI</a>
            <a class="dropdown-item" href="https://www.nengo.ai/nengo-dl/">Nengo DL</a>
            <div class="dropdown-divider"></div>
            <a class="dropdown-item" href="https://www.nengo.ai/nengo-spa/">Nengo SPA</a>
            <a class="dropdown-item" href="https://www.nengo.ai/nengo-extras/">Nengo Extras</a>
            <a class="dropdown-item" href="https://arvoelke.github.io/nengolib-docs/">Nengolib</a>
            <a class="dropdown-item" href="https://github.com/nengo/nengo-examples/">Nengo Examples</a>
            <div class="dropdown-divider"></div>
            <a class="dropdown-item" href="https://www.nengo.ai/nengo-fpga/">Nengo FPGA</a>
            <a class="dropdown-item" href="https://www.nengo.ai/nengo-loihi/">Nengo Loihi</a>
            <a class="dropdown-item" href="https://github.com/nengo/nengo-ocl">Nengo OpenCL</a>
            <a class="dropdown-item" href="https://github.com/project-rig/nengo_spinnaker">Nengo SpiNNaker</a>
            <a class="dropdown-item" href="https://github.com/nengo/nengo-mpi">Nengo MPI</a>
            <div class="dropdown-divider"></div>
            <a class="dropdown-item" href="https://www.nengo.ai/documentation"
              >All documentation</a
            >
          </div>
        </li>
        <li class="nav-item dropdown">
          <a
            class="nav-link dropdown-toggle"
            id="navbar-dropdown-community"
            data-toggle="dropdown"
            aria-haspopup="true"
            aria-expanded="false"
            href="#"
            >Community</a
          >
          <div
            class="dropdown-menu shadow-lg border-0"
            aria-labelledby="navbar-dropdown-community"
          >
            <a class="dropdown-item" href="https://forum.nengo.ai">Forum</a>
            <div class="dropdown-divider"></div>
            <a class="dropdown-item" href="https://www.nengo.ai/people"
              >People</a
            >
            <a class="dropdown-item" href="https://www.nengo.ai/summer-school"
              >Summer school</a
            >
            <a class="dropdown-item" href="https://www.nengo.ai/contributing"
              >Contributing</a
            >
            <a class="dropdown-item" href="https://www.nengo.ai/publications"
              >Publications</a
            >
            <a class="dropdown-item" href="https://www.nengo.ai/videos"
              >Videos</a
            >
            <a class="dropdown-item" href="https://www.nengo.ai/conduct"
              >Code of conduct</a
            >
            <a class="dropdown-item" href="https://www.nengo.ai/caa">CAA</a>
          </div>
        </li>
        <li class="nav-item">
          <a
            class="nav-link btn btn-success btn-sm text-white"
            href="https://www.nengo.ai/download"
            >Download</a
          >
        </li>
      </ul>
    </div>
  </nav>
</header>
<div class="main-content gradient-top">
  <div class="container-fluid">
    <div class="row"><a class="toggle-sidenav d-block d-md-none" href="#"
  ><i class="icon-close fa fa-fw fa-arrow-left"></i
  ><i class="icon-open fa fa-fw fa-arrow-right"></i
></a>
<div role="complementary" class="sidenav col-4 col-xl-3 p-0 border-right">
  <h3 class="pt-5 px-5">
    <a href="index.html">
      <img
        class="img-fluid documentation-image"
        src="https://www.nengo.ai/design/_images/nengo-dl-full-light.svg"
        alt="NengoDL"
      />
    </a>
  </h3>
  
  <form class="px-5 pb-5 mb-0 mt-3 border-bottom">
    <div class="form-group">
      <label class="text-gray">Version:</label>
      <select class="custom-select" onchange="switchVersion(this);">
        
        
        <option value="../training.html">latest</option>
        
        
          
        <option selected>v2.2.0</option>
          
        
          
        <option value="../v2.1.1/training.html">
          v2.1.1
        </option>
          
        
          
        <option value="../v2.1.0/training.html">
          v2.1.0
        </option>
          
        
          
        <option value="../v2.0.0/training.html">
          v2.0.0
        </option>
          
        
          
        <option value="../v1.2.1/training.html">
          v1.2.1
        </option>
          
        
          
        <option value="../v1.2.0/training.html">
          v1.2.0
        </option>
          
        
          
        <option value="../v1.1.0/training.html">
          v1.1.0
        </option>
          
        
          
        <option value="../v1.0.0/training.html">
          v1.0.0
        </option>
          
        
          
        <option value="../v0.6.2/training.html">
          v0.6.2
        </option>
          
        
          
        <option value="../v0.6.1/training.html">
          v0.6.1
        </option>
          
        
          
        <option value="../v0.6.0/training.html">
          v0.6.0
        </option>
          
        
          
        <option value="../v0.5.2/training.html">
          v0.5.2
        </option>
          
        
          
        <option value="../v0.5.1/training.html">
          v0.5.1
        </option>
          
        
          
        <option value="../v0.5.0/training.html">
          v0.5.0
        </option>
          
        
          
        <option value="../v0.4.0/training.html">
          v0.4.0
        </option>
          
        
          
        <option value="../v0.3.1/training.html">
          v0.3.1
        </option>
          
        
          
        <option value="../v0.3.0/training.html">
          v0.3.0
        </option>
          
        
          
        <option value="../v0.2.0/training.html">
          v0.2.0
        </option>
          
        
      </select>
    </div>
  </form>
  
  <div class="p-5 toctree">
    <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="introduction.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="installation.html">Installation</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="user-guide.html">User guide</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="simulator.html">NengoDL Simulator</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">Optimizing a NengoDL model</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#simulator-train-arguments">Simulator.train arguments</a></li>
<li class="toctree-l3"><a class="reference internal" href="#choosing-which-elements-to-optimize">Choosing which elements to optimize</a></li>
<li class="toctree-l3"><a class="reference internal" href="#saving-and-loading-parameters">Saving and loading parameters</a></li>
<li class="toctree-l3"><a class="reference internal" href="#examples">Examples</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="tensor-node.html">TensorNodes</a></li>
<li class="toctree-l2"><a class="reference internal" href="config.html">Configuration options</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="reference.html">API reference</a></li>
<li class="toctree-l1"><a class="reference internal" href="examples.html">Examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="resources.html">Additional resources</a></li>
<li class="toctree-l1"><a class="reference internal" href="project.html">Project information</a></li>
</ul>

  </div>
<form class="p-5 my-0 border-top" action="search.html" method="get">
  <div class="form-group form-group-single">
    <input type="text" name="q" class="form-control" placeholder="Search" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
    <button type="submit" class="btn btn-link">
      <img src="https://www.nengo.ai/img/icon-search.svg" alt="Go" />
    </button>
  </div>
</form></div>
      

      <div class="col-12 col-md-8 col-xl-9">
        <div class="container">
          <div class="row">
            <div class="col-10 offset-1 pb-5 documentation-source">
              
  <div class="section" id="optimizing-a-nengodl-model">
<h1>Optimizing a NengoDL model<a class="headerlink" href="#optimizing-a-nengodl-model" title="Permalink to this headline">¶</a></h1>
<p>Optimizing Nengo models via deep learning training methods is one of the
important features of NengoDL.  This functionality is accessed via the
<a class="reference internal" href="reference.html#nengo_dl.simulator.Simulator.train" title="nengo_dl.simulator.Simulator.train"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Simulator.train</span></code></a> method.  For example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">nengo</span><span class="o">.</span><span class="n">Network</span><span class="p">()</span> <span class="k">as</span> <span class="n">net</span><span class="p">:</span>
    <span class="o">&lt;</span><span class="n">construct</span> <span class="n">the</span> <span class="n">model</span><span class="o">&gt;</span>

<span class="k">with</span> <span class="n">nengo_dl</span><span class="o">.</span><span class="n">Simulator</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="o">...</span><span class="p">)</span> <span class="k">as</span> <span class="n">sim</span><span class="p">:</span>
    <span class="n">sim</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="o">&lt;</span><span class="n">data</span><span class="o">&gt;</span><span class="p">,</span> <span class="o">&lt;</span><span class="n">optimizer</span><span class="o">&gt;</span><span class="p">,</span> <span class="n">n_epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">objective</span><span class="o">=&lt;</span><span class="n">objective</span><span class="o">&gt;</span><span class="p">)</span>
</pre></div>
</div>
<p>When the <code class="docutils literal notranslate"><span class="pre">Simulator</span></code> is first constructed, all the parameters in the model
(e.g., encoders, decoders, connection weights, biases) are initialized based
on the functions/distributions specified during model construction (see the
<a class="reference external" href="https://www.nengo.ai/nengo/">Nengo documentation</a> for more detail on
how that works).  What the <a class="reference internal" href="reference.html#nengo_dl.simulator.Simulator.train" title="nengo_dl.simulator.Simulator.train"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Simulator.train</span></code></a> method does is then
further optimize those parameters based on some inputs and desired
outputs.  We’ll go through each of those components in more detail
below.</p>
<div class="section" id="simulator-train-arguments">
<h2>Simulator.train arguments<a class="headerlink" href="#simulator-train-arguments" title="Permalink to this headline">¶</a></h2>
<div class="section" id="data">
<h3>data<a class="headerlink" href="#data" title="Permalink to this headline">¶</a></h3>
<p>The first argument to the <a class="reference internal" href="reference.html#nengo_dl.simulator.Simulator.train" title="nengo_dl.simulator.Simulator.train"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Simulator.train</span></code></a> function is the training
data.  This generally consists of two components: input values for Nodes, and
target values for Probes.</p>
<p><strong>inputs</strong></p>
<p>We can think of a model as computing a function
<span class="math notranslate nohighlight">\(y = f(x, \theta)\)</span>, where <span class="math notranslate nohighlight">\(f\)</span> is the model, mapping inputs
<span class="math notranslate nohighlight">\(x\)</span> to outputs <span class="math notranslate nohighlight">\(y\)</span> with parameters <span class="math notranslate nohighlight">\(\theta\)</span>.  These values
are specifying the values for <span class="math notranslate nohighlight">\(x\)</span>.</p>
<p>In practice what that means is specifying values for the input Nodes in the
model.  A <a class="reference external" href="https://www.nengo.ai/nengo/frontend_api.html#nengo.Node" title="(in Nengo v3.0)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Node</span></code></a> is a Nengo object that inserts values into
a Network, usually used
to define external inputs.  <a class="reference internal" href="reference.html#nengo_dl.simulator.Simulator.train" title="nengo_dl.simulator.Simulator.train"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Simulator.train</span></code></a> will override the normal
Node values with the training data that is provided.  This is specified as a
dictionary <code class="docutils literal notranslate"><span class="pre">{&lt;node&gt;:</span> <span class="pre">&lt;array&gt;,</span> <span class="pre">...}</span></code>, where <code class="docutils literal notranslate"><span class="pre">&lt;node&gt;</span></code> is the input node
for which training data is being defined, and <code class="docutils literal notranslate"><span class="pre">&lt;array&gt;</span></code> is a numpy array
containing the training values.  This training array should have shape
<code class="docutils literal notranslate"><span class="pre">(n_inputs,</span> <span class="pre">n_steps,</span> <span class="pre">node.size_out)</span></code>, where <code class="docutils literal notranslate"><span class="pre">n_inputs</span></code> is the number of
training examples, <code class="docutils literal notranslate"><span class="pre">n_steps</span></code> is the number of simulation steps to train
across, and <code class="docutils literal notranslate"><span class="pre">node.size_out</span></code> is the dimensionality of the Node.</p>
<p>When training a NengoDL model the user must specify the <code class="docutils literal notranslate"><span class="pre">minibatch_size</span></code>
to use during training, via the <code class="docutils literal notranslate"><span class="pre">Simulator(...,</span> <span class="pre">minibatch_size=n</span></code>) argument.
This defines how many inputs (out of the total <code class="docutils literal notranslate"><span class="pre">n_inputs</span></code> defined above) will
be used for each optimization step.</p>
<p>Here is an example illustrating how to define the input values for two
input nodes:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">nengo</span><span class="o">.</span><span class="n">Network</span><span class="p">()</span> <span class="k">as</span> <span class="n">net</span><span class="p">:</span>
    <span class="n">a</span> <span class="o">=</span> <span class="n">nengo</span><span class="o">.</span><span class="n">Node</span><span class="p">([</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">b</span> <span class="o">=</span> <span class="n">nengo</span><span class="o">.</span><span class="n">Node</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
    <span class="o">...</span>

<span class="n">n_inputs</span> <span class="o">=</span> <span class="mi">1000</span>
<span class="n">minibatch_size</span> <span class="o">=</span> <span class="mi">20</span>
<span class="n">n_steps</span> <span class="o">=</span> <span class="mi">10</span>

<span class="k">with</span> <span class="n">nengo_dl</span><span class="o">.</span><span class="n">Simulator</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">minibatch_size</span><span class="o">=</span><span class="n">minibatch_size</span><span class="p">)</span> <span class="k">as</span> <span class="n">sim</span><span class="p">:</span>
    <span class="n">sim</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="p">{</span><span class="n">a</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">n_inputs</span><span class="p">,</span> <span class="n">n_steps</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
                    <span class="n">b</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">n_inputs</span><span class="p">,</span> <span class="n">n_steps</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span>
                    <span class="o">...</span><span class="p">},</span>
              <span class="o">...</span><span class="p">)</span>
</pre></div>
</div>
<p>Note that inputs can only be defined for Nodes with no incoming connections
(i.e., Nodes with <code class="docutils literal notranslate"><span class="pre">size_in</span> <span class="pre">==</span> <span class="pre">0</span></code>).  Any Nodes that don’t have data provided
will take on the values specified during model construction.</p>
<p><strong>targets</strong></p>
<p>Returning to the network equation <span class="math notranslate nohighlight">\(y = f(x, \theta)\)</span>, the goal in
optimization is usually to find a set of parameter values such that given
inputs <span class="math notranslate nohighlight">\(x\)</span> and target values <span class="math notranslate nohighlight">\(t\)</span>, an error value
<span class="math notranslate nohighlight">\(e = o(y, t)\)</span> is minimized.  These values are specifying those target
values <span class="math notranslate nohighlight">\(t\)</span>.</p>
<p>This works very similarly to defining inputs, except instead of assigning
input values to Nodes it assigns target values to Probes.  We add
<code class="docutils literal notranslate"><span class="pre">{&lt;probe&gt;:</span> <span class="pre">&lt;array&gt;,</span> <span class="pre">...}</span></code> entries to the <code class="docutils literal notranslate"><span class="pre">data</span></code> dictionary, where
<code class="docutils literal notranslate"><span class="pre">&lt;array&gt;</span></code> has shape <code class="docutils literal notranslate"><span class="pre">(n_inputs,</span> <span class="pre">n_steps,</span> <span class="pre">probe.size_in)</span></code>.  Those target
values will be passed to the objective function <span class="math notranslate nohighlight">\(g\)</span> for each timestep.</p>
<p>For example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">nengo</span><span class="o">.</span><span class="n">Network</span><span class="p">()</span> <span class="k">as</span> <span class="n">net</span><span class="p">:</span>
    <span class="o">...</span>
    <span class="n">ens</span> <span class="o">=</span> <span class="n">nengo</span><span class="o">.</span><span class="n">Ensemble</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
    <span class="n">p</span> <span class="o">=</span> <span class="n">nengo</span><span class="o">.</span><span class="n">Probe</span><span class="p">(</span><span class="n">ens</span><span class="p">)</span>

<span class="n">n_inputs</span> <span class="o">=</span> <span class="mi">1000</span>
<span class="n">minibatch_size</span> <span class="o">=</span> <span class="mi">20</span>
<span class="n">n_steps</span> <span class="o">=</span> <span class="mi">10</span>

<span class="k">with</span> <span class="n">nengo_dl</span><span class="o">.</span><span class="n">Simulator</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">minibatch_size</span><span class="o">=</span><span class="n">minibatch_size</span><span class="p">)</span> <span class="k">as</span> <span class="n">sim</span><span class="p">:</span>
    <span class="n">sim</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="p">{</span><span class="o">...</span><span class="p">,</span> <span class="n">p</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">n_inputs</span><span class="p">,</span> <span class="n">n_steps</span><span class="p">,</span> <span class="mi">2</span><span class="p">)},</span>
              <span class="o">...</span><span class="p">)</span>
</pre></div>
</div>
<p>Note that these examples use random inputs/targets, for the sake of simplicity.
In practice we would do something like <code class="docutils literal notranslate"><span class="pre">targets=my_func(inputs)</span></code>, where
<code class="docutils literal notranslate"><span class="pre">my_func</span></code> is a function specifying what the ideal outputs are for the given
inputs.</p>
</div>
<div class="section" id="optimizer">
<h3>optimizer<a class="headerlink" href="#optimizer" title="Permalink to this headline">¶</a></h3>
<p>The optimizer is the algorithm that defines how to update the
network parameters during training.  Any of the optimization methods
implemented in TensorFlow can be used in NengoDL; more information can be found
in the <a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/train">TensorFlow documentation</a>.</p>
<p>An instance of the desired TensorFlow optimizer is created (specifying any
arguments required by that optimizer), and that instance is then passed to
<a class="reference internal" href="reference.html#nengo_dl.simulator.Simulator.train" title="nengo_dl.simulator.Simulator.train"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Simulator.train</span></code></a>.  For example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="kn">as</span> <span class="nn">tf</span>

<span class="k">with</span> <span class="n">nengo_dl</span><span class="o">.</span><span class="n">Simulator</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="o">...</span><span class="p">)</span> <span class="k">as</span> <span class="n">sim</span><span class="p">:</span>
    <span class="n">sim</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">MomentumOptimizer</span><span class="p">(</span>
        <span class="n">learning_rate</span><span class="o">=</span><span class="mf">1e-2</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span> <span class="n">use_nesterov</span><span class="o">=</span><span class="bp">True</span><span class="p">),</span> <span class="o">...</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="objective">
<h3>objective<a class="headerlink" href="#objective" title="Permalink to this headline">¶</a></h3>
<p>As mentioned, the goal in optimization is to minimize some error value
<span class="math notranslate nohighlight">\(e = o(y, t)\)</span>.  The objective is the function <span class="math notranslate nohighlight">\(o\)</span> that computes an
error value <span class="math notranslate nohighlight">\(e\)</span>, given <span class="math notranslate nohighlight">\(y\)</span> and <span class="math notranslate nohighlight">\(t\)</span>.  This argument is
specified as a dictionary mapping Probes to objective functions, indicating how
the output of that probe is mapped to an error value.</p>
<p>The default objective in NengoDL is the standard <a class="reference external" href="https://en.wikipedia.org/wiki/Mean_squared_error">mean squared error</a>.  This will be used if
the user doesn’t specify an objective.</p>
<p>Users can specify a custom objective by creating a function that implements
the <span class="math notranslate nohighlight">\(o\)</span> function above.  Note that the
objective is defined using TensorFlow operators.  It should accept Tensors
representing outputs and targets as input (each with shape
<code class="docutils literal notranslate"><span class="pre">(minibatch_size,</span> <span class="pre">n_steps,</span> <span class="pre">probe.size_in)</span></code>) and return a scalar Tensor
representing the error. This example manually computes mean squared error,
rather than using the default:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="kn">as</span> <span class="nn">tf</span>

<span class="k">def</span> <span class="nf">my_objective</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">((</span><span class="n">targets</span> <span class="o">-</span> <span class="n">outputs</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span>

<span class="k">with</span> <span class="n">nengo_dl</span><span class="o">.</span><span class="n">Simulator</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="o">...</span><span class="p">)</span> <span class="k">as</span> <span class="n">sim</span><span class="p">:</span>
    <span class="n">sim</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">objective</span><span class="o">=</span><span class="p">{</span><span class="n">p</span><span class="p">:</span> <span class="n">my_objective</span><span class="p">},</span> <span class="o">...</span><span class="p">)</span>
</pre></div>
</div>
<p>Some objective functions may not require target values.  In this case the
function can be defined with one argument</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">my_objective</span><span class="p">(</span><span class="n">outputs</span><span class="p">):</span>
    <span class="o">...</span>
</pre></div>
</div>
<p>Finally, it is also possible to specify <code class="docutils literal notranslate"><span class="pre">None</span></code> as the objective.  This
indicates that the error is being computed outside the simulation by the
modeller.  In this case the modeller should directly specify the output error
gradient as the <code class="docutils literal notranslate"><span class="pre">targets</span></code> value.  For example, we could apply the same mean
squared error update this way:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">nengo_dl</span><span class="o">.</span><span class="n">Simulator</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="o">...</span><span class="p">)</span> <span class="k">as</span> <span class="n">sim</span><span class="p">:</span>
    <span class="n">sim</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
    <span class="n">error</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="p">(</span><span class="n">sim</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">p</span><span class="p">]</span> <span class="o">-</span> <span class="n">my_targets</span><span class="p">)</span>
    <span class="n">sim</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="p">{</span><span class="o">...</span><span class="p">,</span> <span class="n">p</span><span class="p">:</span> <span class="n">error</span><span class="p">},</span> <span class="n">objective</span><span class="o">=</span><span class="p">{</span><span class="n">p</span><span class="p">:</span> <span class="bp">None</span><span class="p">},</span> <span class="o">...</span><span class="p">)</span>
</pre></div>
</div>
<p>Note that it is possible to specify multiple objective functions like
<code class="docutils literal notranslate"><span class="pre">objective={p0:</span> <span class="pre">my_objective0,</span> <span class="pre">p1:</span> <span class="pre">my_objective1}</span></code>.  In this case the error
will be summed across the probe objectives to produce an overall error
value to be minimized.
It is also possible to create objective functions that depend on multiple
probe outputs, by specifying <code class="docutils literal notranslate"><span class="pre">objective={(p0,</span> <span class="pre">p1):</span> <span class="pre">my_objective}</span></code>.  In this
case, <code class="docutils literal notranslate"><span class="pre">my_objective</span></code> will still be passed parameters <code class="docutils literal notranslate"><span class="pre">outputs</span></code> and
<code class="docutils literal notranslate"><span class="pre">targets</span></code>, but those parameters will be lists containing the output/target
values for each of the specified probes.</p>
<p><a class="reference internal" href="reference.html#nengo_dl.simulator.Simulator.loss" title="nengo_dl.simulator.Simulator.loss"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Simulator.loss</span></code></a> can be used to check the loss
(error) value for a given objective.</p>
<p>See <a class="reference internal" href="reference.html#objective-api"><span class="std std-ref">Objectives</span></a> for some common objective functions that are
provided with NengoDL for convenience.</p>
</div>
<div class="section" id="truncation">
<span id="id1"></span><h3>truncation<a class="headerlink" href="#truncation" title="Permalink to this headline">¶</a></h3>
<p>When optimizing a simulation over time we specify inputs and targets for all
<span class="math notranslate nohighlight">\(n\)</span> steps of the simulation.  The gradients are computed by running
the simulation forward for <span class="math notranslate nohighlight">\(n\)</span> steps, comparing the outputs to the
targets we specified, and then propagating the gradients backwards from
<span class="math notranslate nohighlight">\(n\)</span> to 0.  This is known as <a class="reference external" href="https://en.wikipedia.org/wiki/Backpropagation_through_time">Backpropagation Through Time (BPTT)</a>.</p>
<p>However, in some cases we may not want to run BPTT over the full <span class="math notranslate nohighlight">\(n\)</span>
steps (usually because it requires a lot of memory to store all the
intermediate values for <span class="math notranslate nohighlight">\(n\)</span> steps of gradient calculation).  In this case
we choose some value <span class="math notranslate nohighlight">\(m &lt; n\)</span>, run the simulation for <span class="math notranslate nohighlight">\(m\)</span> steps,
backpropagate the gradients over those <span class="math notranslate nohighlight">\(m\)</span> steps, then run the simulation
for <span class="math notranslate nohighlight">\(m\)</span> more steps, and so on until we have run for the total <span class="math notranslate nohighlight">\(n\)</span>
steps.  This is known as Truncated BPTT.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">truncation</span></code> argument is used to specify <span class="math notranslate nohighlight">\(m\)</span>, i.e.
<code class="docutils literal notranslate"><span class="pre">sim.train(...,</span> <span class="pre">truncation=m)</span></code>.  If no value is given then full un-truncated
BPTT will be performed.</p>
<p>In general, truncated BPTT will result in worse performance than untruncated
BPTT.  Truncation limits the range of the temporal dynamics that the network
is able to learn.  For example, if we tried to learn a function where input
<span class="math notranslate nohighlight">\(x_t\)</span> should influence the output at <span class="math notranslate nohighlight">\(y_{t+m+1}\)</span> that would not
work well, because the errors from step <span class="math notranslate nohighlight">\(t+m+1\)</span> never make it back to
step <span class="math notranslate nohighlight">\(t\)</span>.  More generally, a truncated system has less information about
how outputs at <span class="math notranslate nohighlight">\(t\)</span> will affect future performance, which will limit how
well that system can be optimized.</p>
<p>As mentioned, the main reason to use truncated BPTT is in order to reduce the
memory demands during training.  So if you find yourself running out of memory
while training a model, consider using the <code class="docutils literal notranslate"><span class="pre">truncation</span></code> argument (while
ensuring that the value of <span class="math notranslate nohighlight">\(m\)</span> is still large enough to capture the
temporal dynamics in the task).</p>
</div>
<div class="section" id="summaries">
<span id="id2"></span><h3>summaries<a class="headerlink" href="#summaries" title="Permalink to this headline">¶</a></h3>
<p>It is often useful to view information about how aspects of a model are
changing over the course of training.  TensorFlow has created <a class="reference external" href="https://www.tensorflow.org/guide/summaries_and_tensorboard">TensorBoard</a> to
help visualize this kind of data, and the <code class="docutils literal notranslate"><span class="pre">summaries</span></code> argument can be used to
specify the model data that you would like to export for TensorBoard.</p>
<p>It is specified as a list of objects for which we want to collect
data.  The data collected depends on the object: if it is a
<a class="reference external" href="https://www.nengo.ai/nengo/frontend_api.html#nengo.Connection" title="(in Nengo v3.0)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Connection</span></code></a> then data will be collected about the
distribution of the connection weights over the course of training; passing an
<a class="reference external" href="https://www.nengo.ai/nengo/frontend_api.html#nengo.Ensemble" title="(in Nengo v3.0)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Ensemble</span></code></a> will collect data about the distribution of
encoders, and <a class="reference external" href="https://www.nengo.ai/nengo/frontend_api.html#nengo.ensemble.Neurons" title="(in Nengo v3.0)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Neurons</span></code></a> will collect data about
the distribution of biases. Additionally, the string <code class="docutils literal notranslate"><span class="pre">&quot;loss&quot;</span></code> can be passed,
in which case the training error for the given objective will be
collected over the course of training.</p>
<p>Alternatively, you can manually create summaries using <code class="docutils literal notranslate"><span class="pre">tf.summary.*</span></code> ops for
any Tensors you would like to track (see <a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/summary">the TensorFlow documentation</a>), and include those
in the summaries list.</p>
<p>TensorBoard can be used to view the exported data via the command</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>tensorboard --logdir &lt;tensorboard_dir&gt;
</pre></div>
</div>
<p>where <code class="docutils literal notranslate"><span class="pre">tensorboard_dir</span></code> is the value specified on Simulator creation via
<code class="docutils literal notranslate"><span class="pre">nengo_dl.Simulator(...,</span> <span class="pre">tensorboard=tensorboard_dir)</span></code>.  After TensorBoard is
running you can view the data by opening a web browser and navigating to
<a class="reference external" href="http://localhost:6006">http://localhost:6006</a>.</p>
<p>For details on the usage of TensorBoard, consult the <a class="reference external" href="https://www.tensorflow.org/guide/summaries_and_tensorboard">TensorFlow documentation</a>.
However, as a brief summary, you will find plots showing the loss values over
the course of training in the <code class="docutils literal notranslate"><span class="pre">Scalars</span></code> tab at the top, and plots showing the
distributions of weights/encoders/biases over time in the <code class="docutils literal notranslate"><span class="pre">Distributions</span></code> or
<code class="docutils literal notranslate"><span class="pre">Histograms</span></code> tabs.  If you call <code class="docutils literal notranslate"><span class="pre">sim.train</span></code> several times with the same
summaries, each call will result in its own set of plots, with a suffix added
to the label indicating the call number (e.g.
<code class="docutils literal notranslate"><span class="pre">label,</span> <span class="pre">label_1,</span> <span class="pre">label_2,</span> <span class="pre">...</span></code>). If you run your code multiple times with
the same <code class="docutils literal notranslate"><span class="pre">tensorboard_dir</span></code>, data will be organized according to run number;
you can turn on/off the plots for different runs using the checkboxes in the
bottom left.</p>
</div>
<div class="section" id="other-parameters">
<h3>Other parameters<a class="headerlink" href="#other-parameters" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">n_epochs</span></code> (int): run training for this many passes through the input data</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">shuffle</span></code> (bool): if <code class="docutils literal notranslate"><span class="pre">True</span></code> (default), randomly assign data to different
minibatches each epoch</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">profile</span></code> (bool or str): collect profiling information
(<a class="reference internal" href="simulator.html#sim-profile"><span class="std std-ref">as in Simulator.run</span></a>)</p></li>
</ul>
</div>
</div>
<div class="section" id="choosing-which-elements-to-optimize">
<h2>Choosing which elements to optimize<a class="headerlink" href="#choosing-which-elements-to-optimize" title="Permalink to this headline">¶</a></h2>
<p>By default, NengoDL will optimize the following elements in a model:</p>
<ol class="arabic simple">
<li><p>Connection weights (neuron–neuron weight matrices or decoders)</p></li>
<li><p>Ensemble encoders</p></li>
<li><p>Neuron biases</p></li>
</ol>
<p>These elements will <em>not</em> be optimized if they are targeted by an online
learning rule.  For example, <a class="reference external" href="https://www.nengo.ai/nengo/frontend_api.html#nengo.PES" title="(in Nengo v3.0)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nengo.PES</span></code></a> modifies connection
weights as a model is running.  If we also tried to optimize those weights with
some offline training method then those two processes would conflict
with each other, likely resulting in unintended effects.  So NengoDL will
assume that those elements should not be optimized.</p>
<p>Any of these default behaviours can be overridden using the
<a class="reference internal" href="config.html#config-trainable"><span class="std std-ref">“trainable” config option</span></a>.</p>
</div>
<div class="section" id="saving-and-loading-parameters">
<h2>Saving and loading parameters<a class="headerlink" href="#saving-and-loading-parameters" title="Permalink to this headline">¶</a></h2>
<p>After optimizing a model we often want to do something with the trained
parameters (e.g., inspect their values, save them to file, reuse them in a
different model).  NengoDL provides a number of methods to access model
parameters, in order to support different use cases.</p>
<div class="section" id="sim-data">
<h3>sim.data<a class="headerlink" href="#sim-data" title="Permalink to this headline">¶</a></h3>
<p>The most basic way to access model parameters is through the
<a class="reference internal" href="reference.html#nengo_dl.simulator.SimulationData" title="nengo_dl.simulator.SimulationData"><code class="xref py py-obj docutils literal notranslate"><span class="pre">sim.data</span></code></a>
data structure.  This provides access to the parameters of any Nengo object,
returning them as <code class="docutils literal notranslate"><span class="pre">numpy</span></code> arrays.  For example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">nengo</span><span class="o">.</span><span class="n">Network</span><span class="p">()</span> <span class="k">as</span> <span class="n">net</span><span class="p">:</span>
    <span class="n">node</span> <span class="o">=</span> <span class="n">nengo</span><span class="o">.</span><span class="n">Node</span><span class="p">([</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">ens</span> <span class="o">=</span> <span class="n">nengo</span><span class="o">.</span><span class="n">Ensemble</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">conn</span> <span class="o">=</span> <span class="n">nengo</span><span class="o">.</span><span class="n">Connection</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="n">ens</span><span class="p">)</span>
    <span class="n">probe</span> <span class="o">=</span> <span class="n">nengo</span><span class="o">.</span><span class="n">Probe</span><span class="p">(</span><span class="n">ens</span><span class="p">)</span>

<span class="k">with</span> <span class="n">nengo_dl</span><span class="o">.</span><span class="n">Simulator</span><span class="p">(</span><span class="n">net</span><span class="p">)</span> <span class="k">as</span> <span class="n">sim</span><span class="p">:</span>
    <span class="c1"># &lt; run training &gt;</span>

    <span class="k">print</span><span class="p">(</span><span class="n">sim</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">conn</span><span class="p">]</span><span class="o">.</span><span class="n">weights</span><span class="p">)</span>  <span class="c1"># connection weights</span>
    <span class="k">print</span><span class="p">(</span><span class="n">sim</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">ens</span><span class="p">]</span><span class="o">.</span><span class="n">bias</span><span class="p">)</span>  <span class="c1"># bias values</span>
    <span class="k">print</span><span class="p">(</span><span class="n">sim</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">ens</span><span class="p">]</span><span class="o">.</span><span class="n">encoders</span><span class="p">)</span>  <span class="c1"># encoder values</span>
    <span class="k">print</span><span class="p">(</span><span class="n">sim</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">ens</span><span class="p">])</span>  <span class="c1"># to see all the parameters for an object</span>
</pre></div>
</div>
<p>Once we have the parameters as <code class="docutils literal notranslate"><span class="pre">numpy</span></code> arrays we can then do whatever
we want with them (e.g., save them to file, or use them as arguments in a
different model).  Thus this method is the most general and flexible, but also
somewhat labour intensive as the user needs to handle all of that processing
themselves for each parameter.</p>
</div>
<div class="section" id="sim-save-params-sim-load-params">
<h3>sim.save_params/sim.load_params<a class="headerlink" href="#sim-save-params-sim-load-params" title="Permalink to this headline">¶</a></h3>
<p>On the opposite end of the spectrum, <a class="reference internal" href="reference.html#nengo_dl.simulator.Simulator.save_params" title="nengo_dl.simulator.Simulator.save_params"><code class="xref py py-obj docutils literal notranslate"><span class="pre">save_params</span></code></a>/
<a class="reference internal" href="reference.html#nengo_dl.simulator.Simulator.load_params" title="nengo_dl.simulator.Simulator.load_params"><code class="xref py py-obj docutils literal notranslate"><span class="pre">load_params</span></code></a> can be used to save all the parameters of a
model to file (using TensorFlow’s checkpointing system).  This is
convenient if we want to save and resume the state of a model (e.g., run some
training, do some analysis, and then run more training):</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">nengo_dl</span><span class="o">.</span><span class="n">Simulator</span><span class="p">(</span><span class="n">net</span><span class="p">)</span> <span class="k">as</span> <span class="n">sim</span><span class="p">:</span>
    <span class="c1"># &lt; run training &gt;</span>

    <span class="n">sim</span><span class="o">.</span><span class="n">save_params</span><span class="p">(</span><span class="s2">&quot;./my_saved_params&quot;</span><span class="p">)</span>

<span class="c1"># &lt; do something else &gt;</span>

<span class="k">with</span> <span class="n">nengo_dl</span><span class="o">.</span><span class="n">Simulator</span><span class="p">(</span><span class="n">net</span><span class="p">)</span> <span class="k">as</span> <span class="n">sim2</span><span class="p">:</span>
    <span class="n">sim2</span><span class="o">.</span><span class="n">load_params</span><span class="p">(</span><span class="s2">&quot;./my_saved_params&quot;</span><span class="p">)</span>
    <span class="c1"># sim2 will now match the final state of sim</span>
</pre></div>
</div>
<p>We can also use <code class="docutils literal notranslate"><span class="pre">save/load_params</span></code> to reuse parameters between models, as
long as the structure of the two models match exactly (for example,
reusing parameters from a rate version of a model in a spiking version;
see the <a class="reference internal" href="examples/spiking-mnist.html"><span class="doc">spiking MNIST example</span></a>).</p>
<p>This method is quick and convenient, but not as flexible as other options.</p>
</div>
<div class="section" id="sim-freeze-params">
<h3>sim.freeze_params<a class="headerlink" href="#sim-freeze-params" title="Permalink to this headline">¶</a></h3>
<p>Rather than saving model parameters using TensorFlow’s checkpoint system,
we can store live parameters back into the model definition using
<a class="reference internal" href="reference.html#nengo_dl.simulator.Simulator.freeze_params" title="nengo_dl.simulator.Simulator.freeze_params"><code class="xref py py-obj docutils literal notranslate"><span class="pre">freeze_params</span></code></a>.  We can freeze the parameters of individual
Ensembles and Connections, or pass a Network to freeze all the Ensembles and
Connections in that Network.</p>
<p>The main advantage of this approach is
that it makes it easy to reuse a NengoDL model in different Nengo simulators.
For example, we could optimize a model in NengoDL, save the result as a
Nengo network, and then run that model in another Simulator (e.g., one running
on custom neuromorphic hardware).</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">nengo_dl</span><span class="o">.</span><span class="n">Simulator</span><span class="p">(</span><span class="n">net</span><span class="p">)</span> <span class="k">as</span> <span class="n">sim</span><span class="p">:</span>
    <span class="c1"># &lt; run training &gt;</span>

    <span class="n">sim</span><span class="o">.</span><span class="n">freeze_params</span><span class="p">(</span><span class="n">net</span><span class="p">)</span>

<span class="c1"># load our optimized network in a different simulator</span>
<span class="k">with</span> <span class="n">nengo</span><span class="o">.</span><span class="n">Simulator</span><span class="p">(</span><span class="n">net</span><span class="p">)</span> <span class="k">as</span> <span class="n">sim2</span><span class="p">:</span>
    <span class="c1"># sim2 will now simulate a model in the default Nengo simulator, but</span>
    <span class="c1"># with the same parameters as our optimized nengo_dl model</span>
    <span class="n">sim2</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="mf">1.0</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="examples">
<h2>Examples<a class="headerlink" href="#examples" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p><a class="reference internal" href="examples/from-nengo.html"><span class="doc">Coming from Nengo to NengoDL</span></a></p></li>
<li><p><a class="reference internal" href="examples/from-tensorflow.html"><span class="doc">Coming from TensorFlow to NengoDL</span></a></p></li>
<li><p><a class="reference internal" href="examples/spiking-mnist.html"><span class="doc">Optimizing spiking neural networks</span></a></p></li>
</ul>
</div>
</div>


            </div>
          </div>
        </div>
      </div>

    </div>
  </div>
</div><footer class="text-light footer-main gradient-bottom">
  <p class="small text-center mb-0">
    <a href="https://www.nengo.ai/">What is Nengo?</a>
    <a href="https://www.nengo.ai/documentation/">Documentation</a>
    <a href="https://www.nengo.ai/download/">Download</a>
    <a href="https://appliedbrainresearch.com">ABR</a>
    <a href="https://www.nengo.ai/privacy/">Privacy</a>
  </p>
  <p class="small text-center mb-0">&copy; Applied Brain Research</p>
</footer>
<script>
  function switchVersion(select) {
    var option = select.selectedOptions[0];
    if (option.hasAttribute("value")) {
      window.location = option.value;
    }
  }
</script>

<script>
  var elements = document.querySelectorAll('.sidenav');
  Stickyfill.add(elements);
</script>
<script>
  ScrollReveal().reveal(".fade-in", {
      scale: 0.85,
      duration: 1000,
      delay: 250,
      interval: 50
  });
</script>
<script>
  $('a.toggle-sidenav').on('click', function(e) {
    e.preventDefault();
    if ( $(this).hasClass('active') ) {
      $(this).removeClass('active');
      $('.sidenav').removeClass('open');
    } else {
      $(this).addClass('active');
      $('.sidenav').addClass('open');
    }
  });
</script>
<script>
  var lists = document.querySelectorAll('.toctree ul');
  lists.forEach((ul) => {
      ul.classList.add("nav");
  });
  var links = document.querySelectorAll('.toctree a');
  links.forEach((link) => {
      link.classList.add("nav-link");
  });
  $("body").scrollspy({target: ".sidenav"});
</script>
  </body>
</html>