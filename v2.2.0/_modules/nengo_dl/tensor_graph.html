
<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta charset="utf-8" />
    <title>nengo_dl.tensor_graph &#8212; NengoDL 2.2.0 docs</title>
    <link rel="stylesheet" href="../../_static/basic.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
<link href="https://fonts.googleapis.com/css?family=IBM+Plex+Sans:400,400i,600|Rajdhani:700&display=swap" rel="stylesheet">
<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.8.2/css/all.css" integrity="sha384-oS3vJWv+0UjzBfQzYUhtDYW+Pj2yciDJxpsK1OYPAYjqT085Qq/1cq5FLXAZQ7Ay" crossorigin="anonymous">
<link rel="stylesheet" href="https://www.nengo.ai/css/bootstrap.css" type="text/css">
<style>
  body .title-bar,
  body .documentation-source h1:after {
    background-color: #ff6600;
  }
</style>
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-41658423-2"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'UA-41658423-2');
</script>
<script src="https://code.jquery.com/jquery-3.3.1.min.js" integrity="sha256-FgpCb/KJQlLNfOu91ta32o/NMZxltwRo8QtmkMRdAu8=" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.3/umd/popper.min.js" integrity="sha384-ZMP7rVo3mIykV+2+9J3UJ46jBk0WLaUAdn689aCwoqbBJiSnjAK/l8WvCWPIPm49" crossorigin="anonymous"></script>
<script src="https://unpkg.com/scrollreveal"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/stickyfill/2.1.0/stickyfill.min.js"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.1.1/js/bootstrap.min.js" integrity="sha384-smHYKdLADwkXOn1EmN1qk/HfnUcbVRZyYmZ4qpPea6sjB/pTJ0euyQp0Mk8ck+5T" crossorigin="anonymous"></script>
<!-- From basic/layout.html -->
<script type="text/javascript" id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
  
  
<script type="text/javascript" src="../../_static/underscore.js"></script>
  
  
<script type="text/javascript" src="../../_static/doctools.js"></script>
  
  
<script type="text/javascript" src="../../_static/language_data.js"></script>
  
  
<script async="async" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
  
  
<script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true, "ignoreClass": "document", "processClass": "math|output_area"}})</script>
  
    <link rel="shortcut icon" href="../../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
<meta name="viewport" content="width=device-width, initial-scale=1, viewport-fit=cover">

  </head><body class="bg-dark">

<header class="fixed-top header-top shadow-sm">
  <nav class="navbar navbar-expand-md navbar-light bg-white">
    <a class="navbar-brand" href="https://www.nengo.ai">
      <img
        src="https://www.nengo.ai/design/_images/general-full-light.svg"
        alt="Nengo"
        class="logo"
      />
    </a>
    <button
      class="navbar-toggler"
      type="button"
      data-toggle="collapse"
      data-target="#navbar-collapse"
      aria-controls="navbar-collapse"
      aria-expanded="false"
      aria-label="Toggle navigation"
    >
      <span class="navbar-toggler-icon"></span>
    </button>
    <div class="collapse navbar-collapse" id="navbar-collapse">
      <ul class="navbar-nav ml-auto">
        <li class="nav-item">
          <a class="nav-link" href="https://www.nengo.ai">What is Nengo?</a>
        </li>
        <li class="nav-item dropdown active">
          <a
            class="nav-link dropdown-toggle"
            id="navbar-dropdown-docs"
            data-toggle="dropdown"
            aria-haspopup="true"
            aria-expanded="false"
            href="#"
            >Documentation</a
          >
          <div
            class="dropdown-menu shadow-lg border-0"
            aria-labelledby="navbar-dropdown-docs"
          >
            
            <a class="dropdown-item" href="https://www.nengo.ai/nengo/">Nengo Core</a>
            <a class="dropdown-item" href="https://github.com/nengo/nengo-gui/">Nengo GUI</a>
            <a class="dropdown-item" href="https://www.nengo.ai/nengo-dl/">Nengo DL</a>
            <div class="dropdown-divider"></div>
            <a class="dropdown-item" href="https://www.nengo.ai/nengo-spa/">Nengo SPA</a>
            <a class="dropdown-item" href="https://www.nengo.ai/nengo-extras/">Nengo Extras</a>
            <a class="dropdown-item" href="https://arvoelke.github.io/nengolib-docs/">Nengolib</a>
            <a class="dropdown-item" href="https://github.com/nengo/nengo-examples/">Nengo Examples</a>
            <div class="dropdown-divider"></div>
            <a class="dropdown-item" href="https://www.nengo.ai/nengo-fpga/">Nengo FPGA</a>
            <a class="dropdown-item" href="https://www.nengo.ai/nengo-loihi/">Nengo Loihi</a>
            <a class="dropdown-item" href="https://github.com/nengo/nengo-ocl">Nengo OpenCL</a>
            <a class="dropdown-item" href="https://github.com/project-rig/nengo_spinnaker">Nengo SpiNNaker</a>
            <a class="dropdown-item" href="https://github.com/nengo/nengo-mpi">Nengo MPI</a>
            <div class="dropdown-divider"></div>
            <a class="dropdown-item" href="https://www.nengo.ai/documentation"
              >All documentation</a
            >
          </div>
        </li>
        <li class="nav-item dropdown">
          <a
            class="nav-link dropdown-toggle"
            id="navbar-dropdown-community"
            data-toggle="dropdown"
            aria-haspopup="true"
            aria-expanded="false"
            href="#"
            >Community</a
          >
          <div
            class="dropdown-menu shadow-lg border-0"
            aria-labelledby="navbar-dropdown-community"
          >
            <a class="dropdown-item" href="https://forum.nengo.ai">Forum</a>
            <div class="dropdown-divider"></div>
            <a class="dropdown-item" href="https://www.nengo.ai/people"
              >People</a
            >
            <a class="dropdown-item" href="https://www.nengo.ai/summer-school"
              >Summer school</a
            >
            <a class="dropdown-item" href="https://www.nengo.ai/contributing"
              >Contributing</a
            >
            <a class="dropdown-item" href="https://www.nengo.ai/publications"
              >Publications</a
            >
            <a class="dropdown-item" href="https://www.nengo.ai/videos"
              >Videos</a
            >
            <a class="dropdown-item" href="https://www.nengo.ai/conduct"
              >Code of conduct</a
            >
            <a class="dropdown-item" href="https://www.nengo.ai/caa">CAA</a>
          </div>
        </li>
        <li class="nav-item">
          <a
            class="nav-link btn btn-success btn-sm text-white"
            href="https://www.nengo.ai/download"
            >Download</a
          >
        </li>
      </ul>
    </div>
  </nav>
</header>
<div class="main-content gradient-top">
  <div class="container-fluid">
    <div class="row"><a class="toggle-sidenav d-block d-md-none" href="#"
  ><i class="icon-close fa fa-fw fa-arrow-left"></i
  ><i class="icon-open fa fa-fw fa-arrow-right"></i
></a>
<div role="complementary" class="sidenav col-4 col-xl-3 p-0 border-right">
  <h3 class="pt-5 px-5">
    <a href="../../index.html">
      <img
        class="img-fluid documentation-image"
        src="https://www.nengo.ai/design/_images/nengo-dl-full-light.svg"
        alt="NengoDL"
      />
    </a>
  </h3>
  
  <form class="px-5 pb-5 mb-0 mt-3 border-bottom">
    <div class="form-group">
      <label class="text-gray">Version:</label>
      <select class="custom-select" onchange="switchVersion(this);">
        
        
        <option value="../../../_modules/nengo_dl/tensor_graph.html">latest</option>
        
        
          
        <option selected>v2.2.0</option>
          
        
          
        <option value="../../../v2.1.1/_modules/nengo_dl/tensor_graph.html">
          v2.1.1
        </option>
          
        
          
        <option value="../../../v2.1.0/_modules/nengo_dl/tensor_graph.html">
          v2.1.0
        </option>
          
        
          
        <option value="../../../v2.0.0/_modules/nengo_dl/tensor_graph.html">
          v2.0.0
        </option>
          
        
          
        <option value="../../../v1.2.1/_modules/nengo_dl/tensor_graph.html">
          v1.2.1
        </option>
          
        
          
        <option value="../../../v1.2.0/_modules/nengo_dl/tensor_graph.html">
          v1.2.0
        </option>
          
        
          
        <option value="../../../v1.1.0/_modules/nengo_dl/tensor_graph.html">
          v1.1.0
        </option>
          
        
          
        <option value="../../../v1.0.0/_modules/nengo_dl/tensor_graph.html">
          v1.0.0
        </option>
          
        
          
        <option value="../../../v0.6.2/_modules/nengo_dl/tensor_graph.html">
          v0.6.2
        </option>
          
        
          
        <option value="../../../v0.6.1/_modules/nengo_dl/tensor_graph.html">
          v0.6.1
        </option>
          
        
          
        <option value="../../../v0.6.0/_modules/nengo_dl/tensor_graph.html">
          v0.6.0
        </option>
          
        
          
        <option value="../../../v0.5.2/_modules/nengo_dl/tensor_graph.html">
          v0.5.2
        </option>
          
        
          
        <option value="../../../v0.5.1/_modules/nengo_dl/tensor_graph.html">
          v0.5.1
        </option>
          
        
          
        <option value="../../../v0.5.0/_modules/nengo_dl/tensor_graph.html">
          v0.5.0
        </option>
          
        
          
        <option value="../../../v0.4.0/_modules/nengo_dl/tensor_graph.html">
          v0.4.0
        </option>
          
        
          
        <option value="../../../v0.3.1/_modules/nengo_dl/tensor_graph.html">
          v0.3.1
        </option>
          
        
          
        <option value="../../../v0.3.0/_modules/nengo_dl/tensor_graph.html">
          v0.3.0
        </option>
          
        
          
        <option value="../../../v0.2.0/_modules/nengo_dl/tensor_graph.html">
          v0.2.0
        </option>
          
        
      </select>
    </div>
  </form>
  
  <div class="p-5 toctree">
    <ul>
<li class="toctree-l1"><a class="reference internal" href="../../introduction.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../user-guide.html">User guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../reference.html">API reference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../examples.html">Examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../resources.html">Additional resources</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../project.html">Project information</a></li>
</ul>

  </div>
<form class="p-5 my-0 border-top" action="../../search.html" method="get">
  <div class="form-group form-group-single">
    <input type="text" name="q" class="form-control" placeholder="Search" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
    <button type="submit" class="btn btn-link">
      <img src="https://www.nengo.ai/img/icon-search.svg" alt="Go" />
    </button>
  </div>
</form></div>
      

      <div class="col-12 col-md-8 col-xl-9">
        <div class="container">
          <div class="row">
            <div class="col-10 offset-1 pb-5 documentation-source">
              
  <h1>Source code for nengo_dl.tensor_graph</h1><div class="highlight"><pre>
<span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">Manages all the data and build processes associated with the TensorFlow graph.</span>

<span class="sd">The TensorFlow graph is the symbolic description of the computations in the</span>
<span class="sd">network, which will be executed by the simulator.</span>
<span class="sd">&quot;&quot;&quot;</span>

<span class="kn">from</span> <span class="nn">collections</span> <span class="k">import</span> <span class="n">OrderedDict</span><span class="p">,</span> <span class="n">defaultdict</span>
<span class="kn">import</span> <span class="nn">functools</span>
<span class="kn">import</span> <span class="nn">inspect</span>
<span class="kn">import</span> <span class="nn">itertools</span>
<span class="kn">import</span> <span class="nn">logging</span>
<span class="kn">import</span> <span class="nn">warnings</span>

<span class="kn">from</span> <span class="nn">nengo</span> <span class="k">import</span> <span class="n">Connection</span><span class="p">,</span> <span class="n">Process</span><span class="p">,</span> <span class="n">Ensemble</span>
<span class="kn">from</span> <span class="nn">nengo.builder.operator</span> <span class="k">import</span> <span class="n">TimeUpdate</span><span class="p">,</span> <span class="n">SimPyFunc</span><span class="p">,</span> <span class="n">Reset</span>
<span class="kn">from</span> <span class="nn">nengo.builder.processes</span> <span class="k">import</span> <span class="n">SimProcess</span>
<span class="kn">from</span> <span class="nn">nengo.config</span> <span class="k">import</span> <span class="n">ConfigError</span>
<span class="kn">from</span> <span class="nn">nengo.ensemble</span> <span class="k">import</span> <span class="n">Neurons</span>
<span class="kn">from</span> <span class="nn">nengo.exceptions</span> <span class="k">import</span> <span class="n">SimulationError</span><span class="p">,</span> <span class="n">ValidationError</span>
<span class="kn">from</span> <span class="nn">nengo.neurons</span> <span class="k">import</span> <span class="n">Direct</span>
<span class="kn">from</span> <span class="nn">nengo.utils.magic</span> <span class="k">import</span> <span class="n">decorator</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>

<span class="kn">from</span> <span class="nn">nengo_dl</span> <span class="k">import</span> <span class="p">(</span>
    <span class="n">builder</span><span class="p">,</span> <span class="n">graph_optimizer</span><span class="p">,</span> <span class="n">signals</span><span class="p">,</span> <span class="n">utils</span><span class="p">,</span> <span class="n">tensor_node</span><span class="p">,</span> <span class="n">config</span><span class="p">)</span>
<span class="kn">from</span> <span class="nn">nengo_dl.compat</span> <span class="k">import</span> <span class="p">(</span>
    <span class="n">tf_compat</span><span class="p">,</span> <span class="n">SparseMatrix</span><span class="p">,</span> <span class="n">is_sparse</span><span class="p">,</span> <span class="n">make_process_state</span><span class="p">,</span> <span class="n">make_process_step</span><span class="p">)</span>

<span class="n">logger</span> <span class="o">=</span> <span class="n">logging</span><span class="o">.</span><span class="n">getLogger</span><span class="p">(</span><span class="vm">__name__</span><span class="p">)</span>


<div class="viewcode-block" id="with_self"><a class="viewcode-back" href="../../reference.html#nengo_dl.tensor_graph.with_self">[docs]</a><span class="nd">@decorator</span>
<span class="k">def</span> <span class="nf">with_self</span><span class="p">(</span><span class="n">wrapped</span><span class="p">,</span> <span class="n">instance</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">kwargs</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;A decorator that can be used to ensure that any ops created within the</span>
<span class="sd">    wrapped method will be added to the TensorGraph object&#39;s graph.&quot;&quot;&quot;</span>

    <span class="k">with</span> <span class="n">instance</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">as_default</span><span class="p">(),</span> <span class="n">instance</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="n">instance</span><span class="o">.</span><span class="n">device</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">wrapped</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></div>


<div class="viewcode-block" id="TensorGraph"><a class="viewcode-back" href="../../reference.html#nengo_dl.tensor_graph.TensorGraph">[docs]</a><span class="k">class</span> <span class="nc">TensorGraph</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Manages the construction of the TensorFlow symbolic computation graph.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    model : `~nengo.builder.Model`</span>
<span class="sd">        Pre-built Nengo model describing the network to be simulated</span>
<span class="sd">    dt : float</span>
<span class="sd">        Length of a simulator timestep, in seconds</span>
<span class="sd">    unroll_simulation : int</span>
<span class="sd">        Unroll simulation loop by explicitly building ``unroll_simulation``</span>
<span class="sd">        iterations into the computation graph</span>
<span class="sd">    dtype : ``tf.DType``</span>
<span class="sd">        Floating point precision to use for simulation</span>
<span class="sd">    minibatch_size : int</span>
<span class="sd">        The number of simultaneous inputs that will be passed through the</span>
<span class="sd">        network</span>
<span class="sd">    device : None or ``&quot;/cpu:0&quot;`` or ``&quot;/gpu:[0-n]&quot;``</span>
<span class="sd">        Device on which to execute computations (if None then uses the</span>
<span class="sd">        default device as determined by TensorFlow)</span>
<span class="sd">    progress : `.utils.ProgressBar`</span>
<span class="sd">        Progress bar for optimization stage</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">dt</span><span class="p">,</span> <span class="n">unroll_simulation</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">minibatch_size</span><span class="p">,</span>
                 <span class="n">device</span><span class="p">,</span> <span class="n">progress</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dt</span> <span class="o">=</span> <span class="n">dt</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">unroll</span> <span class="o">=</span> <span class="n">unroll_simulation</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dtype</span> <span class="o">=</span> <span class="n">dtype</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">minibatch_size</span> <span class="o">=</span> <span class="n">minibatch_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="n">device</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">graph</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Graph</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">signals</span> <span class="o">=</span> <span class="n">signals</span><span class="o">.</span><span class="n">SignalDict</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">minibatch_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">inference_only</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">get_setting</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="s2">&quot;inference_only&quot;</span><span class="p">,</span>
                                                 <span class="kc">False</span><span class="p">)</span>

        <span class="c1"># find invariant inputs (nodes that don&#39;t receive any input other</span>
        <span class="c1"># than the simulation time). we&#39;ll compute these outside the simulation</span>
        <span class="c1"># and feed in the result.</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">toplevel</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">invariant_inputs</span> <span class="o">=</span> <span class="n">OrderedDict</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">invariant_inputs</span> <span class="o">=</span> <span class="n">OrderedDict</span><span class="p">(</span>
                <span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">n</span><span class="o">.</span><span class="n">output</span><span class="p">)</span> <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">toplevel</span><span class="o">.</span><span class="n">all_nodes</span>
                <span class="k">if</span> <span class="n">n</span><span class="o">.</span><span class="n">size_in</span> <span class="o">==</span> <span class="mi">0</span>
                <span class="ow">and</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">tensor_node</span><span class="o">.</span><span class="n">TensorNode</span><span class="p">))</span>

        <span class="c1"># filter unused operators</span>
        <span class="c1"># remove TimeUpdate because it is executed as part of the simulation</span>
        <span class="c1"># loop, not part of the step plan. remove input nodes because they</span>
        <span class="c1"># are executed outside the simulation.</span>
        <span class="n">node_processes</span> <span class="o">=</span> <span class="p">[</span><span class="n">n</span><span class="o">.</span><span class="n">output</span> <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">invariant_inputs</span>
                          <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">n</span><span class="o">.</span><span class="n">output</span><span class="p">,</span> <span class="n">Process</span><span class="p">)]</span>
        <span class="n">operators</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">op</span> <span class="k">for</span> <span class="n">op</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">operators</span> <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span>
                <span class="nb">isinstance</span><span class="p">(</span><span class="n">op</span><span class="p">,</span> <span class="n">TimeUpdate</span><span class="p">)</span>
                <span class="ow">or</span> <span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">op</span><span class="p">,</span> <span class="n">SimPyFunc</span><span class="p">)</span> <span class="ow">and</span> <span class="n">op</span><span class="o">.</span><span class="n">x</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">)</span>
                <span class="ow">or</span> <span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">op</span><span class="p">,</span> <span class="n">SimProcess</span><span class="p">)</span> <span class="ow">and</span> <span class="n">op</span><span class="o">.</span><span class="n">input</span> <span class="ow">is</span> <span class="kc">None</span>
                    <span class="ow">and</span> <span class="n">op</span><span class="o">.</span><span class="n">process</span> <span class="ow">in</span> <span class="n">node_processes</span><span class="p">))]</span>

        <span class="c1"># mark trainable signals</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mark_signals</span><span class="p">()</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Initial plan length: </span><span class="si">%d</span><span class="s2">&quot;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">operators</span><span class="p">))</span>

        <span class="c1"># apply graph simplification functions</span>
        <span class="n">simplifications</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">get_setting</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="s2">&quot;simplifications&quot;</span><span class="p">,</span> <span class="p">[</span>
            <span class="n">graph_optimizer</span><span class="o">.</span><span class="n">remove_constant_copies</span><span class="p">,</span>
            <span class="n">graph_optimizer</span><span class="o">.</span><span class="n">remove_unmodified_resets</span><span class="p">,</span>
            <span class="n">graph_optimizer</span><span class="o">.</span><span class="n">remove_zero_incs</span><span class="p">,</span>
            <span class="n">graph_optimizer</span><span class="o">.</span><span class="n">remove_identity_muls</span><span class="p">,</span>
        <span class="p">])</span>

        <span class="k">with</span> <span class="n">progress</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="s2">&quot;operator simplificaton&quot;</span><span class="p">,</span> <span class="n">max_value</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
            <span class="n">old_operators</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">while</span> <span class="nb">len</span><span class="p">(</span><span class="n">old_operators</span><span class="p">)</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="n">operators</span><span class="p">)</span> <span class="ow">or</span> <span class="nb">any</span><span class="p">(</span>
                    <span class="n">x</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">y</span> <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">operators</span><span class="p">,</span> <span class="n">old_operators</span><span class="p">)):</span>
                <span class="n">old_operators</span> <span class="o">=</span> <span class="n">operators</span>
                <span class="k">for</span> <span class="n">simp</span> <span class="ow">in</span> <span class="n">simplifications</span><span class="p">:</span>
                    <span class="n">operators</span> <span class="o">=</span> <span class="n">simp</span><span class="p">(</span><span class="n">operators</span><span class="p">)</span>

        <span class="c1"># group mergeable operators</span>
        <span class="n">planner</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">get_setting</span><span class="p">(</span>
            <span class="n">model</span><span class="p">,</span> <span class="s2">&quot;planner&quot;</span><span class="p">,</span> <span class="n">graph_optimizer</span><span class="o">.</span><span class="n">tree_planner</span><span class="p">)</span>

        <span class="k">with</span> <span class="n">progress</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="s2">&quot;merging operators&quot;</span><span class="p">,</span> <span class="n">max_value</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
            <span class="n">plan</span> <span class="o">=</span> <span class="n">planner</span><span class="p">(</span><span class="n">operators</span><span class="p">)</span>

        <span class="c1"># TODO: we could also merge operators sequentially (e.g., combine</span>
        <span class="c1"># a copy and dotinc into one op), as long as the intermediate signal</span>
        <span class="c1"># is only written to by one op and read by one op</span>

        <span class="c1"># order signals/operators to promote contiguous reads</span>
        <span class="n">sorter</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">get_setting</span><span class="p">(</span>
            <span class="n">model</span><span class="p">,</span> <span class="s2">&quot;sorter&quot;</span><span class="p">,</span> <span class="n">graph_optimizer</span><span class="o">.</span><span class="n">order_signals</span><span class="p">)</span>

        <span class="k">with</span> <span class="n">progress</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="s2">&quot;ordering signals&quot;</span><span class="p">,</span> <span class="n">max_value</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
            <span class="n">sigs</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">plan</span> <span class="o">=</span> <span class="n">sorter</span><span class="p">(</span><span class="n">plan</span><span class="p">,</span> <span class="n">n_passes</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>

        <span class="c1"># create base arrays and map Signals to TensorSignals (views on those</span>
        <span class="c1"># base arrays)</span>
        <span class="k">with</span> <span class="n">progress</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="s2">&quot;creating signals&quot;</span><span class="p">,</span> <span class="n">max_value</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">create_signals</span><span class="p">(</span><span class="n">sigs</span><span class="p">)</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Optimized plan length: </span><span class="si">%d</span><span class="s2">&quot;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">plan</span><span class="p">))</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Number of base arrays: </span><span class="si">%d</span><span class="s2">&quot;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">base_arrays_init</span><span class="p">))</span>

        <span class="c1"># initialize op builder</span>
        <span class="n">build_config</span> <span class="o">=</span> <span class="n">builder</span><span class="o">.</span><span class="n">BuildConfig</span><span class="p">(</span>
            <span class="n">inference_only</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">inference_only</span><span class="p">,</span>
            <span class="n">lif_smoothing</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">get_setting</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s2">&quot;lif_smoothing&quot;</span><span class="p">),</span>
            <span class="n">cpu_only</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span> <span class="o">==</span> <span class="s2">&quot;/cpu:0&quot;</span> <span class="ow">or</span> <span class="ow">not</span> <span class="n">utils</span><span class="o">.</span><span class="n">tf_gpu_installed</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">op_builder</span> <span class="o">=</span> <span class="n">builder</span><span class="o">.</span><span class="n">Builder</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">plan</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">graph</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">signals</span><span class="p">,</span>
                                          <span class="n">build_config</span><span class="p">)</span>

<div class="viewcode-block" id="TensorGraph.build"><a class="viewcode-back" href="../../reference.html#nengo_dl.tensor_graph.TensorGraph.build">[docs]</a>    <span class="nd">@with_self</span>
    <span class="k">def</span> <span class="nf">build</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">progress</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Constructs a new graph to simulate the model.</span>

<span class="sd">        progress : `.utils.ProgressBar`</span>
<span class="sd">            Progress bar for construction stage</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">target_phs</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">outputs</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">optimizers</span> <span class="o">=</span> <span class="p">{}</span>

        <span class="c1"># create these constants once here for reuse in different operators</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">signals</span><span class="o">.</span><span class="n">dt</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dt</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">signals</span><span class="o">.</span><span class="n">dt_val</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dt</span>  <span class="c1"># store the actual value as well</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">signals</span><span class="o">.</span><span class="n">zero</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">signals</span><span class="o">.</span><span class="n">one</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">inference_only</span><span class="p">:</span>
            <span class="c1"># this variable controls behaviour in the simulation that is</span>
            <span class="c1"># conditional on whether we are doing training or inference</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">signals</span><span class="o">.</span><span class="n">training</span> <span class="o">=</span> <span class="n">tf_compat</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">bool</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(),</span>
                                                          <span class="n">name</span><span class="o">=</span><span class="s2">&quot;training&quot;</span><span class="p">)</span>

            <span class="c1"># variable to track training step</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">training_step</span> <span class="o">=</span> <span class="n">tf_compat</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">get_or_create_global_step</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">training_step</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="c1"># create base arrays</span>
        <span class="n">sub</span> <span class="o">=</span> <span class="n">progress</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="s2">&quot;creating base arrays&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">base_vars</span> <span class="o">=</span> <span class="n">OrderedDict</span><span class="p">()</span>
        <span class="n">unique_ids</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">trainable</span><span class="p">)</span> <span class="ow">in</span> <span class="n">sub</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">base_arrays_init</span><span class="o">.</span><span class="n">items</span><span class="p">()):</span>
            <span class="n">name</span> <span class="o">=</span> <span class="s2">&quot;</span><span class="si">%s</span><span class="s2">_</span><span class="si">%s</span><span class="s2">_</span><span class="si">%s</span><span class="s2">_</span><span class="si">%d</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span>
                <span class="n">v</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="s2">&quot;_&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">v</span><span class="o">.</span><span class="n">shape</span><span class="p">),</span> <span class="n">trainable</span><span class="p">,</span>
                <span class="n">unique_ids</span><span class="p">[(</span><span class="n">v</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">v</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">trainable</span><span class="p">)])</span>
            <span class="n">unique_ids</span><span class="p">[(</span><span class="n">v</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">v</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">trainable</span><span class="p">)]</span> <span class="o">+=</span> <span class="mi">1</span>

            <span class="c1"># we initialize all the variables from placeholders, and then</span>
            <span class="c1"># feed in the initial values when the init op is called. this</span>
            <span class="c1"># prevents TensorFlow from storing large constants in the graph</span>
            <span class="c1"># def, which can cause problems for large models</span>
            <span class="n">ph</span> <span class="o">=</span> <span class="n">tf_compat</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">v</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">v</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;</span><span class="si">%s</span><span class="s2">_init&quot;</span> <span class="o">%</span> <span class="n">name</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">trainable</span><span class="p">:</span>
                <span class="k">with</span> <span class="n">tf_compat</span><span class="o">.</span><span class="n">variable_scope</span><span class="p">(</span><span class="s2">&quot;trainable_vars&quot;</span><span class="p">,</span> <span class="n">reuse</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
                    <span class="n">var</span> <span class="o">=</span> <span class="n">tf_compat</span><span class="o">.</span><span class="n">get_variable</span><span class="p">(</span>
                        <span class="n">name</span><span class="p">,</span> <span class="n">initializer</span><span class="o">=</span><span class="n">ph</span><span class="p">,</span> <span class="n">trainable</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                        <span class="n">use_resource</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">with</span> <span class="n">tf_compat</span><span class="o">.</span><span class="n">variable_scope</span><span class="p">(</span><span class="s2">&quot;local_vars&quot;</span><span class="p">,</span> <span class="n">reuse</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
                    <span class="n">var</span> <span class="o">=</span> <span class="n">tf_compat</span><span class="o">.</span><span class="n">get_local_variable</span><span class="p">(</span>
                        <span class="n">name</span><span class="p">,</span> <span class="n">initializer</span><span class="o">=</span><span class="n">ph</span><span class="p">,</span> <span class="n">trainable</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                        <span class="n">use_resource</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">base_vars</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">var</span><span class="p">,</span> <span class="n">ph</span><span class="p">,</span> <span class="n">v</span><span class="p">)</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot;created base arrays&quot;</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">([</span><span class="nb">str</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">base_vars</span><span class="o">.</span><span class="n">values</span><span class="p">()])</span>

        <span class="c1"># set up invariant inputs</span>
        <span class="n">sub</span> <span class="o">=</span> <span class="n">progress</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="s2">&quot;building inputs&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">build_inputs</span><span class="p">(</span><span class="n">sub</span><span class="p">)</span>

        <span class="c1"># pre-build stage</span>
        <span class="k">with</span> <span class="n">progress</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="s2">&quot;pre-build stage&quot;</span><span class="p">,</span> <span class="n">max_value</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">plan</span><span class="p">))</span> <span class="k">as</span> <span class="n">sub</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">op_builder</span><span class="o">.</span><span class="n">pre_build</span><span class="p">(</span><span class="n">sub</span><span class="p">)</span>

        <span class="c1"># build stage</span>
        <span class="k">with</span> <span class="n">progress</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span>
                <span class="s2">&quot;build stage&quot;</span><span class="p">,</span> <span class="n">max_value</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">plan</span><span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">unroll</span><span class="p">)</span> <span class="k">as</span> <span class="n">sub</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">build_loop</span><span class="p">(</span><span class="n">sub</span><span class="p">)</span>

        <span class="c1"># ops for initializing variables (will be called by simulator)</span>
        <span class="n">trainable_vars</span> <span class="o">=</span> <span class="n">tf_compat</span><span class="o">.</span><span class="n">trainable_variables</span><span class="p">()</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">inference_only</span><span class="p">:</span>
            <span class="n">trainable_vars</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">training_step</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">trainable_init_op</span> <span class="o">=</span> <span class="n">tf_compat</span><span class="o">.</span><span class="n">variables_initializer</span><span class="p">(</span>
            <span class="n">trainable_vars</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">local_init_op</span> <span class="o">=</span> <span class="n">tf_compat</span><span class="o">.</span><span class="n">local_variables_initializer</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">global_init_op</span> <span class="o">=</span> <span class="n">tf_compat</span><span class="o">.</span><span class="n">variables_initializer</span><span class="p">(</span>
            <span class="p">[</span><span class="n">v</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">tf_compat</span><span class="o">.</span><span class="n">global_variables</span><span class="p">()</span>
             <span class="k">if</span> <span class="n">v</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">trainable_vars</span><span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">constant_init_op</span> <span class="o">=</span> <span class="n">tf_compat</span><span class="o">.</span><span class="n">variables_initializer</span><span class="p">(</span>
            <span class="n">tf_compat</span><span class="o">.</span><span class="n">get_collection</span><span class="p">(</span><span class="s2">&quot;constants&quot;</span><span class="p">))</span>

        <span class="c1"># logging</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Number of reads: </span><span class="si">%d</span><span class="s2">&quot;</span><span class="p">,</span> <span class="nb">sum</span><span class="p">(</span>
            <span class="n">x</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">signals</span><span class="o">.</span><span class="n">read_types</span><span class="o">.</span><span class="n">values</span><span class="p">()))</span>
        <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">signals</span><span class="o">.</span><span class="n">read_types</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;    </span><span class="si">%s</span><span class="s2">: </span><span class="si">%d</span><span class="s2">&quot;</span><span class="p">,</span> <span class="o">*</span><span class="n">x</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Number of writes: </span><span class="si">%d</span><span class="s2">&quot;</span><span class="p">,</span> <span class="nb">sum</span><span class="p">(</span>
            <span class="n">x</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">signals</span><span class="o">.</span><span class="n">write_types</span><span class="o">.</span><span class="n">values</span><span class="p">()))</span>
        <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">signals</span><span class="o">.</span><span class="n">write_types</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;    </span><span class="si">%s</span><span class="s2">: </span><span class="si">%d</span><span class="s2">&quot;</span><span class="p">,</span> <span class="o">*</span><span class="n">x</span><span class="p">)</span></div>

<div class="viewcode-block" id="TensorGraph.build_step"><a class="viewcode-back" href="../../reference.html#nengo_dl.tensor_graph.TensorGraph.build_step">[docs]</a>    <span class="k">def</span> <span class="nf">build_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">progress</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Build the operators that execute a single simulation timestep</span>
<span class="sd">        into the graph.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        progress : `.utils.ProgressBar`</span>
<span class="sd">            Progress bar for loop construction</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        probe_tensors : list of ``tf.Tensor``</span>
<span class="sd">            The Tensor objects representing the data required for each model</span>
<span class="sd">            Probe</span>
<span class="sd">        side_effects : list of ``tf.Tensor``</span>
<span class="sd">            The output Tensors of computations that may have side-effects</span>
<span class="sd">            (e.g., `~nengo.Node` functions), meaning that they</span>
<span class="sd">            must be executed each time step even if their output doesn&#39;t appear</span>
<span class="sd">            to be used in the simulation</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c1"># manually build TimeUpdate. we don&#39;t include this in the plan,</span>
        <span class="c1"># because loop variables (`step`) are (semi?) pinned to the CPU, which</span>
        <span class="c1"># causes the whole variable to get pinned to the CPU if we include</span>
        <span class="c1"># `step` as part of the normal planning process.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">signals</span><span class="o">.</span><span class="n">time</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">signals</span><span class="o">.</span><span class="n">step</span><span class="p">,</span>
                                    <span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">signals</span><span class="o">.</span><span class="n">dt</span>

        <span class="c1"># build operators</span>
        <span class="n">side_effects</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">op_builder</span><span class="o">.</span><span class="n">build</span><span class="p">(</span><span class="n">progress</span><span class="p">)</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot;collecting probe tensors&quot;</span><span class="p">)</span>
        <span class="n">probe_tensors</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">probes</span><span class="p">:</span>
            <span class="n">probe_sig</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">sig</span><span class="p">[</span><span class="n">p</span><span class="p">][</span><span class="s2">&quot;in&quot;</span><span class="p">]</span>
            <span class="k">if</span> <span class="n">probe_sig</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">signals</span><span class="p">:</span>
                <span class="c1"># TODO: better solution to avoid the forced_copy</span>
                <span class="c1"># we need to make sure that probe reads occur before the</span>
                <span class="c1"># probe value is overwritten on the next timestep. however,</span>
                <span class="c1"># just blocking on the sliced value (probe_tensor) doesn&#39;t</span>
                <span class="c1"># work, because slices of variables don&#39;t perform a</span>
                <span class="c1"># copy, so the slice can be &quot;executed&quot; and then the value</span>
                <span class="c1"># overwritten before the tensorarray write occurs. what we</span>
                <span class="c1"># really want to do is block until the probe_arrays.write</span>
                <span class="c1"># happens, but you can&#39;t block on probe_arrays (and blocking on</span>
                <span class="c1"># probe_array.flow doesn&#39;t work, although I think it should).</span>
                <span class="c1"># so by adding the copy here and then blocking on the copy, we</span>
                <span class="c1"># make sure that the probe value is read before it can be</span>
                <span class="c1"># overwritten.</span>
                <span class="n">probe_tensors</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">signals</span><span class="o">.</span><span class="n">gather</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">signals</span><span class="p">[</span><span class="n">probe_sig</span><span class="p">],</span> <span class="n">force_copy</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># if a probe signal isn&#39;t in sig_map, that means that it isn&#39;t</span>
                <span class="c1"># involved in any simulator ops.  so we know its value never</span>
                <span class="c1"># changes, and we&#39;ll just return a constant containing the</span>
                <span class="c1"># initial value.</span>
                <span class="k">if</span> <span class="n">probe_sig</span><span class="o">.</span><span class="n">minibatched</span><span class="p">:</span>
                    <span class="n">init_val</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">tile</span><span class="p">(</span><span class="n">probe_sig</span><span class="o">.</span><span class="n">initial_value</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="kc">None</span><span class="p">],</span>
                                       <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">minibatch_size</span><span class="p">))</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">init_val</span> <span class="o">=</span> <span class="n">probe_sig</span><span class="o">.</span><span class="n">initial_value</span>
                <span class="n">probe_tensors</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="n">init_val</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">))</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">30</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot;build_step complete&quot;</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot;probe_tensors </span><span class="si">%s</span><span class="s2">&quot;</span><span class="p">,</span> <span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">probe_tensors</span><span class="p">])</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot;side_effects </span><span class="si">%s</span><span class="s2">&quot;</span><span class="p">,</span> <span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">side_effects</span><span class="p">])</span>

        <span class="k">return</span> <span class="n">probe_tensors</span><span class="p">,</span> <span class="n">side_effects</span></div>

<div class="viewcode-block" id="TensorGraph.build_loop"><a class="viewcode-back" href="../../reference.html#nengo_dl.tensor_graph.TensorGraph.build_loop">[docs]</a>    <span class="k">def</span> <span class="nf">build_loop</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">progress</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Build simulation loop.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        progress : `.utils.ProgressBar`</span>
<span class="sd">            Progress bar for loop construction</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">def</span> <span class="nf">loop_condition</span><span class="p">(</span><span class="n">step</span><span class="p">,</span> <span class="n">stop</span><span class="p">,</span> <span class="o">*</span><span class="n">_</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">step</span> <span class="o">&lt;</span> <span class="n">stop</span>

        <span class="k">def</span> <span class="nf">loop_body</span><span class="p">(</span><span class="n">step</span><span class="p">,</span> <span class="n">stop</span><span class="p">,</span> <span class="n">loop_i</span><span class="p">,</span> <span class="n">probe_arrays</span><span class="p">,</span> <span class="n">base_vars</span><span class="p">):</span>
            <span class="c1"># fill in signals.bases (note: we need to do this here because we</span>
            <span class="c1"># need to use the versions of the base vars from inside the</span>
            <span class="c1"># loop, not the static variables in self.base_vars)</span>
            <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">signals</span><span class="o">.</span><span class="n">bases</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span>
            <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">key</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">itertools</span><span class="o">.</span><span class="n">chain</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">base_vars</span><span class="o">.</span><span class="n">keys</span><span class="p">(),</span> <span class="bp">self</span><span class="o">.</span><span class="n">signals</span><span class="o">.</span><span class="n">internal_vars</span><span class="o">.</span><span class="n">keys</span><span class="p">())):</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">signals</span><span class="o">.</span><span class="n">bases</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">base_vars</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>

            <span class="k">for</span> <span class="nb">iter</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">unroll</span><span class="p">):</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot;BUILDING ITERATION </span><span class="si">%d</span><span class="s2">&quot;</span><span class="p">,</span> <span class="nb">iter</span><span class="p">)</span>
                <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="s2">&quot;iteration_</span><span class="si">%d</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="nb">iter</span><span class="p">):</span>
                    <span class="c1"># note: nengo step counter is incremented at the beginning</span>
                    <span class="c1"># of the timestep</span>
                    <span class="n">step</span> <span class="o">+=</span> <span class="mi">1</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">signals</span><span class="o">.</span><span class="n">step</span> <span class="o">=</span> <span class="n">step</span>

                    <span class="c1"># fill in invariant input data</span>
                    <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_ph</span><span class="p">:</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">signals</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span>
                            <span class="bp">self</span><span class="o">.</span><span class="n">signals</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">sig</span><span class="p">[</span><span class="n">n</span><span class="p">][</span><span class="s2">&quot;out&quot;</span><span class="p">]],</span>
                            <span class="bp">self</span><span class="o">.</span><span class="n">input_ph</span><span class="p">[</span><span class="n">n</span><span class="p">][</span><span class="n">loop_i</span><span class="p">])</span>

                    <span class="c1"># build the operators for a single step</span>
                    <span class="c1"># note: we tie things to the `loop_i` variable so that we</span>
                    <span class="c1"># can be sure the other things we&#39;re tying to the</span>
                    <span class="c1"># simulation step (side effects and probes) from the</span>
                    <span class="c1"># previous timestep are executed before the next step</span>
                    <span class="c1"># starts</span>
                    <span class="c1"># note2: we use the variable scope to make sure that we</span>
                    <span class="c1"># aren&#39;t accidentally creating new variables for</span>
                    <span class="c1"># unrolled iterations (this is really only a concern</span>
                    <span class="c1"># with TensorNodes)</span>
                    <span class="n">scope</span> <span class="o">=</span> <span class="n">tf_compat</span><span class="o">.</span><span class="n">variable_scope</span><span class="p">(</span>
                        <span class="n">tf_compat</span><span class="o">.</span><span class="n">get_variable_scope</span><span class="p">(),</span>
                        <span class="n">reuse</span><span class="o">=</span><span class="nb">iter</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span>
                    <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">control_dependencies</span><span class="p">([</span><span class="n">loop_i</span><span class="p">]),</span> <span class="n">scope</span><span class="p">:</span>
                        <span class="n">probe_tensors</span><span class="p">,</span> <span class="n">side_effects</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">build_step</span><span class="p">(</span><span class="n">progress</span><span class="p">)</span>

                    <span class="c1"># copy probe data to array</span>
                    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">p</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">probe_tensors</span><span class="p">):</span>
                        <span class="k">if</span> <span class="n">config</span><span class="o">.</span><span class="n">get_setting</span><span class="p">(</span>
                                <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s2">&quot;keep_history&quot;</span><span class="p">,</span>
                                <span class="n">default</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">obj</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">probes</span><span class="p">[</span><span class="n">i</span><span class="p">]):</span>
                            <span class="n">probe_arrays</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">probe_arrays</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">loop_i</span><span class="p">,</span> <span class="n">p</span><span class="p">)</span>
                        <span class="k">else</span><span class="p">:</span>
                            <span class="n">probe_arrays</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">cond</span><span class="p">(</span>
                                <span class="n">pred</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">equal</span><span class="p">(</span><span class="n">step</span><span class="p">,</span> <span class="n">stop</span><span class="p">),</span>
                                <span class="n">true_fn</span><span class="o">=</span><span class="k">lambda</span> <span class="n">p</span><span class="o">=</span><span class="n">p</span><span class="p">:</span> <span class="n">probe_arrays</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span>
                                                                          <span class="n">p</span><span class="p">),</span>
                                <span class="n">false_fn</span><span class="o">=</span><span class="k">lambda</span><span class="p">:</span> <span class="n">probe_arrays</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>

                    <span class="c1"># need to make sure that any operators that could have side</span>
                    <span class="c1"># effects run each timestep, so we tie them to the loop</span>
                    <span class="c1"># increment. we also need to make sure that all the probe</span>
                    <span class="c1"># reads happen before those values get overwritten on the</span>
                    <span class="c1"># next timestep</span>
                    <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">control_dependencies</span><span class="p">(</span><span class="n">side_effects</span>
                                                         <span class="o">+</span> <span class="n">probe_tensors</span><span class="p">):</span>
                        <span class="n">loop_i</span> <span class="o">+=</span> <span class="mi">1</span>

            <span class="n">base_vars</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">signals</span><span class="o">.</span><span class="n">bases</span><span class="o">.</span><span class="n">values</span><span class="p">())</span>

            <span class="k">return</span> <span class="n">step</span><span class="p">,</span> <span class="n">stop</span><span class="p">,</span> <span class="n">loop_i</span><span class="p">,</span> <span class="n">probe_arrays</span><span class="p">,</span> <span class="n">base_vars</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">step_var</span> <span class="o">=</span> <span class="n">tf_compat</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(),</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;step&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">stop_var</span> <span class="o">=</span> <span class="n">tf_compat</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(),</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;stop&quot;</span><span class="p">)</span>
        <span class="n">loop_i</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

        <span class="n">probe_arrays</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">tf</span><span class="o">.</span><span class="n">TensorArray</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">clear_after_read</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                <span class="n">dynamic_size</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">probes</span><span class="p">]</span>

        <span class="c1"># build simulation loop</span>
        <span class="n">loop_vars</span> <span class="o">=</span> <span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">step_var</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">stop_var</span><span class="p">,</span> <span class="n">loop_i</span><span class="p">,</span> <span class="n">probe_arrays</span><span class="p">,</span>
            <span class="nb">tuple</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">_ref</span><span class="p">()</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">)</span> <span class="k">else</span> <span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
                  <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">base_vars</span><span class="o">.</span><span class="n">values</span><span class="p">())</span>
            <span class="o">+</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">_ref</span><span class="p">()</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">signals</span><span class="o">.</span><span class="n">internal_vars</span><span class="o">.</span><span class="n">values</span><span class="p">()))</span>

        <span class="n">loop_vars</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">while_loop</span><span class="p">(</span>
            <span class="n">cond</span><span class="o">=</span><span class="n">loop_condition</span><span class="p">,</span> <span class="n">body</span><span class="o">=</span><span class="n">loop_body</span><span class="p">,</span> <span class="n">loop_vars</span><span class="o">=</span><span class="n">loop_vars</span><span class="p">,</span>
            <span class="n">parallel_iterations</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">back_prop</span><span class="o">=</span><span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">inference_only</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">steps_run</span> <span class="o">=</span> <span class="n">loop_vars</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">probe_arrays</span> <span class="o">=</span> <span class="n">OrderedDict</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">p</span><span class="p">,</span> <span class="n">a</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">probes</span><span class="p">,</span> <span class="n">loop_vars</span><span class="p">[</span><span class="mi">3</span><span class="p">]):</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">stack</span><span class="p">()</span>

            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">sig</span><span class="p">[</span><span class="n">p</span><span class="p">][</span><span class="s2">&quot;in&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">minibatched</span><span class="p">:</span>
                <span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span>
                    <span class="n">a</span><span class="o">=</span><span class="n">x</span><span class="p">,</span>
                    <span class="n">perm</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">roll</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">get_shape</span><span class="p">()</span><span class="o">.</span><span class="n">ndims</span><span class="p">),</span> <span class="mi">1</span><span class="p">))</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">probe_arrays</span><span class="p">[</span><span class="n">p</span><span class="p">]</span> <span class="o">=</span> <span class="n">x</span></div>

<div class="viewcode-block" id="TensorGraph.build_inputs"><a class="viewcode-back" href="../../reference.html#nengo_dl.tensor_graph.TensorGraph.build_inputs">[docs]</a>    <span class="k">def</span> <span class="nf">build_inputs</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">progress</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Sets up the inputs in the model (which will be computed outside of</span>
<span class="sd">        TensorFlow and fed in each simulation block).</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        progress : `.utils.ProgressBar`</span>
<span class="sd">            Progress bar for input construction</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">input_ph</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="n">progress</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">invariant_inputs</span><span class="p">):</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">sig</span><span class="p">[</span><span class="n">n</span><span class="p">][</span><span class="s2">&quot;out&quot;</span><span class="p">]</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">signals</span><span class="p">:</span>
                <span class="c1"># set up a placeholder input for this node</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">input_ph</span><span class="p">[</span><span class="n">n</span><span class="p">]</span> <span class="o">=</span> <span class="n">tf_compat</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">n</span><span class="o">.</span><span class="n">size_out</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">minibatch_size</span><span class="p">),</span>
                    <span class="n">name</span><span class="o">=</span><span class="s2">&quot;</span><span class="si">%s</span><span class="s2">_ph&quot;</span> <span class="o">%</span> <span class="n">utils</span><span class="o">.</span><span class="n">sanitize_name</span><span class="p">(</span><span class="n">n</span><span class="p">))</span></div>

<div class="viewcode-block" id="TensorGraph.build_optimizer_func"><a class="viewcode-back" href="../../reference.html#nengo_dl.tensor_graph.TensorGraph.build_optimizer_func">[docs]</a>    <span class="k">def</span> <span class="nf">build_optimizer_func</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">objective</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Adds elements into the graph to execute the given optimizer.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        optimizer : ``tf.train.Optimizer``</span>
<span class="sd">            Instance of a TensorFlow optimizer class</span>
<span class="sd">        objective : dict of {`~nengo.Probe`: callable or ``None``}</span>
<span class="sd">            The objective to be minimized. This is a dictionary mapping Probes</span>
<span class="sd">            to functions</span>
<span class="sd">            ``f(output, target) -&gt; loss`` that consume the actual output and</span>
<span class="sd">            target output for the given probe(s) and return a ``tf.Tensor``</span>
<span class="sd">            representing a scalar loss value.  The function may also accept a</span>
<span class="sd">            single argument ``f(output) -&gt; loss`` if targets are not required.</span>
<span class="sd">            Some common objective functions can be found in</span>
<span class="sd">            `nengo_dl.objectives`.</span>

<span class="sd">            Passing ``None`` as the probe value (instead of a callable)</span>
<span class="sd">            indicates that the error is being computed outside the simulation,</span>
<span class="sd">            and the value passed for that probe in ``data`` directly specifies</span>
<span class="sd">            the output error gradient.</span>

<span class="sd">            If multiple probes are specified as the key, then the corresponding</span>
<span class="sd">            output/target values will be passed as a list to the objective</span>
<span class="sd">            function.</span>

<span class="sd">            The overall loss value being minimized will be the sum across all</span>
<span class="sd">            the objectives specified.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        apply_optimizer : callable</span>
<span class="sd">            A function that builds the operators required to implement the</span>
<span class="sd">            given optimizer update.  Generally this function will then be</span>
<span class="sd">            passed to `~.build_outputs`.</span>

<span class="sd">        Notes</span>
<span class="sd">        -----</span>
<span class="sd">        This function caches its outputs, so if it is called again with the</span>
<span class="sd">        same arguments then it will return the previous function.  This avoids</span>
<span class="sd">        building duplicates of the same operations over and over.  This can</span>
<span class="sd">        also be important functionally, e.g. if the optimizer has internal</span>
<span class="sd">        state like momentum.  By caching the output we ensure that subsequent</span>
<span class="sd">        calls share the same internal state.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">key</span> <span class="o">=</span> <span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="nb">frozenset</span><span class="p">(</span><span class="n">objective</span><span class="o">.</span><span class="n">items</span><span class="p">()))</span>

        <span class="k">try</span><span class="p">:</span>
            <span class="c1"># return the cached optimizer function if it exists</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimizers</span><span class="p">[</span><span class="n">key</span><span class="p">]</span>
        <span class="k">except</span> <span class="ne">KeyError</span><span class="p">:</span>
            <span class="k">pass</span>

        <span class="c1"># note: the standard workflow is that sim.train calls</span>
        <span class="c1"># build_optimizer_func to get this function. it then passes the</span>
        <span class="c1"># function to run_batch, which calls build_outputs to actually</span>
        <span class="c1"># build these operations into the graph. we do this somewhat</span>
        <span class="c1"># indirect method so that everything passes through build_output,</span>
        <span class="c1"># allowing us to consolidate certain logic there (like capturing</span>
        <span class="c1"># new variables)</span>
        <span class="k">def</span> <span class="nf">apply_optimizer</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">):</span>
            <span class="c1"># note: we don&#39;t actually use outputs/targets, because the same</span>
            <span class="c1"># data is pulled implicitly from `objective` below.</span>
            <span class="c1"># we just check that outputs and targets match up with</span>
            <span class="c1"># objective, to make sure there&#39;s nothing weird going on.</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">):</span>
                <span class="n">outputs</span> <span class="o">=</span> <span class="p">(</span><span class="n">outputs</span><span class="p">,)</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">targets</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">):</span>
                <span class="n">targets</span> <span class="o">=</span> <span class="p">(</span><span class="n">targets</span><span class="p">,)</span>
            <span class="k">assert</span> <span class="nb">set</span><span class="p">(</span><span class="n">outputs</span><span class="p">)</span> <span class="o">==</span> <span class="nb">set</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">probe_arrays</span><span class="p">[</span><span class="n">p</span><span class="p">]</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">objective</span><span class="p">)</span>
            <span class="k">assert</span> <span class="nb">set</span><span class="p">(</span><span class="n">targets</span><span class="p">)</span> <span class="o">==</span> <span class="nb">set</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">target_phs</span><span class="p">[</span><span class="n">p</span><span class="p">]</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">objective</span><span class="p">)</span>

            <span class="n">agg_method</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">AggregationMethod</span><span class="o">.</span><span class="n">DEFAULT</span>
            <span class="n">grads</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="nb">vars</span> <span class="o">=</span> <span class="n">tf_compat</span><span class="o">.</span><span class="n">trainable_variables</span><span class="p">()</span>

            <span class="c1"># compute loss</span>
            <span class="c1"># note: we drop the `None` items in objective, because we</span>
            <span class="c1"># want to treat those as direct gradients (rather than</span>
            <span class="c1"># returning the probe value, which is the standard behaviour for</span>
            <span class="c1"># build_outputs)</span>
            <span class="n">loss</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">build_outputs</span><span class="p">(</span>
                <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">v</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">objective</span><span class="o">.</span><span class="n">items</span><span class="p">()</span> <span class="k">if</span> <span class="n">v</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">})</span>

            <span class="c1"># compute gradients wrt loss</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="c1"># reduce loss to a scalar</span>
                <span class="n">loss</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span>
                    <span class="n">input_tensor</span><span class="o">=</span><span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">input_tensor</span><span class="o">=</span><span class="n">v</span><span class="p">)</span>
                                  <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">loss</span><span class="o">.</span><span class="n">values</span><span class="p">()])</span>

                <span class="n">grads</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">gradients</span><span class="p">(</span>
                    <span class="n">ys</span><span class="o">=</span><span class="n">loss</span><span class="p">,</span> <span class="n">xs</span><span class="o">=</span><span class="nb">vars</span><span class="p">,</span> <span class="n">aggregation_method</span><span class="o">=</span><span class="n">agg_method</span><span class="p">))</span>

            <span class="c1"># add in any gradients where the user directly specified the output</span>
            <span class="c1"># error grad</span>
            <span class="k">for</span> <span class="n">p</span><span class="p">,</span> <span class="n">g</span> <span class="ow">in</span> <span class="n">objective</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                <span class="k">if</span> <span class="n">g</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">grads</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">gradients</span><span class="p">(</span>
                        <span class="n">ys</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">probe_arrays</span><span class="p">[</span><span class="n">p</span><span class="p">],</span> <span class="n">xs</span><span class="o">=</span><span class="nb">vars</span><span class="p">,</span>
                        <span class="n">grad_ys</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">target_phs</span><span class="p">[</span><span class="n">p</span><span class="p">],</span>
                        <span class="n">aggregation_method</span><span class="o">=</span><span class="n">agg_method</span><span class="p">))</span>

            <span class="c1"># combine gradients for each variable</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">grads</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                <span class="n">grads</span> <span class="o">=</span> <span class="n">grads</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">grads</span> <span class="o">=</span> <span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">input_tensor</span><span class="o">=</span><span class="n">gs</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
                         <span class="k">for</span> <span class="n">gs</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="n">grads</span><span class="p">)]</span>

            <span class="n">opt_op</span> <span class="o">=</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">apply_gradients</span><span class="p">(</span>
                <span class="nb">zip</span><span class="p">(</span><span class="n">grads</span><span class="p">,</span> <span class="n">tf_compat</span><span class="o">.</span><span class="n">trainable_variables</span><span class="p">()))</span>

            <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">control_dependencies</span><span class="p">([</span><span class="n">opt_op</span><span class="p">]):</span>
                <span class="n">new_step</span> <span class="o">=</span> <span class="n">tf_compat</span><span class="o">.</span><span class="n">assign_add</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">training_step</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">int64</span><span class="p">))</span>

            <span class="k">return</span> <span class="n">new_step</span><span class="p">,</span> <span class="n">loss</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">optimizers</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">apply_optimizer</span>

        <span class="k">return</span> <span class="n">apply_optimizer</span></div>

<div class="viewcode-block" id="TensorGraph.build_outputs"><a class="viewcode-back" href="../../reference.html#nengo_dl.tensor_graph.TensorGraph.build_outputs">[docs]</a>    <span class="nd">@with_self</span>
    <span class="k">def</span> <span class="nf">build_outputs</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">outputs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Adds elements into the graph to compute the given outputs.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        outputs : dict of {(tuple of) `~nengo.Probe`: callable or None}</span>
<span class="sd">            The output function to be applied to each probe or group of probes.</span>
<span class="sd">            The function can accept one argument (the output of that probe) or</span>
<span class="sd">            two (output and target values for that probe).  If a tuple of</span>
<span class="sd">            Probes are given as the key, then those output/target parameters</span>
<span class="sd">            will be the corresponding tuple of probe/target values.  The</span>
<span class="sd">            function should return a ``tf.Tensor`` or tuple of Tensors</span>
<span class="sd">            representing the output we want from those probes.  If ``None`` is</span>
<span class="sd">            given instead of a function then the output will simply be the</span>
<span class="sd">            output value from the corresponding probes.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        output_vals : dict of {(tuple of) `~nengo.Probe`: \</span>
<span class="sd">                               (tuple of) ``tf.Tensor``}</span>
<span class="sd">            Tensors representing the result of applying the output functions</span>
<span class="sd">            to the probes.</span>
<span class="sd">        new_vars_init : ``tf.Tensor`` or None</span>
<span class="sd">            Initialization op for any new variables created when building</span>
<span class="sd">            the outputs.</span>

<span class="sd">        Notes</span>
<span class="sd">        -----</span>
<span class="sd">        This function caches its outputs, so if it is called again with the</span>
<span class="sd">        same arguments then it will return the previous Tensors.  This avoids</span>
<span class="sd">        building duplicates of the same operations over and over.  This can</span>
<span class="sd">        also be important functionally, e.g. if the outputs have internal</span>
<span class="sd">        state.  By caching the output we ensure that subsequent</span>
<span class="sd">        calls share the same internal state.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">key</span> <span class="o">=</span> <span class="nb">frozenset</span><span class="p">(</span><span class="n">outputs</span><span class="o">.</span><span class="n">items</span><span class="p">())</span>

        <span class="k">try</span><span class="p">:</span>
            <span class="c1"># return the cached outputs if they exist</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">outputs</span><span class="p">[</span><span class="n">key</span><span class="p">],</span> <span class="kc">None</span>
        <span class="k">except</span> <span class="ne">KeyError</span><span class="p">:</span>
            <span class="k">pass</span>

        <span class="n">output_vals</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="n">new_vars</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">probes</span><span class="p">,</span> <span class="n">out</span> <span class="ow">in</span> <span class="n">outputs</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="n">is_tuple</span> <span class="o">=</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">probes</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)</span>
            <span class="n">probe_arrays</span> <span class="o">=</span> <span class="p">(</span>
                <span class="nb">tuple</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">probe_arrays</span><span class="p">[</span><span class="n">p</span><span class="p">]</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">probes</span><span class="p">)</span> <span class="k">if</span> <span class="n">is_tuple</span> <span class="k">else</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">probe_arrays</span><span class="p">[</span><span class="n">probes</span><span class="p">])</span>

            <span class="k">if</span> <span class="n">out</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="c1"># return probe output value</span>
                <span class="n">output_vals</span><span class="p">[</span><span class="n">probes</span><span class="p">]</span> <span class="o">=</span> <span class="n">probe_arrays</span>
            <span class="k">elif</span> <span class="n">callable</span><span class="p">(</span><span class="n">out</span><span class="p">):</span>
                <span class="c1"># look up number of arguments for function</span>
                <span class="n">spec</span> <span class="o">=</span> <span class="n">inspect</span><span class="o">.</span><span class="n">getfullargspec</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
                <span class="n">nargs</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">spec</span><span class="o">.</span><span class="n">args</span><span class="p">)</span>

                <span class="c1"># don&#39;t count keyword arguments</span>
                <span class="k">if</span> <span class="n">spec</span><span class="o">.</span><span class="n">defaults</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">nargs</span> <span class="o">-=</span> <span class="nb">len</span><span class="p">(</span><span class="n">spec</span><span class="o">.</span><span class="n">defaults</span><span class="p">)</span>

                <span class="c1"># don&#39;t count self argument for methods or callable classes</span>
                <span class="n">out_func</span> <span class="o">=</span> <span class="p">(</span><span class="n">out</span><span class="o">.</span><span class="n">func</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="n">functools</span><span class="o">.</span><span class="n">partial</span><span class="p">)</span>
                            <span class="k">else</span> <span class="n">out</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">inspect</span><span class="o">.</span><span class="n">ismethod</span><span class="p">(</span><span class="n">out_func</span><span class="p">)</span> <span class="ow">or</span> <span class="ow">not</span> <span class="n">inspect</span><span class="o">.</span><span class="n">isroutine</span><span class="p">(</span>
                        <span class="n">out_func</span><span class="p">):</span>
                    <span class="n">nargs</span> <span class="o">-=</span> <span class="mi">1</span>

                <span class="c1"># build function arguments</span>
                <span class="k">if</span> <span class="n">nargs</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                    <span class="n">args</span> <span class="o">=</span> <span class="p">[</span><span class="n">probe_arrays</span><span class="p">]</span>
                <span class="k">elif</span> <span class="n">nargs</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
                    <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">probes</span> <span class="k">if</span> <span class="n">is_tuple</span> <span class="k">else</span> <span class="p">(</span><span class="n">probes</span><span class="p">,):</span>
                        <span class="c1"># create a placeholder for the target values if one</span>
                        <span class="c1"># hasn&#39;t been created yet</span>
                        <span class="k">if</span> <span class="n">p</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">target_phs</span><span class="p">:</span>
                            <span class="bp">self</span><span class="o">.</span><span class="n">target_phs</span><span class="p">[</span><span class="n">p</span><span class="p">]</span> <span class="o">=</span> <span class="n">tf_compat</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span>
                                <span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
                                <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">minibatch_size</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">size_in</span><span class="p">),</span>
                                <span class="n">name</span><span class="o">=</span><span class="s2">&quot;</span><span class="si">%s</span><span class="s2">_ph&quot;</span> <span class="o">%</span> <span class="n">utils</span><span class="o">.</span><span class="n">sanitize_name</span><span class="p">(</span><span class="n">p</span><span class="p">))</span>
                    <span class="n">target_phs</span> <span class="o">=</span> <span class="p">(</span><span class="nb">tuple</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">target_phs</span><span class="p">[</span><span class="n">p</span><span class="p">]</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">probes</span><span class="p">)</span>
                                  <span class="k">if</span> <span class="n">is_tuple</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">target_phs</span><span class="p">[</span><span class="n">probes</span><span class="p">])</span>
                    <span class="n">args</span> <span class="o">=</span> <span class="p">[</span><span class="n">probe_arrays</span><span class="p">,</span> <span class="n">target_phs</span><span class="p">]</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="n">ValidationError</span><span class="p">(</span>
                        <span class="s2">&quot;Output functions must accept 1 or 2 arguments; &#39;</span><span class="si">%s</span><span class="s2">&#39; &quot;</span>
                        <span class="s2">&quot;takes </span><span class="si">%s</span><span class="s2"> arguments&quot;</span> <span class="o">%</span> <span class="p">(</span>
                            <span class="n">utils</span><span class="o">.</span><span class="n">function_name</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="n">sanitize</span><span class="o">=</span><span class="kc">False</span><span class="p">),</span> <span class="n">nargs</span><span class="p">),</span>
                        <span class="s2">&quot;outputs&quot;</span><span class="p">)</span>

                <span class="c1"># apply output function</span>
                <span class="k">with</span> <span class="n">tf_compat</span><span class="o">.</span><span class="n">variable_scope</span><span class="p">(</span>
                        <span class="n">utils</span><span class="o">.</span><span class="n">function_name</span><span class="p">(</span><span class="n">out</span><span class="p">))</span> <span class="k">as</span> <span class="n">scope</span><span class="p">:</span>
                    <span class="n">output_vals</span><span class="p">[</span><span class="n">probes</span><span class="p">]</span> <span class="o">=</span> <span class="n">out</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">)</span>

                <span class="c1"># collect any new variables from building the outputs</span>
                <span class="k">for</span> <span class="n">collection</span> <span class="ow">in</span> <span class="p">[</span><span class="n">tf_compat</span><span class="o">.</span><span class="n">GraphKeys</span><span class="o">.</span><span class="n">GLOBAL_VARIABLES</span><span class="p">,</span>
                                   <span class="n">tf_compat</span><span class="o">.</span><span class="n">GraphKeys</span><span class="o">.</span><span class="n">LOCAL_VARIABLES</span><span class="p">,</span>
                                   <span class="s2">&quot;gradient_vars&quot;</span><span class="p">]:</span>
                    <span class="n">new_vars</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">scope</span><span class="o">.</span><span class="n">get_collection</span><span class="p">(</span><span class="n">collection</span><span class="p">))</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="n">ValidationError</span><span class="p">(</span><span class="s2">&quot;Outputs must be callable or None)&quot;</span><span class="p">,</span>
                                      <span class="s2">&quot;outputs&quot;</span><span class="p">)</span>

        <span class="n">new_vars_init</span> <span class="o">=</span> <span class="p">(</span><span class="n">tf_compat</span><span class="o">.</span><span class="n">variables_initializer</span><span class="p">(</span><span class="n">new_vars</span><span class="p">)</span>
                         <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">new_vars</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="kc">None</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">outputs</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">output_vals</span>

        <span class="k">return</span> <span class="n">output_vals</span><span class="p">,</span> <span class="n">new_vars_init</span></div>

<div class="viewcode-block" id="TensorGraph.build_post"><a class="viewcode-back" href="../../reference.html#nengo_dl.tensor_graph.TensorGraph.build_post">[docs]</a>    <span class="nd">@with_self</span>
    <span class="k">def</span> <span class="nf">build_post</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sess</span><span class="p">,</span> <span class="n">rng</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Executes post-build processes for operators (after the graph has</span>
<span class="sd">        been constructed and session/variables initialized).</span>

<span class="sd">        Note that unlike other build functions, this is called every time</span>
<span class="sd">        the simulator is reset.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        sess : ``tf.Session``</span>
<span class="sd">            The TensorFlow session for the simulator</span>
<span class="sd">        rng : `~numpy.random.RandomState`</span>
<span class="sd">            Seeded random number generator</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c1"># build input functions (we need to do this here, because in the case</span>
        <span class="c1"># of processes these functions depend on the rng, and need to be be</span>
        <span class="c1"># rebuilt on reset)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">input_funcs</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="n">n</span><span class="p">,</span> <span class="n">output</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">invariant_inputs</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">input_funcs</span><span class="p">[</span><span class="n">n</span><span class="p">]</span> <span class="o">=</span> <span class="n">output</span>
            <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">Process</span><span class="p">):</span>
                <span class="n">state</span> <span class="o">=</span> <span class="n">make_process_state</span><span class="p">(</span>
                    <span class="n">output</span><span class="p">,</span> <span class="p">(</span><span class="n">n</span><span class="o">.</span><span class="n">size_in</span><span class="p">,),</span> <span class="p">(</span><span class="n">n</span><span class="o">.</span><span class="n">size_out</span><span class="p">,),</span> <span class="bp">self</span><span class="o">.</span><span class="n">dt</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">input_funcs</span><span class="p">[</span><span class="n">n</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span>
                    <span class="n">make_process_step</span><span class="p">(</span>
                        <span class="n">output</span><span class="p">,</span>
                        <span class="p">(</span><span class="n">n</span><span class="o">.</span><span class="n">size_in</span><span class="p">,),</span> <span class="p">(</span><span class="n">n</span><span class="o">.</span><span class="n">size_out</span><span class="p">,),</span> <span class="bp">self</span><span class="o">.</span><span class="n">dt</span><span class="p">,</span>
                        <span class="n">output</span><span class="o">.</span><span class="n">get_rng</span><span class="p">(</span><span class="n">rng</span><span class="p">),</span> <span class="n">state</span><span class="p">)</span>
                    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">minibatch_size</span><span class="p">)]</span>
            <span class="k">elif</span> <span class="n">n</span><span class="o">.</span><span class="n">size_out</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">input_funcs</span><span class="p">[</span><span class="n">n</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span>
                    <span class="n">utils</span><span class="o">.</span><span class="n">align_func</span><span class="p">((</span><span class="n">n</span><span class="o">.</span><span class="n">size_out</span><span class="p">,),</span> <span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">)(</span><span class="n">output</span><span class="p">)]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># a node with no inputs and no outputs, but it can still</span>
                <span class="c1"># have side effects</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">input_funcs</span><span class="p">[</span><span class="n">n</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">output</span><span class="p">]</span>

        <span class="c1"># execute post_build on all the op builders</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">op_builder</span><span class="o">.</span><span class="n">post_build</span><span class="p">(</span><span class="n">sess</span><span class="p">,</span> <span class="n">rng</span><span class="p">)</span></div>

<div class="viewcode-block" id="TensorGraph.build_summaries"><a class="viewcode-back" href="../../reference.html#nengo_dl.tensor_graph.TensorGraph.build_summaries">[docs]</a>    <span class="nd">@with_self</span>
    <span class="k">def</span> <span class="nf">build_summaries</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">summaries</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Adds ops to collect summary data for the given objects.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        summaries : list of dict or \</span>
<span class="sd">                            `~nengo.Connection` or \</span>
<span class="sd">                            `~nengo.Ensemble` or \</span>
<span class="sd">                            `~nengo.ensemble.Neurons` or \</span>
<span class="sd">                            ``tf.Tensor``}</span>
<span class="sd">            List of objects for which we want to collect data.  Object can be a</span>
<span class="sd">            Connection (in which case data on weights will be collected),</span>
<span class="sd">            Ensemble (encoders), Neurons (biases), a dict of</span>
<span class="sd">            ``{probe: objective}`` that indicates a loss function that will</span>
<span class="sd">            be tracked, or a pre-built summary tensor.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        op : ``tf.Tensor``</span>
<span class="sd">            Merged summary op for the given summaries</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">summary_ops</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">inits</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;/cpu:0&quot;</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">obj</span> <span class="ow">in</span> <span class="n">summaries</span><span class="p">:</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
                    <span class="c1"># overall loss</span>
                    <span class="n">loss</span><span class="p">,</span> <span class="n">init</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">build_outputs</span><span class="p">(</span><span class="n">obj</span><span class="p">)</span>
                    <span class="k">if</span> <span class="n">init</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                        <span class="n">inits</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">init</span><span class="p">)</span>
                    <span class="n">summary_ops</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">tf_compat</span><span class="o">.</span><span class="n">summary</span><span class="o">.</span><span class="n">scalar</span><span class="p">(</span>
                        <span class="s2">&quot;loss&quot;</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span>
                            <span class="n">input_tensor</span><span class="o">=</span><span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">input_tensor</span><span class="o">=</span><span class="n">v</span><span class="p">)</span>
                                          <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">loss</span><span class="o">.</span><span class="n">values</span><span class="p">()]),</span>
                        <span class="n">family</span><span class="o">=</span><span class="s2">&quot;loss&quot;</span><span class="p">))</span>

                    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">obj</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
                        <span class="c1"># get loss for each probe</span>
                        <span class="k">for</span> <span class="n">p</span><span class="p">,</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">loss</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                            <span class="n">summary_ops</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">tf_compat</span><span class="o">.</span><span class="n">summary</span><span class="o">.</span><span class="n">scalar</span><span class="p">(</span>
                                <span class="n">utils</span><span class="o">.</span><span class="n">sanitize_name</span><span class="p">(</span><span class="s2">&quot;Probe_</span><span class="si">%s</span><span class="s2">_loss&quot;</span> <span class="o">%</span> <span class="n">p</span><span class="o">.</span><span class="n">label</span><span class="p">),</span>
                                <span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">input_tensor</span><span class="o">=</span><span class="n">t</span><span class="p">),</span> <span class="n">family</span><span class="o">=</span><span class="s2">&quot;loss&quot;</span><span class="p">))</span>
                <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="p">(</span><span class="n">Ensemble</span><span class="p">,</span> <span class="n">Neurons</span><span class="p">,</span> <span class="n">Connection</span><span class="p">)):</span>
                    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="n">Ensemble</span><span class="p">):</span>
                        <span class="n">param</span> <span class="o">=</span> <span class="s2">&quot;encoders&quot;</span>
                        <span class="n">name</span> <span class="o">=</span> <span class="s2">&quot;Ensemble_</span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">obj</span><span class="o">.</span><span class="n">label</span>
                    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="n">Neurons</span><span class="p">):</span>
                        <span class="n">param</span> <span class="o">=</span> <span class="s2">&quot;bias&quot;</span>
                        <span class="n">name</span> <span class="o">=</span> <span class="s2">&quot;Ensemble.neurons_</span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">obj</span><span class="o">.</span><span class="n">ensemble</span><span class="o">.</span><span class="n">label</span>
                    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="n">Connection</span><span class="p">):</span>
                        <span class="n">param</span> <span class="o">=</span> <span class="s2">&quot;weights&quot;</span>
                        <span class="n">name</span> <span class="o">=</span> <span class="s2">&quot;Connection_</span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">obj</span><span class="o">.</span><span class="n">label</span>

                    <span class="n">summary_ops</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">tf_compat</span><span class="o">.</span><span class="n">summary</span><span class="o">.</span><span class="n">histogram</span><span class="p">(</span>
                        <span class="n">utils</span><span class="o">.</span><span class="n">sanitize_name</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">%s</span><span class="s2">_</span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">param</span><span class="p">)),</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">get_tensor</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">sig</span><span class="p">[</span><span class="n">obj</span><span class="p">][</span><span class="n">param</span><span class="p">])))</span>
                <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
                    <span class="c1"># we assume that obj is a summary op</span>
                    <span class="n">summary_ops</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">obj</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="n">SimulationError</span><span class="p">(</span>
                        <span class="s2">&quot;Unknown summary object: </span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">obj</span><span class="p">)</span>

            <span class="k">return</span> <span class="n">tf_compat</span><span class="o">.</span><span class="n">summary</span><span class="o">.</span><span class="n">merge</span><span class="p">(</span><span class="n">summary_ops</span><span class="p">),</span> <span class="p">(</span>
                <span class="kc">None</span> <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">inits</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span> <span class="k">else</span> <span class="n">inits</span><span class="p">)</span></div>

<div class="viewcode-block" id="TensorGraph.get_tensor"><a class="viewcode-back" href="../../reference.html#nengo_dl.tensor_graph.TensorGraph.get_tensor">[docs]</a>    <span class="nd">@with_self</span>
    <span class="k">def</span> <span class="nf">get_tensor</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sig</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Returns a Tensor corresponding to the given Signal.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        sig : `~nengo.builder.Signal`</span>
<span class="sd">            A signal in the model</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        tensor : ``tf.Tensor``</span>
<span class="sd">            Tensor containing the value of the given Signal</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">tensor_sig</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">signals</span><span class="p">[</span><span class="n">sig</span><span class="p">]</span>

        <span class="n">base</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">base_vars</span><span class="p">[</span><span class="n">tensor_sig</span><span class="o">.</span><span class="n">key</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>

        <span class="k">if</span> <span class="s2">&quot;while/&quot;</span> <span class="ow">in</span> <span class="n">tensor_sig</span><span class="o">.</span><span class="n">tf_indices</span><span class="o">.</span><span class="n">name</span><span class="p">:</span>
            <span class="c1"># rebuild tf indices outside the while loop</span>
            <span class="n">tensor_sig</span><span class="o">.</span><span class="n">_tf_indices</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">gather</span><span class="p">(</span><span class="n">base</span><span class="p">,</span> <span class="n">tensor_sig</span><span class="o">.</span><span class="n">tf_indices</span><span class="p">)</span></div>

<div class="viewcode-block" id="TensorGraph.mark_signals"><a class="viewcode-back" href="../../reference.html#nengo_dl.tensor_graph.TensorGraph.mark_signals">[docs]</a>    <span class="k">def</span> <span class="nf">mark_signals</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Mark all the signals in ``self.model`` according to whether they</span>
<span class="sd">        represent trainable parameters of the model (parameters that can be</span>
<span class="sd">        optimized by deep learning methods).</span>

<span class="sd">        Trainable parameters include connection weights, ensemble encoders, and</span>
<span class="sd">        neuron biases.  Unless one of those signals is targeted by a Nengo</span>
<span class="sd">        learning rule (otherwise the learning rule update conflicts with the</span>
<span class="sd">        deep learning optimization).</span>

<span class="sd">        Users can manually specify whether signals are trainable or not using</span>
<span class="sd">        the config system (e.g.,</span>
<span class="sd">        ``net.config[nengo.Ensemble].trainable = False``)</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">def</span> <span class="nf">get_trainable</span><span class="p">(</span><span class="n">net_config</span><span class="p">,</span> <span class="n">obj</span><span class="p">,</span> <span class="n">network_trainable</span><span class="p">):</span>
            <span class="sd">&quot;&quot;&quot;Looks up the current value of ``obj.trainable``.&quot;&quot;&quot;</span>

            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">inference_only</span><span class="p">:</span>
                <span class="k">return</span> <span class="kc">False</span>

            <span class="k">try</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">obj</span> <span class="ow">in</span> <span class="n">net_config</span><span class="o">.</span><span class="n">params</span><span class="p">:</span>
                    <span class="c1"># priority #1: instance config</span>
                    <span class="n">trainable</span> <span class="o">=</span> <span class="n">net_config</span><span class="p">[</span><span class="n">obj</span><span class="p">]</span><span class="o">.</span><span class="n">trainable</span>
                <span class="k">elif</span> <span class="n">network_trainable</span> <span class="ow">is</span> <span class="ow">not</span> <span class="mi">1</span><span class="p">:</span>  <span class="c1"># noqa: F632</span>
                    <span class="c1"># priority #2: network setting</span>
                    <span class="n">trainable</span> <span class="o">=</span> <span class="n">network_trainable</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="c1"># priority #3: class config</span>
                    <span class="n">trainable</span> <span class="o">=</span> <span class="n">net_config</span><span class="p">[</span><span class="n">obj</span><span class="p">]</span><span class="o">.</span><span class="n">trainable</span>
            <span class="k">except</span> <span class="p">(</span><span class="n">ConfigError</span><span class="p">,</span> <span class="ne">AttributeError</span><span class="p">):</span>
                <span class="n">trainable</span> <span class="o">=</span> <span class="n">network_trainable</span>

            <span class="c1"># we return 1 if trainable isn&#39;t configured, since the default is</span>
            <span class="c1"># for everything to be trainable but we want to be able to</span>
            <span class="c1"># distinguish whether something was specifically set to be</span>
            <span class="c1"># trainable (True) or just defaulting to trainable (1)</span>
            <span class="k">return</span> <span class="mi">1</span> <span class="k">if</span> <span class="n">trainable</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">trainable</span>

        <span class="k">def</span> <span class="nf">mark_network</span><span class="p">(</span><span class="n">net_config</span><span class="p">,</span> <span class="n">net</span><span class="p">,</span> <span class="n">network_trainable</span><span class="p">):</span>
            <span class="sd">&quot;&quot;&quot;Recursively marks the signals for objects within each</span>
<span class="sd">            subnetwork.&quot;&quot;&quot;</span>

            <span class="k">for</span> <span class="n">subnet</span> <span class="ow">in</span> <span class="n">net</span><span class="o">.</span><span class="n">networks</span><span class="p">:</span>
                <span class="n">mark_network</span><span class="p">(</span><span class="n">net_config</span><span class="p">,</span> <span class="n">subnet</span><span class="p">,</span>
                             <span class="n">get_trainable</span><span class="p">(</span><span class="n">net_config</span><span class="p">,</span> <span class="n">subnet</span><span class="p">,</span>
                                           <span class="n">network_trainable</span><span class="p">))</span>

            <span class="c1"># encoders and biases are trainable</span>
            <span class="k">for</span> <span class="n">ens</span> <span class="ow">in</span> <span class="n">net</span><span class="o">.</span><span class="n">ensembles</span><span class="p">:</span>
                <span class="n">ens_trainable</span> <span class="o">=</span> <span class="n">get_trainable</span><span class="p">(</span><span class="n">net_config</span><span class="p">,</span> <span class="n">ens</span><span class="p">,</span>
                                              <span class="n">network_trainable</span><span class="p">)</span>

                <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">sig</span><span class="p">[</span><span class="n">ens</span><span class="p">][</span><span class="s2">&quot;encoders&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">trainable</span> <span class="o">=</span> <span class="n">ens_trainable</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">sig</span><span class="p">[</span><span class="n">ens</span><span class="p">][</span><span class="s2">&quot;encoders&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">minibatched</span> <span class="o">=</span> <span class="kc">False</span>

                <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">ens</span><span class="o">.</span><span class="n">neuron_type</span><span class="p">,</span> <span class="n">Direct</span><span class="p">):</span>
                    <span class="n">neurons_trainable</span> <span class="o">=</span> <span class="n">get_trainable</span><span class="p">(</span><span class="n">net_config</span><span class="p">,</span> <span class="n">ens</span><span class="o">.</span><span class="n">neurons</span><span class="p">,</span>
                                                      <span class="n">network_trainable</span><span class="p">)</span>
                    <span class="k">if</span> <span class="n">neurons_trainable</span> <span class="ow">is</span> <span class="mi">1</span><span class="p">:</span>  <span class="c1"># noqa: F632</span>
                        <span class="n">neurons_trainable</span> <span class="o">=</span> <span class="n">ens_trainable</span>

                    <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">sig</span><span class="p">[</span><span class="n">ens</span><span class="o">.</span><span class="n">neurons</span><span class="p">][</span><span class="s2">&quot;bias&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">trainable</span> <span class="o">=</span> <span class="p">(</span>
                        <span class="n">neurons_trainable</span><span class="p">)</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">sig</span><span class="p">[</span><span class="n">ens</span><span class="o">.</span><span class="n">neurons</span><span class="p">][</span><span class="s2">&quot;bias&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">minibatched</span> <span class="o">=</span> <span class="kc">False</span>

            <span class="c1"># connection weights are trainable</span>
            <span class="k">for</span> <span class="n">conn</span> <span class="ow">in</span> <span class="n">net</span><span class="o">.</span><span class="n">connections</span><span class="p">:</span>
                <span class="c1"># note: this doesn&#39;t include probe connections, since they</span>
                <span class="c1"># aren&#39;t added to the network</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">sig</span><span class="p">[</span><span class="n">conn</span><span class="p">][</span><span class="s2">&quot;weights&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">trainable</span> <span class="o">=</span> <span class="n">get_trainable</span><span class="p">(</span>
                    <span class="n">net_config</span><span class="p">,</span> <span class="n">conn</span><span class="p">,</span> <span class="n">network_trainable</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">sig</span><span class="p">[</span><span class="n">conn</span><span class="p">][</span><span class="s2">&quot;weights&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">minibatched</span> <span class="o">=</span> <span class="kc">False</span>

            <span class="c1"># parameters can&#39;t be modified by an online Nengo learning rule</span>
            <span class="c1"># and offline training at the same time. (it is possible in</span>
            <span class="c1"># theory, but it complicates things a lot and is probably not a</span>
            <span class="c1"># common use case). we also make those signals minibatched</span>
            <span class="c1"># (they wouldn&#39;t be normally), because we want to be able to</span>
            <span class="c1"># learn independently in each minibatch</span>
            <span class="k">for</span> <span class="n">conn</span> <span class="ow">in</span> <span class="n">net</span><span class="o">.</span><span class="n">connections</span><span class="p">:</span>
                <span class="n">rule</span> <span class="o">=</span> <span class="n">conn</span><span class="o">.</span><span class="n">learning_rule</span>
                <span class="k">if</span> <span class="n">rule</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">rule</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
                        <span class="n">rule</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">rule</span><span class="o">.</span><span class="n">values</span><span class="p">())</span>
                    <span class="k">elif</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">rule</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
                        <span class="n">rule</span> <span class="o">=</span> <span class="p">[</span><span class="n">rule</span><span class="p">]</span>

                    <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="n">rule</span><span class="p">:</span>
                        <span class="k">if</span> <span class="n">r</span><span class="o">.</span><span class="n">modifies</span> <span class="ow">in</span> <span class="p">(</span><span class="s2">&quot;weights&quot;</span><span class="p">,</span> <span class="s2">&quot;decoders&quot;</span><span class="p">):</span>
                            <span class="n">obj</span> <span class="o">=</span> <span class="n">conn</span>
                            <span class="n">attr</span> <span class="o">=</span> <span class="s2">&quot;weights&quot;</span>
                        <span class="k">elif</span> <span class="n">r</span><span class="o">.</span><span class="n">modifies</span> <span class="o">==</span> <span class="s2">&quot;encoders&quot;</span><span class="p">:</span>
                            <span class="n">obj</span> <span class="o">=</span> <span class="n">conn</span><span class="o">.</span><span class="n">post_obj</span>
                            <span class="n">attr</span> <span class="o">=</span> <span class="s2">&quot;encoders&quot;</span>
                        <span class="k">else</span><span class="p">:</span>
                            <span class="k">raise</span> <span class="ne">NotImplementedError</span>

                        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">sig</span><span class="p">[</span><span class="n">obj</span><span class="p">][</span><span class="n">attr</span><span class="p">]</span><span class="o">.</span><span class="n">trainable</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
                            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                                <span class="s2">&quot;</span><span class="si">%s</span><span class="s2"> has a learning rule and is also set &quot;</span>
                                <span class="s2">&quot;to be trainable; this is likely to &quot;</span>
                                <span class="s2">&quot;produce strange training behaviour.&quot;</span> <span class="o">%</span>
                                <span class="n">obj</span><span class="p">)</span>
                        <span class="k">else</span><span class="p">:</span>
                            <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">sig</span><span class="p">[</span><span class="n">obj</span><span class="p">][</span><span class="n">attr</span><span class="p">]</span><span class="o">.</span><span class="n">trainable</span> <span class="o">=</span> <span class="kc">False</span>

                        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">sig</span><span class="p">[</span><span class="n">obj</span><span class="p">][</span><span class="n">attr</span><span class="p">]</span><span class="o">.</span><span class="n">minibatched</span> <span class="o">=</span> <span class="kc">True</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">toplevel</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                <span class="s2">&quot;No top-level network in model; assuming no trainable &quot;</span>
                <span class="s2">&quot;parameters&quot;</span><span class="p">,</span> <span class="ne">UserWarning</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">net_config</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">toplevel</span><span class="o">.</span><span class="n">config</span>
            <span class="n">mark_network</span><span class="p">(</span><span class="n">net_config</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">toplevel</span><span class="p">,</span>
                         <span class="n">get_trainable</span><span class="p">(</span><span class="n">net_config</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">toplevel</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>

            <span class="c1"># the connections to connection probes are not trainable, but</span>
            <span class="c1"># also not minibatched</span>
            <span class="n">probe_seeds</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">seeds</span><span class="p">[</span><span class="n">p</span><span class="p">]</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">probes</span><span class="p">]</span>
            <span class="k">for</span> <span class="n">obj</span><span class="p">,</span> <span class="n">seed</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">seeds</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="n">Connection</span><span class="p">)</span> <span class="ow">and</span> <span class="n">seed</span> <span class="ow">in</span> <span class="n">probe_seeds</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">sig</span><span class="p">[</span><span class="n">obj</span><span class="p">][</span><span class="s2">&quot;weights&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">trainable</span> <span class="o">=</span> <span class="kc">False</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">sig</span><span class="p">[</span><span class="n">obj</span><span class="p">][</span><span class="s2">&quot;weights&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">minibatched</span> <span class="o">=</span> <span class="kc">False</span>

        <span class="c1"># fill in defaults for all other signals</span>
        <span class="c1"># signals are not trainable by default, and views take on the</span>
        <span class="c1"># properties of their bases</span>
        <span class="k">for</span> <span class="n">op</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">operators</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">sig</span> <span class="ow">in</span> <span class="n">op</span><span class="o">.</span><span class="n">all_signals</span><span class="p">:</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">sig</span><span class="o">.</span><span class="n">base</span><span class="p">,</span> <span class="s2">&quot;trainable&quot;</span><span class="p">):</span>
                    <span class="n">sig</span><span class="o">.</span><span class="n">base</span><span class="o">.</span><span class="n">trainable</span> <span class="o">=</span> <span class="kc">False</span>

                <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">sig</span><span class="o">.</span><span class="n">base</span><span class="p">,</span> <span class="s2">&quot;minibatched&quot;</span><span class="p">):</span>
                    <span class="n">sig</span><span class="o">.</span><span class="n">base</span><span class="o">.</span><span class="n">minibatched</span> <span class="o">=</span> <span class="ow">not</span> <span class="n">sig</span><span class="o">.</span><span class="n">base</span><span class="o">.</span><span class="n">trainable</span>

                <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">sig</span><span class="p">,</span> <span class="s2">&quot;trainable&quot;</span><span class="p">):</span>
                    <span class="n">sig</span><span class="o">.</span><span class="n">trainable</span> <span class="o">=</span> <span class="n">sig</span><span class="o">.</span><span class="n">base</span><span class="o">.</span><span class="n">trainable</span>

                <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">sig</span><span class="p">,</span> <span class="s2">&quot;minibatched&quot;</span><span class="p">):</span>
                    <span class="n">sig</span><span class="o">.</span><span class="n">minibatched</span> <span class="o">=</span> <span class="n">sig</span><span class="o">.</span><span class="n">base</span><span class="o">.</span><span class="n">minibatched</span></div>

<div class="viewcode-block" id="TensorGraph.create_signals"><a class="viewcode-back" href="../../reference.html#nengo_dl.tensor_graph.TensorGraph.create_signals">[docs]</a>    <span class="k">def</span> <span class="nf">create_signals</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sigs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Groups signal data together into larger arrays, and represent each</span>
<span class="sd">        individual signal as a slice into that array.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        sigs : list of `~nengo.builder.Signal`</span>
<span class="sd">            Base signals arranged into the order in which they should reside in</span>
<span class="sd">            memory (e.g., output from `.graph_optimizer.order_signals`)</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">float_type</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="o">.</span><span class="n">as_numpy_dtype</span>
        <span class="n">base_arrays</span> <span class="o">=</span> <span class="n">OrderedDict</span><span class="p">()</span>
        <span class="n">curr_keys</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="n">sig_idxs</span> <span class="o">=</span> <span class="p">{</span><span class="n">s</span><span class="p">:</span> <span class="n">i</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">s</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">sigs</span><span class="p">)}</span>

        <span class="c1"># find the non-overlapping partitions of the signals</span>
        <span class="n">breaks</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">diff</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">ops</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">plan</span><span class="p">:</span>
            <span class="c1"># note: we don&#39;t include Resets, otherwise the big reset block</span>
            <span class="c1"># overrides most of the partitioning</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">ops</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">Reset</span><span class="p">):</span>
                <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">ops</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">all_signals</span><span class="p">)):</span>
                    <span class="n">op_sigs</span> <span class="o">=</span> <span class="p">[</span><span class="n">op</span><span class="o">.</span><span class="n">all_signals</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">base</span> <span class="k">for</span> <span class="n">op</span> <span class="ow">in</span> <span class="n">ops</span><span class="p">]</span>
                    <span class="n">idxs</span> <span class="o">=</span> <span class="p">[</span><span class="n">sig_idxs</span><span class="p">[</span><span class="n">s</span><span class="p">]</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">op_sigs</span><span class="p">]</span>
                    <span class="n">diff</span><span class="p">[</span><span class="n">op_sigs</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">argmin</span><span class="p">(</span><span class="n">idxs</span><span class="p">)]]</span> <span class="o">+=</span> <span class="mi">1</span>
                    <span class="n">diff</span><span class="p">[</span><span class="n">op_sigs</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">idxs</span><span class="p">)]]</span> <span class="o">-=</span> <span class="mi">1</span>

        <span class="c1"># find the partition points in signal list</span>
        <span class="nb">open</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">s</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">sigs</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">diff</span><span class="p">:</span>
                <span class="nb">open</span> <span class="o">+=</span> <span class="n">diff</span><span class="p">[</span><span class="n">s</span><span class="p">]</span>

            <span class="k">if</span> <span class="nb">open</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">breaks</span> <span class="o">+=</span> <span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span>

        <span class="n">logging</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot;partitions&quot;</span><span class="p">)</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="si">%s</span><span class="s2">&quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="s2">&quot;|&quot;</span> <span class="k">if</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">breaks</span> <span class="k">else</span> <span class="s2">&quot; &quot;</span>
                                      <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">sigs</span><span class="p">))))</span>

        <span class="c1"># create all the base signals</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">sig</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">sigs</span><span class="p">):</span>
            <span class="k">assert</span> <span class="n">sig</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">signals</span>
            <span class="k">assert</span> <span class="ow">not</span> <span class="n">sig</span><span class="o">.</span><span class="n">is_view</span>

            <span class="k">if</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">breaks</span><span class="p">:</span>
                <span class="c1"># start a new array for all current bases</span>
                <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">curr_keys</span><span class="p">:</span>
                    <span class="n">curr_keys</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="nb">object</span><span class="p">()</span>

            <span class="c1"># convert to appropriate dtype</span>
            <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">issubdtype</span><span class="p">(</span><span class="n">sig</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">floating</span><span class="p">):</span>
                <span class="n">dtype</span> <span class="o">=</span> <span class="n">float_type</span>
            <span class="k">elif</span> <span class="n">np</span><span class="o">.</span><span class="n">issubdtype</span><span class="p">(</span><span class="n">sig</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">integer</span><span class="p">):</span>
                <span class="n">dtype</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">int32</span>
            <span class="k">elif</span> <span class="n">np</span><span class="o">.</span><span class="n">issubdtype</span><span class="p">(</span><span class="n">sig</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">bool_</span><span class="p">):</span>
                <span class="n">dtype</span> <span class="o">=</span> <span class="n">sig</span><span class="o">.</span><span class="n">dtype</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">&quot;Unsupported signal dtype&quot;</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">is_sparse</span><span class="p">(</span><span class="n">sig</span><span class="p">):</span>
                <span class="c1"># for sparse tensors, what we care about is the shape of the</span>
                <span class="c1"># underlying data, not the full matrix</span>
                <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="n">sig</span><span class="o">.</span><span class="n">initial_value</span><span class="o">.</span><span class="n">size</span><span class="p">,)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># resize scalars to length 1 vectors</span>
                <span class="n">shape</span> <span class="o">=</span> <span class="n">sig</span><span class="o">.</span><span class="n">shape</span> <span class="k">if</span> <span class="n">sig</span><span class="o">.</span><span class="n">shape</span> <span class="o">!=</span> <span class="p">()</span> <span class="k">else</span> <span class="p">(</span><span class="mi">1</span><span class="p">,)</span>

            <span class="c1"># parameters of signal that affect the base array</span>
            <span class="n">array_params</span> <span class="o">=</span> <span class="p">(</span><span class="n">dtype</span><span class="p">,</span> <span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:],</span> <span class="n">sig</span><span class="o">.</span><span class="n">trainable</span><span class="p">,</span> <span class="n">sig</span><span class="o">.</span><span class="n">minibatched</span><span class="p">)</span>

            <span class="c1"># key used to map signals to base arrays</span>
            <span class="k">if</span> <span class="n">array_params</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">curr_keys</span><span class="p">:</span>
                <span class="n">curr_keys</span><span class="p">[</span><span class="n">array_params</span><span class="p">]</span> <span class="o">=</span> <span class="nb">object</span><span class="p">()</span>
            <span class="n">key</span> <span class="o">=</span> <span class="n">curr_keys</span><span class="p">[</span><span class="n">array_params</span><span class="p">]</span>

            <span class="n">initial_value</span> <span class="o">=</span> <span class="n">sig</span><span class="o">.</span><span class="n">initial_value</span>
            <span class="k">if</span> <span class="n">is_sparse</span><span class="p">(</span><span class="n">sig</span><span class="p">):</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">initial_value</span><span class="p">,</span> <span class="n">SparseMatrix</span><span class="p">):</span>
                    <span class="n">initial_value</span> <span class="o">=</span> <span class="n">initial_value</span><span class="o">.</span><span class="n">data</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">initial_value</span> <span class="o">=</span> <span class="n">initial_value</span><span class="o">.</span><span class="n">tocoo</span><span class="p">()</span><span class="o">.</span><span class="n">data</span>

            <span class="n">initial_value</span> <span class="o">=</span> <span class="n">initial_value</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">dtype</span><span class="p">,</span> <span class="n">copy</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

            <span class="c1"># broadcast scalars up to full size</span>
            <span class="k">if</span> <span class="n">initial_value</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">():</span>
                <span class="n">initial_value</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">resize</span><span class="p">(</span><span class="n">initial_value</span><span class="p">,</span> <span class="n">shape</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">sig</span><span class="o">.</span><span class="n">minibatched</span><span class="p">:</span>
                <span class="c1"># duplicate along minibatch dimension</span>
                <span class="n">initial_value</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">tile</span><span class="p">(</span>
                    <span class="n">initial_value</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="kc">None</span><span class="p">],</span>
                    <span class="nb">tuple</span><span class="p">(</span><span class="mi">1</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">shape</span><span class="p">)</span> <span class="o">+</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">minibatch_size</span><span class="p">,))</span>

            <span class="k">if</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">base_arrays</span><span class="p">:</span>
                <span class="n">base_arrays</span><span class="p">[</span><span class="n">key</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">initial_value</span><span class="p">)</span>
                <span class="n">base_arrays</span><span class="p">[</span><span class="n">key</span><span class="p">][</span><span class="mi">2</span><span class="p">]</span> <span class="o">+=</span> <span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">base_arrays</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="p">[[</span><span class="n">initial_value</span><span class="p">],</span> <span class="n">sig</span><span class="o">.</span><span class="n">trainable</span><span class="p">,</span> <span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span>

            <span class="n">n</span> <span class="o">=</span> <span class="n">base_arrays</span><span class="p">[</span><span class="n">key</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
            <span class="n">indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">n</span> <span class="o">-</span> <span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">n</span><span class="p">)</span>

            <span class="n">tensor_sig</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">signals</span><span class="o">.</span><span class="n">get_tensor_signal</span><span class="p">(</span>
                <span class="n">indices</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">shape</span><span class="p">,</span> <span class="n">sig</span><span class="o">.</span><span class="n">minibatched</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="n">sig</span><span class="o">.</span><span class="n">name</span><span class="p">,</span>
                <span class="n">signal</span><span class="o">=</span><span class="n">sig</span><span class="p">)</span>

            <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot;created base signal&quot;</span><span class="p">)</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="n">sig</span><span class="p">)</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="n">tensor_sig</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">base_arrays</span><span class="p">:</span>
            <span class="n">arrs</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">base_arrays</span><span class="p">[</span><span class="n">key</span><span class="p">]</span>
            <span class="n">base_arrays</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">arrs</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span> <span class="n">t</span><span class="p">)</span>

        <span class="c1"># add any signal views to the sig_map</span>
        <span class="n">all_views</span> <span class="o">=</span> <span class="p">[</span><span class="n">sig</span> <span class="k">for</span> <span class="n">ops</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">plan</span> <span class="k">for</span> <span class="n">op</span> <span class="ow">in</span> <span class="n">ops</span> <span class="k">for</span> <span class="n">sig</span> <span class="ow">in</span>
                     <span class="n">op</span><span class="o">.</span><span class="n">all_signals</span> <span class="k">if</span> <span class="n">sig</span><span class="o">.</span><span class="n">is_view</span><span class="p">]</span>
        <span class="k">for</span> <span class="n">sig</span> <span class="ow">in</span> <span class="n">all_views</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">sig</span><span class="o">.</span><span class="n">size</span> <span class="o">==</span> <span class="n">sig</span><span class="o">.</span><span class="n">base</span><span class="o">.</span><span class="n">size</span><span class="p">:</span>
                <span class="c1"># reshape view</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">signals</span><span class="p">[</span><span class="n">sig</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">signals</span><span class="p">[</span><span class="n">sig</span><span class="o">.</span><span class="n">base</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">sig</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">sig</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span> <span class="o">!=</span> <span class="n">sig</span><span class="o">.</span><span class="n">base</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:]:</span>
                    <span class="c1"># TODO: support this?</span>
                    <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span>
                        <span class="s2">&quot;Slicing on axes &gt; 0 is not supported&quot;</span><span class="p">)</span>

                <span class="c1"># slice view</span>
                <span class="k">assert</span> <span class="n">np</span><span class="o">.</span><span class="n">all</span><span class="p">([</span><span class="n">x</span> <span class="o">==</span> <span class="mi">1</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">sig</span><span class="o">.</span><span class="n">elemstrides</span><span class="p">[</span><span class="mi">1</span><span class="p">:]])</span>

                <span class="n">start</span> <span class="o">=</span> <span class="n">sig</span><span class="o">.</span><span class="n">elemoffset</span>
                <span class="n">stride</span> <span class="o">=</span> <span class="n">sig</span><span class="o">.</span><span class="n">elemstrides</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
                <span class="n">stop</span> <span class="o">=</span> <span class="n">start</span> <span class="o">+</span> <span class="n">sig</span><span class="o">.</span><span class="n">size</span> <span class="o">*</span> <span class="n">stride</span>
                <span class="k">if</span> <span class="n">stop</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="n">stop</span> <span class="o">=</span> <span class="kc">None</span>

                <span class="bp">self</span><span class="o">.</span><span class="n">signals</span><span class="p">[</span><span class="n">sig</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">signals</span><span class="p">[</span><span class="n">sig</span><span class="o">.</span><span class="n">base</span><span class="p">][</span><span class="nb">slice</span><span class="p">(</span><span class="n">start</span><span class="p">,</span> <span class="n">stop</span><span class="p">,</span>
                                                                 <span class="n">stride</span><span class="p">)]</span>

        <span class="c1"># error checking</span>
        <span class="k">for</span> <span class="n">sig</span><span class="p">,</span> <span class="n">tensor_sig</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">signals</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="c1"># tensorsignal shapes should match signal shapes</span>
            <span class="k">assert</span> <span class="n">tensor_sig</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="n">sig</span><span class="o">.</span><span class="n">size</span><span class="p">,)</span> <span class="k">if</span> <span class="n">is_sparse</span><span class="p">(</span><span class="n">sig</span><span class="p">)</span> <span class="k">else</span> <span class="p">(</span>
                <span class="n">sig</span><span class="o">.</span><span class="n">shape</span> <span class="k">if</span> <span class="n">sig</span><span class="o">.</span><span class="n">shape</span> <span class="o">!=</span> <span class="p">()</span> <span class="k">else</span> <span class="p">(</span><span class="mi">1</span><span class="p">,))</span>

            <span class="c1"># tensorsignal values should match signal values</span>
            <span class="n">initial_value</span> <span class="o">=</span> <span class="n">sig</span><span class="o">.</span><span class="n">initial_value</span>
            <span class="k">if</span> <span class="n">is_sparse</span><span class="p">(</span><span class="n">sig</span><span class="p">):</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">initial_value</span><span class="p">,</span> <span class="n">SparseMatrix</span><span class="p">):</span>
                    <span class="n">initial_value</span> <span class="o">=</span> <span class="n">initial_value</span><span class="o">.</span><span class="n">data</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">initial_value</span> <span class="o">=</span> <span class="n">initial_value</span><span class="o">.</span><span class="n">tocoo</span><span class="p">()</span><span class="o">.</span><span class="n">data</span>
            <span class="k">if</span> <span class="n">sig</span><span class="o">.</span><span class="n">minibatched</span><span class="p">:</span>
                <span class="n">initial_value</span> <span class="o">=</span> <span class="n">initial_value</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="kc">None</span><span class="p">]</span>
            <span class="k">assert</span> <span class="n">np</span><span class="o">.</span><span class="n">allclose</span><span class="p">(</span>
                <span class="n">base_arrays</span><span class="p">[</span><span class="n">tensor_sig</span><span class="o">.</span><span class="n">key</span><span class="p">][</span><span class="mi">0</span><span class="p">][</span><span class="n">tensor_sig</span><span class="o">.</span><span class="n">indices</span><span class="p">],</span>
                <span class="n">initial_value</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">dtype</span><span class="p">))</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot;base arrays&quot;</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="nb">str</span><span class="p">((</span><span class="n">k</span><span class="p">,</span> <span class="n">v</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">v</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">trainable</span><span class="p">))</span>
                                <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">trainable</span><span class="p">)</span> <span class="ow">in</span> <span class="n">base_arrays</span><span class="o">.</span><span class="n">items</span><span class="p">()]))</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">base_arrays_init</span> <span class="o">=</span> <span class="n">base_arrays</span></div></div>
</pre></div>

            </div>
          </div>
        </div>
      </div>

    </div>
  </div>
</div><footer class="text-light footer-main gradient-bottom">
  <p class="small text-center mb-0">
    <a href="https://www.nengo.ai/">What is Nengo?</a>
    <a href="https://www.nengo.ai/documentation/">Documentation</a>
    <a href="https://www.nengo.ai/download/">Download</a>
    <a href="https://appliedbrainresearch.com">ABR</a>
    <a href="https://www.nengo.ai/privacy/">Privacy</a>
  </p>
  <p class="small text-center mb-0">&copy; Applied Brain Research</p>
</footer>
<script>
  function switchVersion(select) {
    var option = select.selectedOptions[0];
    if (option.hasAttribute("value")) {
      window.location = option.value;
    }
  }
</script>

<script>
  var elements = document.querySelectorAll('.sidenav');
  Stickyfill.add(elements);
</script>
<script>
  ScrollReveal().reveal(".fade-in", {
      scale: 0.85,
      duration: 1000,
      delay: 250,
      interval: 50
  });
</script>
<script>
  $('a.toggle-sidenav').on('click', function(e) {
    e.preventDefault();
    if ( $(this).hasClass('active') ) {
      $(this).removeClass('active');
      $('.sidenav').removeClass('open');
    } else {
      $(this).addClass('active');
      $('.sidenav').addClass('open');
    }
  });
</script>
<script>
  var lists = document.querySelectorAll('.toctree ul');
  lists.forEach((ul) => {
      ul.classList.add("nav");
  });
  var links = document.querySelectorAll('.toctree a');
  links.forEach((link) => {
      link.classList.add("nav-link");
  });
  $("body").scrollspy({target: ".sidenav"});
</script>
  </body>
</html>