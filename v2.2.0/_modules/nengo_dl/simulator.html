
<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta charset="utf-8" />
    <title>nengo_dl.simulator &#8212; NengoDL 2.2.0 docs</title>
    <link rel="stylesheet" href="../../_static/basic.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
<link href="https://fonts.googleapis.com/css?family=IBM+Plex+Sans:400,400i,600|Rajdhani:700&display=swap" rel="stylesheet">
<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.8.2/css/all.css" integrity="sha384-oS3vJWv+0UjzBfQzYUhtDYW+Pj2yciDJxpsK1OYPAYjqT085Qq/1cq5FLXAZQ7Ay" crossorigin="anonymous">
<link rel="stylesheet" href="https://www.nengo.ai/css/bootstrap.css" type="text/css">
<style>
  body .title-bar,
  body .documentation-source h1:after {
    background-color: #ff6600;
  }
</style>

<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-GT8XEDLTMJ"></script>
<script>
 window.dataLayer = window.dataLayer || [];
 function gtag(){dataLayer.push(arguments);}
 gtag('js', new Date());
 gtag('config', 'G-GT8XEDLTMJ');
</script>
<!-- End Google tag (gtag.js) -->

<!-- Matomo -->
<script>
 var _paq = window._paq = window._paq || [];
 _paq.push(["setDocumentTitle", document.domain + "/" + document.title]);
 _paq.push(["setCookieDomain", "*.appliedbrainresearch.com"]);
 _paq.push(["setDomains", ["*.appliedbrainresearch.com","*.edge.nengo.ai","*.forum.nengo.ai","*.labs.nengo.ai","*.nengo.ai"]]);
 _paq.push(["enableCrossDomainLinking"]);
 _paq.push(["setDoNotTrack", true]);
 _paq.push(['trackPageView']);
 _paq.push(['enableLinkTracking']);
 (function() {
   var u="https://appliedbrainresearch.matomo.cloud/";
   _paq.push(['setTrackerUrl', u+'matomo.php']);
   _paq.push(['setSiteId', '3']);
   var d=document, g=d.createElement('script'), s=d.getElementsByTagName('script')[0];
   g.async=true; g.src='//cdn.matomo.cloud/appliedbrainresearch.matomo.cloud/matomo.js'; s.parentNode.insertBefore(g,s);
 })();
</script>
<!-- End Matomo Code -->
<script src="https://code.jquery.com/jquery-3.3.1.min.js" integrity="sha256-FgpCb/KJQlLNfOu91ta32o/NMZxltwRo8QtmkMRdAu8=" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.3/umd/popper.min.js" integrity="sha384-ZMP7rVo3mIykV+2+9J3UJ46jBk0WLaUAdn689aCwoqbBJiSnjAK/l8WvCWPIPm49" crossorigin="anonymous"></script>
<script src="https://unpkg.com/scrollreveal"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/stickyfill/2.1.0/stickyfill.min.js"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.1.1/js/bootstrap.min.js" integrity="sha384-smHYKdLADwkXOn1EmN1qk/HfnUcbVRZyYmZ4qpPea6sjB/pTJ0euyQp0Mk8ck+5T" crossorigin="anonymous"></script>
<!-- From basic/layout.html -->
<script type="text/javascript" id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
  
  
<script type="text/javascript" src="../../_static/underscore.js"></script>
  
  
<script type="text/javascript" src="../../_static/doctools.js"></script>
  
  
<script type="text/javascript" src="../../_static/language_data.js"></script>
  
  
<script async="async" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
  
  
<script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true, "ignoreClass": "document", "processClass": "math|output_area"}})</script>
  
    <link rel="shortcut icon" href="../../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
<meta name="viewport" content="width=device-width, initial-scale=1, viewport-fit=cover">

  </head><body class="bg-dark">

<header class="fixed-top header-top shadow-sm">
  <nav class="navbar navbar-expand-md navbar-light bg-white">
    <a class="navbar-brand" href="https://www.nengo.ai">
      <img
        src="https://www.nengo.ai/design/_images/general-full-light.svg"
        alt="Nengo"
        class="logo"
      />
    </a>
    <button
      class="navbar-toggler"
      type="button"
      data-toggle="collapse"
      data-target="#navbar-collapse"
      aria-controls="navbar-collapse"
      aria-expanded="false"
      aria-label="Toggle navigation"
    >
      <span class="navbar-toggler-icon"></span>
    </button>
    <div class="collapse navbar-collapse" id="navbar-collapse">
      <ul class="navbar-nav ml-auto">
        <li class="nav-item">
          <a class="nav-link" href="https://www.nengo.ai">What is Nengo?</a>
        </li>
        <li class="nav-item dropdown active">
          <a
            class="nav-link dropdown-toggle"
            id="navbar-dropdown-docs"
            data-toggle="dropdown"
            aria-haspopup="true"
            aria-expanded="false"
            href="#"
            >Documentation</a
          >
          <div
            class="dropdown-menu shadow-lg border-0"
            aria-labelledby="navbar-dropdown-docs"
          >
            
            <a class="dropdown-item" href="https://www.nengo.ai/nengo/">Nengo Core</a>
            <a class="dropdown-item" href="https://github.com/nengo/nengo-gui/">Nengo GUI</a>
            <a class="dropdown-item" href="https://www.nengo.ai/nengo-dl/">Nengo DL</a>
            <div class="dropdown-divider"></div>
            <a class="dropdown-item" href="https://www.nengo.ai/nengo-spa/">Nengo SPA</a>
            <a class="dropdown-item" href="https://www.nengo.ai/nengo-extras/">Nengo Extras</a>
            <a class="dropdown-item" href="https://arvoelke.github.io/nengolib-docs/">Nengolib</a>
            <a class="dropdown-item" href="https://github.com/nengo/nengo-examples/">Nengo Examples</a>
            <div class="dropdown-divider"></div>
            <a class="dropdown-item" href="https://www.nengo.ai/nengo-fpga/">Nengo FPGA</a>
            <a class="dropdown-item" href="https://www.nengo.ai/nengo-loihi/">Nengo Loihi</a>
            <a class="dropdown-item" href="https://github.com/nengo/nengo-ocl">Nengo OpenCL</a>
            <a class="dropdown-item" href="https://github.com/project-rig/nengo_spinnaker">Nengo SpiNNaker</a>
            <a class="dropdown-item" href="https://github.com/nengo/nengo-mpi">Nengo MPI</a>
            <div class="dropdown-divider"></div>
            <a class="dropdown-item" href="https://www.nengo.ai/documentation"
              >All documentation</a
            >
          </div>
        </li>
        <li class="nav-item dropdown">
          <a
            class="nav-link dropdown-toggle"
            id="navbar-dropdown-community"
            data-toggle="dropdown"
            aria-haspopup="true"
            aria-expanded="false"
            href="#"
            >Community</a
          >
          <div
            class="dropdown-menu shadow-lg border-0"
            aria-labelledby="navbar-dropdown-community"
          >
            <a class="dropdown-item" href="https://forum.nengo.ai">Forum</a>
            <div class="dropdown-divider"></div>
            <a class="dropdown-item" href="https://www.nengo.ai/people"
              >People</a
            >
            <a class="dropdown-item" href="https://www.nengo.ai/summer-school"
              >Summer school</a
            >
            <a class="dropdown-item" href="https://www.nengo.ai/contributing"
              >Contributing</a
            >
            <a class="dropdown-item" href="https://www.nengo.ai/publications"
              >Publications</a
            >
            <a class="dropdown-item" href="https://www.nengo.ai/videos"
              >Videos</a
            >
            <a class="dropdown-item" href="https://www.nengo.ai/conduct"
              >Code of conduct</a
            >
            <a class="dropdown-item" href="https://www.nengo.ai/caa">CAA</a>
          </div>
        </li>
        <li class="nav-item">
          <a
            class="nav-link btn btn-success btn-sm text-white"
            href="https://www.nengo.ai/download"
            >Download</a
          >
        </li>
      </ul>
    </div>
  </nav>
</header>
<div class="main-content gradient-top">
  <div class="container-fluid">
    <div class="row"><a class="toggle-sidenav d-block d-md-none" href="#"
  ><i class="icon-close fa fa-fw fa-arrow-left"></i
  ><i class="icon-open fa fa-fw fa-arrow-right"></i
></a>
<div role="complementary" class="sidenav col-4 col-xl-3 p-0 border-right">
  <h3 class="pt-5 px-5">
    <a href="../../index.html">
      <img
        class="img-fluid documentation-image"
        src="https://www.nengo.ai/design/_images/nengo-dl-full-light.svg"
        alt="NengoDL"
      />
    </a>
  </h3>
  
  <form class="px-5 pb-5 mb-0 mt-3 border-bottom">
    <div class="form-group">
      <label class="text-gray">Version:</label>
      <select class="custom-select" onchange="switchVersion(this);">
        
        
        <option value="../../../_modules/nengo_dl/simulator.html">latest</option>
        
        
          
        <option selected>v2.2.0</option>
          
        
          
        <option value="../../../v2.1.1/_modules/nengo_dl/simulator.html">
          v2.1.1
        </option>
          
        
          
        <option value="../../../v2.1.0/_modules/nengo_dl/simulator.html">
          v2.1.0
        </option>
          
        
          
        <option value="../../../v2.0.0/_modules/nengo_dl/simulator.html">
          v2.0.0
        </option>
          
        
          
        <option value="../../../v1.2.1/_modules/nengo_dl/simulator.html">
          v1.2.1
        </option>
          
        
          
        <option value="../../../v1.2.0/_modules/nengo_dl/simulator.html">
          v1.2.0
        </option>
          
        
          
        <option value="../../../v1.1.0/_modules/nengo_dl/simulator.html">
          v1.1.0
        </option>
          
        
          
        <option value="../../../v1.0.0/_modules/nengo_dl/simulator.html">
          v1.0.0
        </option>
          
        
          
        <option value="../../../v0.6.2/_modules/nengo_dl/simulator.html">
          v0.6.2
        </option>
          
        
          
        <option value="../../../v0.6.1/_modules/nengo_dl/simulator.html">
          v0.6.1
        </option>
          
        
          
        <option value="../../../v0.6.0/_modules/nengo_dl/simulator.html">
          v0.6.0
        </option>
          
        
          
        <option value="../../../v0.5.2/_modules/nengo_dl/simulator.html">
          v0.5.2
        </option>
          
        
          
        <option value="../../../v0.5.1/_modules/nengo_dl/simulator.html">
          v0.5.1
        </option>
          
        
          
        <option value="../../../v0.5.0/_modules/nengo_dl/simulator.html">
          v0.5.0
        </option>
          
        
          
        <option value="../../../v0.4.0/_modules/nengo_dl/simulator.html">
          v0.4.0
        </option>
          
        
          
        <option value="../../../v0.3.1/_modules/nengo_dl/simulator.html">
          v0.3.1
        </option>
          
        
          
        <option value="../../../v0.3.0/_modules/nengo_dl/simulator.html">
          v0.3.0
        </option>
          
        
          
        <option value="../../../v0.2.0/_modules/nengo_dl/simulator.html">
          v0.2.0
        </option>
          
        
      </select>
    </div>
  </form>
  
  <div class="p-5 toctree">
    <ul>
<li class="toctree-l1"><a class="reference internal" href="../../introduction.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../user-guide.html">User guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../reference.html">API reference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../examples.html">Examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../resources.html">Additional resources</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../project.html">Project information</a></li>
</ul>

  </div>
<form class="p-5 my-0 border-top" action="../../search.html" method="get">
  <div class="form-group form-group-single">
    <input type="text" name="q" class="form-control" placeholder="Search" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
    <button type="submit" class="btn btn-link">
      <img src="https://www.nengo.ai/img/icon-search.svg" alt="Go" />
    </button>
  </div>
</form></div>
      

      <div class="col-12 col-md-8 col-xl-9">
        <div class="container">
          <div class="row">
            <div class="col-10 offset-1 pb-5 documentation-source">
              
  <h1>Source code for nengo_dl.simulator</h1><div class="highlight"><pre>
<span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">The Simulator class is the access point for the main features of NengoDL,</span>
<span class="sd">including `running &lt;.Simulator.run_steps&gt;` and `training &lt;.Simulator.train&gt;`</span>
<span class="sd">a model.</span>
<span class="sd">&quot;&quot;&quot;</span>

<span class="kn">import</span> <span class="nn">collections</span>
<span class="kn">import</span> <span class="nn">copy</span>
<span class="kn">import</span> <span class="nn">logging</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">tempfile</span>
<span class="kn">import</span> <span class="nn">warnings</span>

<span class="kn">from</span> <span class="nn">nengo</span> <span class="k">import</span> <span class="n">Ensemble</span><span class="p">,</span> <span class="n">Connection</span><span class="p">,</span> <span class="n">Probe</span><span class="p">,</span> <span class="n">Network</span><span class="p">,</span> <span class="n">Direct</span><span class="p">,</span> <span class="n">Node</span>
<span class="kn">from</span> <span class="nn">nengo.builder.connection</span> <span class="k">import</span> <span class="n">BuiltConnection</span>
<span class="kn">from</span> <span class="nn">nengo.builder.ensemble</span> <span class="k">import</span> <span class="n">BuiltEnsemble</span>
<span class="kn">from</span> <span class="nn">nengo.ensemble</span> <span class="k">import</span> <span class="n">Neurons</span>
<span class="kn">from</span> <span class="nn">nengo.exceptions</span> <span class="k">import</span> <span class="p">(</span>
    <span class="n">ReadonlyError</span><span class="p">,</span> <span class="n">SimulatorClosed</span><span class="p">,</span> <span class="n">NengoWarning</span><span class="p">,</span> <span class="n">SimulationError</span><span class="p">,</span>
    <span class="n">ValidationError</span><span class="p">)</span>
<span class="kn">from</span> <span class="nn">nengo.solvers</span> <span class="k">import</span> <span class="n">NoSolver</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.client.timeline</span> <span class="k">import</span> <span class="n">Timeline</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.ops</span> <span class="k">import</span> <span class="n">gradient_checker</span>

<span class="kn">from</span> <span class="nn">nengo_dl</span> <span class="k">import</span> <span class="n">utils</span><span class="p">,</span> <span class="n">config</span><span class="p">,</span> <span class="n">objectives</span>
<span class="kn">from</span> <span class="nn">nengo_dl.builder</span> <span class="k">import</span> <span class="n">NengoBuilder</span><span class="p">,</span> <span class="n">NengoModel</span>
<span class="kn">from</span> <span class="nn">nengo_dl.compat</span> <span class="k">import</span> <span class="n">tf_compat</span><span class="p">,</span> <span class="n">Convolution</span>
<span class="kn">from</span> <span class="nn">nengo_dl.tensor_graph</span> <span class="k">import</span> <span class="n">TensorGraph</span>


<span class="n">logger</span> <span class="o">=</span> <span class="n">logging</span><span class="o">.</span><span class="n">getLogger</span><span class="p">(</span><span class="vm">__name__</span><span class="p">)</span>


<div class="viewcode-block" id="Simulator"><a class="viewcode-back" href="../../reference.html#nengo_dl.simulator.Simulator">[docs]</a><span class="k">class</span> <span class="nc">Simulator</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Simulate network using the ``nengo_dl`` backend.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    network : `~nengo.Network` or None</span>
<span class="sd">        A network object to be built and then simulated. If None,</span>
<span class="sd">        then a built model must be passed to ``model`` instead</span>
<span class="sd">    dt : float</span>
<span class="sd">        Length of a simulator timestep, in seconds</span>
<span class="sd">    seed : int</span>
<span class="sd">        Seed for all stochastic operators used in this simulator</span>
<span class="sd">    model : `~nengo.builder.Model`</span>
<span class="sd">        Pre-built model object</span>
<span class="sd">    dtype : ``tf.DType``</span>
<span class="sd">        Deprecated, use ``nengo_dl.configure_settings(dtype=...)`` instead.</span>
<span class="sd">    device : None or ``&quot;/cpu:0&quot;`` or ``&quot;/gpu:[0-n]&quot;``</span>
<span class="sd">        Device on which to execute computations (if None then uses the</span>
<span class="sd">        default device as determined by TensorFlow)</span>
<span class="sd">    unroll_simulation : int</span>
<span class="sd">        Unroll simulation loop by explicitly building the given number of</span>
<span class="sd">        iterations into the computation graph (improves simulation speed</span>
<span class="sd">        but increases build time)</span>
<span class="sd">    minibatch_size : int</span>
<span class="sd">        The number of simultaneous inputs that will be passed through the</span>
<span class="sd">        network</span>
<span class="sd">    tensorboard : str</span>
<span class="sd">        If not None, save network output in the TensorFlow summary format to</span>
<span class="sd">        the given directory, which can be loaded into TensorBoard</span>
<span class="sd">    progress_bar : bool</span>
<span class="sd">        If True (default), display progress information when building a model</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">network</span><span class="p">,</span> <span class="n">dt</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                 <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">unroll_simulation</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                 <span class="n">minibatch_size</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">tensorboard</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">progress_bar</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">closed</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">unroll</span> <span class="o">=</span> <span class="n">unroll_simulation</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">minibatch_size</span> <span class="o">=</span> <span class="mi">1</span> <span class="k">if</span> <span class="n">minibatch_size</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">minibatch_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">SimulationData</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">minibatch_size</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">seed</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">network</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">network</span><span class="o">.</span><span class="n">seed</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">seed</span> <span class="o">=</span> <span class="n">network</span><span class="o">.</span><span class="n">seed</span> <span class="o">+</span> <span class="mi">1</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">seed</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">iinfo</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span><span class="o">.</span><span class="n">max</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">seed</span> <span class="o">=</span> <span class="n">seed</span>

        <span class="c1"># TODO: multi-GPU support</span>

        <span class="k">if</span> <span class="n">device</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">utils</span><span class="o">.</span><span class="n">tf_gpu_installed</span><span class="p">:</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                <span class="s2">&quot;No GPU support detected. It is recommended that you &quot;</span>
                <span class="s2">&quot;install tensorflow-gpu (`pip install tensorflow-gpu`).&quot;</span><span class="p">)</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Running on CPU&quot;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Running on </span><span class="si">%s</span><span class="s2">&quot;</span><span class="p">,</span> <span class="s2">&quot;CPU/GPU&quot;</span> <span class="k">if</span> <span class="n">device</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="p">(</span>
                <span class="s2">&quot;CPU&quot;</span> <span class="k">if</span> <span class="s2">&quot;cpu&quot;</span> <span class="ow">in</span> <span class="n">device</span> <span class="k">else</span> <span class="s2">&quot;GPU&quot;</span><span class="p">))</span>

        <span class="n">ProgressBar</span> <span class="o">=</span> <span class="p">(</span><span class="n">utils</span><span class="o">.</span><span class="n">ProgressBar</span> <span class="k">if</span> <span class="n">progress_bar</span> <span class="k">else</span>
                       <span class="n">utils</span><span class="o">.</span><span class="n">NullProgressBar</span><span class="p">)</span>

        <span class="c1"># build model (uses default nengo builder)</span>
        <span class="k">if</span> <span class="n">model</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">NengoModel</span><span class="p">(</span>
                <span class="n">dt</span><span class="o">=</span><span class="nb">float</span><span class="p">(</span><span class="n">dt</span><span class="p">),</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;</span><span class="si">%s</span><span class="s2">, dt=</span><span class="si">%f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">network</span><span class="p">,</span> <span class="n">dt</span><span class="p">),</span>
                <span class="n">builder</span><span class="o">=</span><span class="n">NengoBuilder</span><span class="p">(),</span> <span class="n">fail_fast</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">dt</span> <span class="o">!=</span> <span class="n">model</span><span class="o">.</span><span class="n">dt</span><span class="p">:</span>
                <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="s2">&quot;Model dt (</span><span class="si">%g</span><span class="s2">) does not match Simulator &quot;</span>
                              <span class="s2">&quot;dt (</span><span class="si">%g</span><span class="s2">)&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">dt</span><span class="p">,</span> <span class="n">dt</span><span class="p">),</span> <span class="n">NengoWarning</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span>

        <span class="k">if</span> <span class="n">network</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">p</span> <span class="o">=</span> <span class="n">ProgressBar</span><span class="p">(</span><span class="s2">&quot;Building network&quot;</span><span class="p">,</span> <span class="s2">&quot;Build&quot;</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">build</span><span class="p">(</span><span class="n">network</span><span class="p">,</span> <span class="n">progress</span><span class="o">=</span><span class="n">p</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">dtype</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                <span class="s2">&quot;dtype parameter is deprecated; use &quot;</span>
                <span class="s2">&quot;nengo_dl.configure_settings(dtype=...) instead&quot;</span><span class="p">,</span>
                <span class="ne">DeprecationWarning</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">dtype</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">get_setting</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s2">&quot;dtype&quot;</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

        <span class="c1"># set up tensorflow graph plan</span>
        <span class="k">with</span> <span class="n">ProgressBar</span><span class="p">(</span><span class="s2">&quot;Optimizing graph&quot;</span><span class="p">,</span> <span class="s2">&quot;Optimization&quot;</span><span class="p">,</span>
                         <span class="n">max_value</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span> <span class="k">as</span> <span class="n">progress</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">tensor_graph</span> <span class="o">=</span> <span class="n">TensorGraph</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dt</span><span class="p">,</span> <span class="n">unroll_simulation</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">minibatch_size</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">progress</span><span class="p">)</span>

        <span class="c1"># set TensorFlow graph seed</span>
        <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">tensor_graph</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">as_default</span><span class="p">():</span>
            <span class="n">tf_compat</span><span class="o">.</span><span class="n">set_random_seed</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">seed</span><span class="p">)</span>

        <span class="c1"># construct graph</span>
        <span class="k">with</span> <span class="n">ProgressBar</span><span class="p">(</span><span class="s2">&quot;Constructing graph&quot;</span><span class="p">,</span> <span class="s2">&quot;Construction&quot;</span><span class="p">,</span>
                         <span class="n">max_value</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span> <span class="k">as</span> <span class="n">progress</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">tensor_graph</span><span class="o">.</span><span class="n">build</span><span class="p">(</span><span class="n">progress</span><span class="p">)</span>

        <span class="c1"># output simulation data for viewing via TensorBoard</span>
        <span class="k">if</span> <span class="n">tensorboard</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">tensorboard</span><span class="p">):</span>
                <span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">tensorboard</span><span class="p">)</span>

            <span class="n">run_number</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span>
                <span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">4</span><span class="p">:])</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="n">tensorboard</span><span class="p">)</span>
                 <span class="k">if</span> <span class="n">x</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">&quot;run&quot;</span><span class="p">)]</span> <span class="ow">or</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span> <span class="o">+</span> <span class="mi">1</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">summary</span> <span class="o">=</span> <span class="n">tf_compat</span><span class="o">.</span><span class="n">summary</span><span class="o">.</span><span class="n">FileWriter</span><span class="p">(</span>
                <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">tensorboard</span><span class="p">,</span> <span class="s2">&quot;run_</span><span class="si">%d</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">run_number</span><span class="p">),</span>
                <span class="n">graph</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tensor_graph</span><span class="o">.</span><span class="n">graph</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">summary</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="c1"># start session</span>

        <span class="n">session_config</span> <span class="o">=</span> <span class="n">tf_compat</span><span class="o">.</span><span class="n">ConfigProto</span><span class="p">(</span>
            <span class="n">allow_soft_placement</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="n">log_device_placement</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="c1"># TODO: XLA compiling doesn&#39;t seem to provide any benefit at the</span>
        <span class="c1"># moment, revisit later after tensorflow has developed it further</span>
        <span class="c1"># config.graph_options.optimizer_options.global_jit_level = (</span>
        <span class="c1">#     tf.OptimizerOptions.ON_1)</span>

        <span class="c1"># set any config options specified by user</span>
        <span class="n">config_settings</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">get_setting</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s2">&quot;session_config&quot;</span><span class="p">,</span> <span class="p">{})</span>
        <span class="k">for</span> <span class="n">c</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">config_settings</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="n">attrs</span> <span class="o">=</span> <span class="n">c</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;.&quot;</span><span class="p">)</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">session_config</span>
            <span class="k">for</span> <span class="n">a</span> <span class="ow">in</span> <span class="n">attrs</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]:</span>
                <span class="n">x</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">a</span><span class="p">)</span>
            <span class="nb">setattr</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">attrs</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">v</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">sess</span> <span class="o">=</span> <span class="n">tf_compat</span><span class="o">.</span><span class="n">Session</span><span class="p">(</span><span class="n">graph</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tensor_graph</span><span class="o">.</span><span class="n">graph</span><span class="p">,</span>
                                      <span class="n">config</span><span class="o">=</span><span class="n">session_config</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">reset</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="n">seed</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">closed</span> <span class="o">=</span> <span class="kc">False</span>

<div class="viewcode-block" id="Simulator.reset"><a class="viewcode-back" href="../../reference.html#nengo_dl.simulator.Simulator.reset">[docs]</a>    <span class="k">def</span> <span class="nf">reset</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Resets the simulator to initial conditions.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        seed : int</span>
<span class="sd">            If not None, overwrite the default simulator seed with this value</span>
<span class="sd">            (note: this becomes the new default simulator seed)</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">closed</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">closed</span><span class="p">:</span>
            <span class="k">raise</span> <span class="n">SimulatorClosed</span><span class="p">(</span><span class="s2">&quot;Cannot reset closed Simulator.&quot;</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">n_steps</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">time</span> <span class="o">=</span> <span class="mf">0.0</span>

        <span class="c1"># initialize variables</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tensor_graph</span><span class="o">.</span><span class="n">constant_init_op</span><span class="p">,</span>
                      <span class="n">feed_dict</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tensor_graph</span><span class="o">.</span><span class="n">signals</span><span class="o">.</span><span class="n">constant_phs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">soft_reset</span><span class="p">(</span><span class="n">include_trainable</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">include_probes</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="c1"># execute post-build processes (we do this here because</span>
        <span class="c1"># seed can change each call to reset)</span>
        <span class="k">if</span> <span class="n">seed</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">seed</span> <span class="o">=</span> <span class="n">seed</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">RandomState</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">seed</span><span class="p">)</span>
        <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">tensor_graph</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">as_default</span><span class="p">():</span>
            <span class="n">tf_compat</span><span class="o">.</span><span class="n">set_random_seed</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">seed</span><span class="p">)</span>

        <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">sess</span><span class="o">.</span><span class="n">as_default</span><span class="p">():</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">tensor_graph</span><span class="o">.</span><span class="n">build_post</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">sess</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">rng</span><span class="p">)</span></div>

<div class="viewcode-block" id="Simulator.soft_reset"><a class="viewcode-back" href="../../reference.html#nengo_dl.simulator.Simulator.soft_reset">[docs]</a>    <span class="k">def</span> <span class="nf">soft_reset</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">include_trainable</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">include_probes</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Resets the internal state of the simulation, but doesn&#39;t</span>
<span class="sd">        rebuild the graph.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        include_trainable : bool</span>
<span class="sd">            If True, also reset any training that has been performed on</span>
<span class="sd">            network parameters (e.g., connection weights)</span>
<span class="sd">        include_probes : bool</span>
<span class="sd">            If True, also clear probe data</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">init_ops</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">tensor_graph</span><span class="o">.</span><span class="n">local_init_op</span><span class="p">,</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">tensor_graph</span><span class="o">.</span><span class="n">global_init_op</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">include_trainable</span><span class="p">:</span>
            <span class="n">init_ops</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tensor_graph</span><span class="o">.</span><span class="n">trainable_init_op</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">init_ops</span><span class="p">,</span> <span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span>
            <span class="n">ph</span><span class="p">:</span> <span class="n">v</span> <span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">ph</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">tensor_graph</span><span class="o">.</span><span class="n">base_vars</span><span class="o">.</span><span class="n">values</span><span class="p">()})</span>

        <span class="k">if</span> <span class="n">include_probes</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">probes</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="n">p</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">n_steps</span> <span class="o">=</span> <span class="mi">0</span></div>

<div class="viewcode-block" id="Simulator.step"><a class="viewcode-back" href="../../reference.html#nengo_dl.simulator.Simulator.step">[docs]</a>    <span class="k">def</span> <span class="nf">step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Run the simulation for one time step.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        kwargs : dict</span>
<span class="sd">            See `.run_steps`</span>

<span class="sd">        Notes</span>
<span class="sd">        -----</span>
<span class="sd">        Progress bar is disabled by default when running via this method.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">kwargs</span><span class="o">.</span><span class="n">setdefault</span><span class="p">(</span><span class="s2">&quot;progress_bar&quot;</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">run_steps</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></div>

<div class="viewcode-block" id="Simulator.run"><a class="viewcode-back" href="../../reference.html#nengo_dl.simulator.Simulator.run">[docs]</a>    <span class="k">def</span> <span class="nf">run</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">time_in_seconds</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Simulate for the given length of time.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        time_in_seconds : float</span>
<span class="sd">            Run the simulator for the given number of simulated seconds</span>
<span class="sd">        kwargs : dict</span>
<span class="sd">            See `.run_steps`</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="n">time_in_seconds</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="n">ValidationError</span><span class="p">(</span>
                <span class="s2">&quot;Must be positive (got </span><span class="si">%g</span><span class="s2">)&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">time_in_seconds</span><span class="p">,),</span>
                <span class="n">attr</span><span class="o">=</span><span class="s2">&quot;time_in_seconds&quot;</span><span class="p">)</span>

        <span class="n">steps</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="nb">float</span><span class="p">(</span><span class="n">time_in_seconds</span><span class="p">)</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">dt</span><span class="p">))</span>

        <span class="k">if</span> <span class="n">steps</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">%g</span><span class="s2"> results in running for 0 timesteps. Simulator &quot;</span>
                          <span class="s2">&quot;still at time </span><span class="si">%g</span><span class="s2">.&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">time_in_seconds</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">time</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">run_steps</span><span class="p">(</span><span class="n">steps</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></div>

<div class="viewcode-block" id="Simulator.run_steps"><a class="viewcode-back" href="../../reference.html#nengo_dl.simulator.Simulator.run_steps">[docs]</a>    <span class="k">def</span> <span class="nf">run_steps</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_steps</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">input_feeds</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">profile</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                  <span class="n">progress_bar</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">extra_feeds</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Simulate for the given number of steps.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        n_steps : int</span>
<span class="sd">            The number of simulation steps to be executed</span>
<span class="sd">        data : dict of {`~nengo.Node`: `~numpy.ndarray`}</span>
<span class="sd">            Override the values of input Nodes with the given data.  Arrays</span>
<span class="sd">            should have shape ``(sim.minibatch_size, n_steps, node.size_out)``.</span>
<span class="sd">        input_feeds : dict of {`~nengo.Node`: `~numpy.ndarray`}</span>
<span class="sd">            Deprecated, use ``data`` instead.</span>
<span class="sd">        profile : bool</span>
<span class="sd">            If True, collect TensorFlow profiling information while the</span>
<span class="sd">            simulation is running (this will slow down the simulation).</span>
<span class="sd">            Can also pass a string specifying a non-default filename for the</span>
<span class="sd">            saved profile data.</span>
<span class="sd">        progress_bar : bool</span>
<span class="sd">            If True, print information about the simulation status to standard</span>
<span class="sd">            output.</span>
<span class="sd">        extra_feeds : dict of {``tf.Tensor``: `~numpy.ndarray`}</span>
<span class="sd">            Can be used to feed a value for arbitrary Tensors in the simulation</span>
<span class="sd">            (will be passed directly to the TensorFlow session)</span>

<span class="sd">        Notes</span>
<span class="sd">        -----</span>
<span class="sd">        If ``unroll_simulation=x`` is specified, and ``n_steps &gt; x``, this will</span>
<span class="sd">        repeatedly execute ``x`` timesteps until the the number of steps</span>
<span class="sd">        executed is &gt;= ``n_steps``.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">actual_steps</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">unroll</span> <span class="o">*</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="n">n_steps</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">unroll</span><span class="p">))</span>

        <span class="k">if</span> <span class="n">actual_steps</span> <span class="o">!=</span> <span class="n">n_steps</span><span class="p">:</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                <span class="s2">&quot;Number of steps (</span><span class="si">%d</span><span class="s2">) is not an even multiple of &quot;</span>
                <span class="s2">&quot;`unroll_simulation` (</span><span class="si">%d</span><span class="s2">).  Simulation will run for </span><span class="si">%d</span><span class="s2"> steps, &quot;</span>
                <span class="s2">&quot;which may have unintended side effects.&quot;</span> <span class="o">%</span>
                <span class="p">(</span><span class="n">n_steps</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">unroll</span><span class="p">,</span> <span class="n">actual_steps</span><span class="p">),</span> <span class="ne">RuntimeWarning</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">input_feeds</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># TODO: remove this in 3.0.0</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                <span class="s2">&quot;The `input_feeds` argument has been renamed; please use &quot;</span>
                <span class="s2">&quot;`data` instead, as `input_feeds` will not be supported in a &quot;</span>
                <span class="s2">&quot;future version.&quot;</span><span class="p">,</span> <span class="ne">DeprecationWarning</span><span class="p">)</span>
            <span class="k">assert</span> <span class="n">data</span> <span class="ow">is</span> <span class="kc">None</span>
            <span class="n">data</span> <span class="o">=</span> <span class="n">input_feeds</span>

        <span class="k">if</span> <span class="n">data</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">data</span> <span class="o">=</span> <span class="n">actual_steps</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># note: we only need to check the shape of the first item, because</span>
            <span class="c1"># check_data (inside run_batch) will ensure that all the items</span>
            <span class="c1"># have the same shape</span>
            <span class="n">batch_size</span><span class="p">,</span> <span class="n">input_steps</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">values</span><span class="p">()))</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="mi">2</span><span class="p">]</span>
            <span class="k">if</span> <span class="n">batch_size</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">minibatch_size</span><span class="p">:</span>
                <span class="k">raise</span> <span class="n">ValidationError</span><span class="p">(</span>
                    <span class="s2">&quot;Input data must have batch size == sim.minibatch_size &quot;</span>
                    <span class="s2">&quot;(</span><span class="si">%d</span><span class="s2"> != </span><span class="si">%d</span><span class="s2">)&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">minibatch_size</span><span class="p">),</span>
                    <span class="s2">&quot;data&quot;</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">input_steps</span> <span class="o">!=</span> <span class="n">actual_steps</span><span class="p">:</span>
                <span class="k">raise</span> <span class="n">ValidationError</span><span class="p">(</span>
                    <span class="s2">&quot;Number of timesteps in input data (</span><span class="si">%d</span><span class="s2">) does not &quot;</span>
                    <span class="s2">&quot;match requested number of steps (</span><span class="si">%d</span><span class="s2">)&quot;</span> <span class="o">%</span>
                    <span class="p">(</span><span class="n">input_steps</span><span class="p">,</span> <span class="n">n_steps</span><span class="p">),</span> <span class="s2">&quot;data&quot;</span><span class="p">)</span>

        <span class="k">def</span> <span class="nf">callback</span><span class="p">(</span><span class="n">_</span><span class="p">,</span> <span class="n">extra_vals</span><span class="p">):</span>
            <span class="k">assert</span> <span class="n">extra_vals</span> <span class="o">==</span> <span class="n">actual_steps</span>

        <span class="n">progress</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">utils</span><span class="o">.</span><span class="n">ProgressBar</span><span class="p">(</span><span class="s2">&quot;Simulating&quot;</span><span class="p">,</span> <span class="s2">&quot;Simulation&quot;</span><span class="p">,</span> <span class="n">max_value</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">progress_bar</span> <span class="k">else</span> <span class="n">utils</span><span class="o">.</span><span class="n">NullProgressBar</span><span class="p">())</span>

        <span class="k">with</span> <span class="n">progress</span><span class="p">:</span>
            <span class="c1"># note: we request steps_run from extra_fetches so that the</span>
            <span class="c1"># simulation will always run for the given number of steps, even</span>
            <span class="c1"># if there are no output probes</span>
            <span class="n">probe_data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">run_batch</span><span class="p">(</span>
                <span class="n">data</span><span class="p">,</span> <span class="p">{</span><span class="n">p</span><span class="p">:</span> <span class="kc">None</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">probes</span><span class="p">},</span>
                <span class="n">extra_feeds</span><span class="o">=</span><span class="n">extra_feeds</span><span class="p">,</span>
                <span class="n">extra_fetches</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tensor_graph</span><span class="o">.</span><span class="n">steps_run</span><span class="p">,</span>
                <span class="n">combine</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">isolate_state</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                <span class="n">callback</span><span class="o">=</span><span class="n">callback</span><span class="p">,</span> <span class="n">profile</span><span class="o">=</span><span class="n">profile</span><span class="p">)</span>

        <span class="c1"># update stored probe data</span>
        <span class="k">for</span> <span class="n">probe</span><span class="p">,</span> <span class="n">val</span> <span class="ow">in</span> <span class="n">probe_data</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="c1"># drop any extra steps (due to uneven unroll_simulation)</span>
            <span class="n">val</span> <span class="o">=</span> <span class="n">val</span><span class="p">[:,</span> <span class="p">:</span><span class="n">n_steps</span><span class="p">]</span>

            <span class="k">if</span> <span class="n">probe</span><span class="o">.</span><span class="n">sample_every</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="c1"># downsample probe according to `sample_every`</span>
                <span class="n">period</span> <span class="o">=</span> <span class="n">probe</span><span class="o">.</span><span class="n">sample_every</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">dt</span>
                <span class="n">steps</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_steps</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_steps</span> <span class="o">+</span> <span class="n">n_steps</span><span class="p">)</span>
                <span class="n">val</span> <span class="o">=</span> <span class="n">val</span><span class="p">[:,</span> <span class="p">(</span><span class="n">steps</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="n">period</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">]</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="n">probe</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">val</span><span class="p">)</span>

        <span class="c1"># update n_steps</span>
        <span class="c1"># note: we update n_steps according to the number of steps that the</span>
        <span class="c1"># user asked for, not the number of steps that were actually run</span>
        <span class="c1"># (in the case of uneven unroll_simulation)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_steps</span> <span class="o">+=</span> <span class="n">n_steps</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">time</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_steps</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">dt</span></div>

<div class="viewcode-block" id="Simulator.train"><a class="viewcode-back" href="../../reference.html#nengo_dl.simulator.Simulator.train">[docs]</a>    <span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">n_epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">objective</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
              <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">summaries</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">profile</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
              <span class="n">extra_feeds</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">progress_bar</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Optimize the trainable parameters of the network using the given</span>
<span class="sd">        optimization method, minimizing the objective value over the given</span>
<span class="sd">        inputs and targets.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        data : dict of {`~nengo.Node` or `~nengo.Probe`: \</span>
<span class="sd">                        `~numpy.ndarray`} or int</span>
<span class="sd">            Input values for Nodes in the network or target values for Probes;</span>
<span class="sd">            arrays should have shape ``(batch_size, n_steps,</span>
<span class="sd">            node.size_out/probe.size_in)``.  If no input data is required,</span>
<span class="sd">            an integer can be given specifying the number of timesteps to</span>
<span class="sd">            run the simulation.</span>
<span class="sd">        optimizer : ``tf.train.Optimizer``</span>
<span class="sd">            TensorFlow optimizer, e.g.</span>
<span class="sd">            ``tf.train.GradientDescentOptimizer(learning_rate=0.1)``</span>
<span class="sd">        n_epochs : int</span>
<span class="sd">            Run training for the given number of epochs (complete passes</span>
<span class="sd">            through ``data``)</span>
<span class="sd">        objective : dict of {(tuple of) `~nengo.Probe`: callable or ``None``}</span>
<span class="sd">            The objective to be minimized. The default applies</span>
<span class="sd">            `.objectives.mse` to all probes in ``data``.  This can be</span>
<span class="sd">            overridden by passing a dictionary mapping Probes to functions</span>
<span class="sd">            ``f(output, target) -&gt; loss`` that consume the actual output and</span>
<span class="sd">            target output for the given probe(s) and return a ``tf.Tensor``</span>
<span class="sd">            representing a scalar loss value.  The function may also accept a</span>
<span class="sd">            single argument ``f(output) -&gt; loss`` if targets are not required.</span>
<span class="sd">            Some common objective functions can be found in</span>
<span class="sd">            `nengo_dl.objectives`.</span>

<span class="sd">            Passing ``None`` as the probe value (instead of a callable)</span>
<span class="sd">            indicates that the error is being computed outside the simulation,</span>
<span class="sd">            and the value passed for that probe in ``data`` directly specifies</span>
<span class="sd">            the output error gradient.</span>

<span class="sd">            If multiple probes are specified as the key, then the corresponding</span>
<span class="sd">            output/target values will be passed as a list to the objective</span>
<span class="sd">            function.</span>

<span class="sd">            The overall loss value being minimized will be the sum across all</span>
<span class="sd">            the objectives specified.</span>
<span class="sd">        shuffle : bool</span>
<span class="sd">            If True, randomize the data into different minibatches each epoch</span>
<span class="sd">        truncation: int</span>
<span class="sd">            If not None, use truncated backpropagation when training the</span>
<span class="sd">            network, with the given truncation length.</span>
<span class="sd">        summaries : list of `~nengo.Connection` or \</span>
<span class="sd">                            `~nengo.Ensemble` or \</span>
<span class="sd">                            `~nengo.ensemble.Neurons` or \</span>
<span class="sd">                            ``&quot;loss&quot;`` or \</span>
<span class="sd">                            ``tf.Tensor``</span>
<span class="sd">            If not None, collect data during the training process using</span>
<span class="sd">            TensorFlow&#39;s ``tf.summary`` format.  The summary objects can be a</span>
<span class="sd">            Connection (in which case data on the corresponding weights will be</span>
<span class="sd">            collected), Ensemble (encoders), Neurons (biases), or ``&quot;loss&quot;``</span>
<span class="sd">            (the loss value for ``objective``).  The user can also create their</span>
<span class="sd">            own summaries and pass in the Tensors representing the summary ops.</span>
<span class="sd">        profile : bool</span>
<span class="sd">            If True, collect TensorFlow profiling information while the</span>
<span class="sd">            simulation is running (this will slow down the simulation).</span>
<span class="sd">            Can also pass a string specifying a non-default filename for the</span>
<span class="sd">            saved profile data.</span>
<span class="sd">        extra_feeds : dict of {``tf.Tensor``: `~numpy.ndarray`}</span>
<span class="sd">            Can be used to feed a value for arbitrary Tensors in the simulation</span>
<span class="sd">            (will be passed directly to the TensorFlow session)</span>
<span class="sd">        progress_bar : bool</span>
<span class="sd">            If True, print information about the simulation status to standard</span>
<span class="sd">            output.</span>

<span class="sd">        Notes</span>
<span class="sd">        -----</span>
<span class="sd">        Most deep learning methods require the network to be differentiable,</span>
<span class="sd">        which means that trying to train a network with non-differentiable</span>
<span class="sd">        elements will result in an error.  Examples of common</span>
<span class="sd">        non-differentiable elements include `~nengo.LIF`,</span>
<span class="sd">        `~nengo.Direct`, or processes/neurons that don&#39;t have a</span>
<span class="sd">        custom TensorFlow implementation (see</span>
<span class="sd">        `.process_builders.SimProcessBuilder`/</span>
<span class="sd">        `.neuron_builders.SimNeuronsBuilder`)</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
            <span class="n">batch_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">minibatch_size</span>
            <span class="n">n_steps</span> <span class="o">=</span> <span class="n">data</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">batch_size</span><span class="p">,</span> <span class="n">n_steps</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">values</span><span class="p">()))</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="mi">2</span><span class="p">]</span>

        <span class="c1"># error checking</span>
        <span class="n">synapses</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="o">.</span><span class="n">synapse</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span>
                    <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">toplevel</span><span class="o">.</span><span class="n">all_connections</span>
                     <span class="o">+</span> <span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">p</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">data</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">Probe</span><span class="p">))</span>
                        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="nb">dict</span><span class="p">)</span> <span class="k">else</span> <span class="p">[]))]</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">n_steps</span> <span class="o">==</span> <span class="mi">1</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">toplevel</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
                <span class="ow">and</span> <span class="nb">any</span><span class="p">(</span><span class="n">synapses</span><span class="p">)):</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                <span class="s2">&quot;Training for one timestep, but the network contains &quot;</span>
                <span class="s2">&quot;synaptic filters (which will introduce at least a &quot;</span>
                <span class="s2">&quot;one-timestep delay); did you mean to set synapse=None?&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
            <span class="k">raise</span> <span class="n">ValidationError</span><span class="p">(</span>
                <span class="s2">&quot;The second argument to `sim.train` should be a &quot;</span>
                <span class="s2">&quot;tf.train.Optimizer, not a dictionary; it is likely that this &quot;</span>
                <span class="s2">&quot;code was written for NengoDL 1.x and needs to be updated for &quot;</span>
                <span class="s2">&quot;NengoDL 2.x; see &quot;</span>
                <span class="s2">&quot;https://www.nengo.ai/nengo-dl/project.html#release-history&quot;</span><span class="p">,</span>
                <span class="s2">&quot;optimizer&quot;</span><span class="p">)</span>

        <span class="c1"># fill in default objective</span>
        <span class="k">if</span> <span class="n">objective</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
                <span class="k">raise</span> <span class="n">ValidationError</span><span class="p">(</span>
                    <span class="s2">&quot;Must specify an explicit objective if no input data &quot;</span>
                    <span class="s2">&quot;given&quot;</span><span class="p">,</span> <span class="s2">&quot;objective&quot;</span><span class="p">)</span>
            <span class="n">objective</span> <span class="o">=</span> <span class="p">{</span>
                <span class="n">p</span><span class="p">:</span> <span class="n">objectives</span><span class="o">.</span><span class="n">mse</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">data</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">Probe</span><span class="p">)}</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">objective</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
            <span class="k">raise</span> <span class="n">ValidationError</span><span class="p">(</span><span class="s2">&quot;Must be a dictionary mapping Probes to &quot;</span>
                                  <span class="s2">&quot;objective functions&quot;</span><span class="p">,</span> <span class="s2">&quot;objective&quot;</span><span class="p">)</span>

        <span class="c1"># fill in mse function</span>
        <span class="k">for</span> <span class="n">p</span><span class="p">,</span> <span class="n">o</span> <span class="ow">in</span> <span class="n">objective</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="k">if</span> <span class="n">o</span> <span class="o">==</span> <span class="s2">&quot;mse&quot;</span><span class="p">:</span>
                <span class="c1"># TODO: remove in 3.0.0</span>
                <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                    <span class="s2">&quot;Using the string &#39;mse&#39; for the objective is deprecated, &quot;</span>
                    <span class="s2">&quot;and will no longer be supported in the future; please &quot;</span>
                    <span class="s2">&quot;use the function `nengo_dl.objectives.mse` in the future&quot;</span><span class="p">,</span>
                    <span class="ne">DeprecationWarning</span><span class="p">)</span>

                <span class="n">objective</span><span class="p">[</span><span class="n">p</span><span class="p">]</span> <span class="o">=</span> <span class="n">objectives</span><span class="o">.</span><span class="n">mse</span>

        <span class="c1"># build the output function</span>
        <span class="n">apply_optimizer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tensor_graph</span><span class="o">.</span><span class="n">build_optimizer_func</span><span class="p">(</span>
            <span class="n">optimizer</span><span class="p">,</span> <span class="n">objective</span><span class="p">)</span>

        <span class="n">extra_fetches</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>

        <span class="c1"># add summaries</span>
        <span class="k">if</span> <span class="n">summaries</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">summary</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="s2">&quot;Simulator was created with tensorboard=False; &quot;</span>
                              <span class="s2">&quot;ignoring requested summaries&quot;</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">summaries</span><span class="p">):</span>
                    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span> <span class="ow">and</span> <span class="n">v</span> <span class="o">==</span> <span class="s2">&quot;loss&quot;</span><span class="p">:</span>
                        <span class="n">summaries</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">objective</span>
                <span class="n">summary_op</span><span class="p">,</span> <span class="n">init</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tensor_graph</span><span class="o">.</span><span class="n">build_summaries</span><span class="p">(</span><span class="n">summaries</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">init</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="c1"># initialize any variables created when building summaries</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">init</span><span class="p">)</span>
                <span class="n">extra_fetches</span><span class="p">[</span><span class="s2">&quot;summaries&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">summary_op</span>

        <span class="n">progress</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">utils</span><span class="o">.</span><span class="n">ProgressBar</span><span class="p">(</span>
                <span class="s2">&quot;Training&quot;</span><span class="p">,</span> <span class="n">max_value</span><span class="o">=</span><span class="p">(</span>
                    <span class="n">n_epochs</span> <span class="o">*</span> <span class="p">(</span><span class="n">batch_size</span> <span class="o">//</span> <span class="bp">self</span><span class="o">.</span><span class="n">minibatch_size</span><span class="p">)</span>
                    <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="k">if</span> <span class="n">truncation</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">n_steps</span> <span class="o">//</span> <span class="n">truncation</span><span class="p">)),</span>
                <span class="nb">vars</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;loss&quot;</span><span class="p">])</span> <span class="k">if</span> <span class="n">progress_bar</span> <span class="k">else</span> <span class="n">utils</span><span class="o">.</span><span class="n">NullProgressBar</span><span class="p">())</span>

        <span class="n">objective_probes</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">objective</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>

        <span class="k">def</span> <span class="nf">callback</span><span class="p">(</span><span class="n">out_vals</span><span class="p">,</span> <span class="n">extra_vals</span><span class="p">):</span>
            <span class="c1"># update progress bar, with loss value</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">out_vals</span><span class="p">[</span><span class="n">objective_probes</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span>
            <span class="c1"># loss will be {} if only direct grads used when calculating</span>
            <span class="c1"># gradient</span>
            <span class="n">kwargs</span> <span class="o">=</span> <span class="p">{}</span> <span class="k">if</span> <span class="n">loss</span> <span class="o">==</span> <span class="p">{}</span> <span class="k">else</span> <span class="nb">dict</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s2">&quot;</span><span class="si">%.4f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">loss</span><span class="p">)</span>
            <span class="n">progress</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

            <span class="c1"># export summaries to tensorboard</span>
            <span class="k">if</span> <span class="s2">&quot;summaries&quot;</span> <span class="ow">in</span> <span class="n">extra_vals</span><span class="p">:</span>
                <span class="c1"># note: the first output value is the new value of the</span>
                <span class="c1"># global training_step</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">summary</span><span class="o">.</span><span class="n">add_summary</span><span class="p">(</span><span class="n">extra_vals</span><span class="p">[</span><span class="s2">&quot;summaries&quot;</span><span class="p">],</span>
                                         <span class="n">out_vals</span><span class="p">[</span><span class="n">objective_probes</span><span class="p">][</span><span class="mi">0</span><span class="p">])</span>

        <span class="c1"># run training</span>
        <span class="k">with</span> <span class="n">progress</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">run_batch</span><span class="p">(</span>
                <span class="n">data</span><span class="p">,</span> <span class="p">{</span><span class="n">objective_probes</span><span class="p">:</span> <span class="n">apply_optimizer</span><span class="p">},</span>
                <span class="n">n_epochs</span><span class="o">=</span><span class="n">n_epochs</span><span class="p">,</span> <span class="n">combine</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="kc">None</span><span class="p">,</span>
                <span class="n">extra_feeds</span><span class="o">=</span><span class="n">extra_feeds</span><span class="p">,</span> <span class="n">extra_fetches</span><span class="o">=</span><span class="n">extra_fetches</span><span class="p">,</span>
                <span class="n">truncation</span><span class="o">=</span><span class="n">truncation</span><span class="p">,</span> <span class="n">profile</span><span class="o">=</span><span class="n">profile</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="n">shuffle</span><span class="p">,</span>
                <span class="n">training</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">callback</span><span class="o">=</span><span class="n">callback</span><span class="p">)</span></div>

<div class="viewcode-block" id="Simulator.loss"><a class="viewcode-back" href="../../reference.html#nengo_dl.simulator.Simulator.loss">[docs]</a>    <span class="k">def</span> <span class="nf">loss</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">objective</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">combine</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">,</span> <span class="n">extra_feeds</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
             <span class="n">progress_bar</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Compute the loss value for the given objective and inputs/targets.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        data : dict of {`~nengo.Node` or `~nengo.Probe`: \</span>
<span class="sd">                        `~numpy.ndarray`} or int</span>
<span class="sd">            Input values for Nodes in the network or target values for Probes;</span>
<span class="sd">            arrays should have shape ``(batch_size, n_steps,</span>
<span class="sd">            node.size_out/probe.size_in)``.  If no input data is required,</span>
<span class="sd">            an integer can be given specifying the number of timesteps to</span>
<span class="sd">            run the simulation.</span>
<span class="sd">        objective : dict of {(tuple of) `~nengo.Probe`: callable}</span>
<span class="sd">            The objective to compute the loss. The default applies</span>
<span class="sd">            `.objectives.mse` to all probes in ``data``.  This can be</span>
<span class="sd">            overridden by passing a dictionary mapping Probes to functions</span>
<span class="sd">            ``f(output, target) -&gt; loss`` that consume the actual output and</span>
<span class="sd">            target output for the given probe(s) and return a ``tf.Tensor``</span>
<span class="sd">            representing a scalar loss value.  The function may also accept a</span>
<span class="sd">            single argument ``f(output) -&gt; loss`` if targets are not required.</span>
<span class="sd">            Some common objective functions can be found in</span>
<span class="sd">            `nengo_dl.objectives`.</span>

<span class="sd">            If multiple probes are specified as the key, then the corresponding</span>
<span class="sd">            output/target values will be passed as a list to the objective</span>
<span class="sd">            function.</span>

<span class="sd">            The overall value returned will be the sum across all</span>
<span class="sd">            the objectives specified.</span>
<span class="sd">        combine : callable</span>
<span class="sd">            Function used to combine objective values from each minibatch.</span>
<span class="sd">        extra_feeds : dict of {``tf.Tensor``: `~numpy.ndarray`}</span>
<span class="sd">            Can be used to feed a value for arbitrary Tensors in the simulation</span>
<span class="sd">            (will be passed directly to the TensorFlow session)</span>
<span class="sd">        progress_bar : bool</span>
<span class="sd">            If True, print information about the simulation status to standard</span>
<span class="sd">            output.</span>
<span class="sd">        training : bool</span>
<span class="sd">            If True, run the network in training mode (where, e.g., spiking</span>
<span class="sd">            neuron models are swapped for the equivalent differentiable</span>
<span class="sd">            approximation).</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        loss : float</span>
<span class="sd">            Sum of computed error values for each function in ``objective``.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">batch_size</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">minibatch_size</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span> <span class="k">else</span>
                      <span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">values</span><span class="p">()))</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

        <span class="c1"># fill in default objective</span>
        <span class="k">if</span> <span class="n">objective</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
                <span class="k">raise</span> <span class="n">ValidationError</span><span class="p">(</span>
                    <span class="s2">&quot;Must specify an explicit objective if no input data &quot;</span>
                    <span class="s2">&quot;given&quot;</span><span class="p">,</span> <span class="s2">&quot;objective&quot;</span><span class="p">)</span>
            <span class="n">objective</span> <span class="o">=</span> <span class="p">{</span>
                <span class="n">p</span><span class="p">:</span> <span class="n">objectives</span><span class="o">.</span><span class="n">mse</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">data</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">Probe</span><span class="p">)}</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">objective</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
            <span class="k">raise</span> <span class="n">ValidationError</span><span class="p">(</span><span class="s2">&quot;Must be a dictionary mapping Probes to &quot;</span>
                                  <span class="s2">&quot;objective functions&quot;</span><span class="p">,</span> <span class="s2">&quot;objective&quot;</span><span class="p">)</span>

        <span class="c1"># fill in mse function</span>
        <span class="k">for</span> <span class="n">p</span><span class="p">,</span> <span class="n">o</span> <span class="ow">in</span> <span class="n">objective</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="k">if</span> <span class="n">o</span> <span class="o">==</span> <span class="s2">&quot;mse&quot;</span><span class="p">:</span>
                <span class="c1"># TODO: remove in 3.0.0</span>
                <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                    <span class="s2">&quot;Using the string &#39;mse&#39; for the objective is deprecated, &quot;</span>
                    <span class="s2">&quot;and will no longer be supported in the future; please &quot;</span>
                    <span class="s2">&quot;use the function `nengo_dl.objectives.mse` in the future&quot;</span><span class="p">,</span>
                    <span class="ne">DeprecationWarning</span><span class="p">)</span>

                <span class="n">objective</span><span class="p">[</span><span class="n">p</span><span class="p">]</span> <span class="o">=</span> <span class="n">objectives</span><span class="o">.</span><span class="n">mse</span>

        <span class="n">progress</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">utils</span><span class="o">.</span><span class="n">ProgressBar</span><span class="p">(</span><span class="s2">&quot;Calculating loss&quot;</span><span class="p">,</span> <span class="s2">&quot;Calculation&quot;</span><span class="p">,</span>
                              <span class="n">max_value</span><span class="o">=</span><span class="n">batch_size</span> <span class="o">//</span> <span class="bp">self</span><span class="o">.</span><span class="n">minibatch_size</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">progress_bar</span> <span class="k">else</span> <span class="n">utils</span><span class="o">.</span><span class="n">NullProgressBar</span><span class="p">())</span>
        <span class="k">with</span> <span class="n">progress</span><span class="p">:</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">run_batch</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">objective</span><span class="p">,</span> <span class="n">extra_feeds</span><span class="o">=</span><span class="n">extra_feeds</span><span class="p">,</span>
                                  <span class="n">callback</span><span class="o">=</span><span class="k">lambda</span> <span class="o">*</span><span class="n">_</span><span class="p">:</span> <span class="n">progress</span><span class="o">.</span><span class="n">step</span><span class="p">(),</span>
                                  <span class="n">combine</span><span class="o">=</span><span class="n">combine</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="n">training</span><span class="p">)</span>

        <span class="c1"># sum across objectives</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">loss</span><span class="o">.</span><span class="n">values</span><span class="p">()))</span>

        <span class="k">return</span> <span class="n">loss</span></div>

<div class="viewcode-block" id="Simulator.run_batch"><a class="viewcode-back" href="../../reference.html#nengo_dl.simulator.Simulator.run_batch">[docs]</a>    <span class="k">def</span> <span class="nf">run_batch</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">outputs</span><span class="p">,</span> <span class="n">extra_feeds</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">extra_fetches</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                  <span class="n">n_epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">profile</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                  <span class="n">training</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">callback</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">combine</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">stack</span><span class="p">,</span>
                  <span class="n">isolate_state</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Run the simulation on a batch of input data, computing the given</span>
<span class="sd">        output functions.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        data : dict of {`~nengo.Node` or `~nengo.Probe`: \</span>
<span class="sd">                        `~numpy.ndarray`} or int</span>
<span class="sd">            Input values for Nodes in the network or target values for Probes;</span>
<span class="sd">            arrays should have shape ``(batch_size, n_steps,</span>
<span class="sd">            node.size_out/probe.size_in)``.  If no input data is required,</span>
<span class="sd">            an integer can be given specifying the number of timesteps to</span>
<span class="sd">            run the simulation.</span>
<span class="sd">        outputs : dict of {(tuple of) `~nengo.Probe`: callable or None}</span>
<span class="sd">            Functions to apply to probe outputs.  Functions can accept one</span>
<span class="sd">            positional argument (the output from that probe on one minibatch)</span>
<span class="sd">            or two (also passed the corresponding target value from ``data``).</span>
<span class="sd">            If a tuple of Probes are given as the key then the first</span>
<span class="sd">            argument will be a list of probe outputs, and the second</span>
<span class="sd">            argument will be the corresponding list of target values.  The</span>
<span class="sd">            function can return a ``tf.Tensor``, or tuple of Tensors,</span>
<span class="sd">            which will be evaluated on each minibatch of data.  If ``None``</span>
<span class="sd">            is given then the return value will be the output value from that</span>
<span class="sd">            probe.</span>
<span class="sd">        extra_feeds : dict of {``tf.Tensor``: `~numpy.ndarray`}</span>
<span class="sd">            Can be used to feed a value for arbitrary Tensors in the simulation</span>
<span class="sd">            (will be passed directly to the TensorFlow session)</span>
<span class="sd">        extra_fetches : (list/tuple/dict of) ``tf.Tensor``</span>
<span class="sd">            Can be used to fetch arbitrary (structures of) Tensor values from</span>
<span class="sd">            the simulation (will be fetched directly from the TensorFlow</span>
<span class="sd">            session).</span>
<span class="sd">        n_epochs : int</span>
<span class="sd">            Repeat ``data`` for ``n_epochs`` iterations.</span>
<span class="sd">        truncation : int</span>
<span class="sd">            If not None, run the simulation ``truncation`` timesteps at a time.</span>
<span class="sd">            Outputs from each truncation block will be passed sequentially to</span>
<span class="sd">            ``combine``, in the same way as minibatch blocks.  Note</span>
<span class="sd">            that the simulation state is preserved between truncation blocks,</span>
<span class="sd">            so the sequence forms one continuous run within each minibatch.</span>
<span class="sd">        shuffle : bool</span>
<span class="sd">            If True, randomize the data into different minibatches each epoch.</span>
<span class="sd">        profile : bool</span>
<span class="sd">            If True, collect TensorFlow profiling information while the</span>
<span class="sd">            simulation is running (this will slow down the simulation).</span>
<span class="sd">            Can also pass a string specifying a non-default filename for the</span>
<span class="sd">            saved profile data.</span>
<span class="sd">        training : bool</span>
<span class="sd">            If True, run the network in training mode, otherwise run it in</span>
<span class="sd">            inference mode (this can affect things like the neuron model</span>
<span class="sd">            used).</span>
<span class="sd">        callback : callable</span>
<span class="sd">            A function that will be called after each minibatch is evaluated.</span>
<span class="sd">            The function is passed two arguments; the first is a dictionary</span>
<span class="sd">            corresponding to ``outputs`` with the output values from each</span>
<span class="sd">            function, and the second is the value of ``extra_feeds``.</span>
<span class="sd">        combine : callable</span>
<span class="sd">            The function that will be used to combine the outputs from each</span>
<span class="sd">            minibatch/truncation block.  The values from each output function</span>
<span class="sd">            on each minibatch will be formed into a list and passed to</span>
<span class="sd">            ``combine`` in order to compute the final return values from</span>
<span class="sd">            this function.  Note that if the output function returns multiple</span>
<span class="sd">            values, then ``combine`` will be applied separately to each of</span>
<span class="sd">            those outputs across the minibatches.</span>
<span class="sd">        isolate_state : bool</span>
<span class="sd">            If True (default), isolate the simulation state for this run</span>
<span class="sd">            from the rest of the simulation (so the execution of this run</span>
<span class="sd">            is not affected by previous runs and will not affect future runs).</span>
<span class="sd">            If False, then this run begins from the terminal state of the</span>
<span class="sd">            last run, each minibatch will continue in sequence from the state</span>
<span class="sd">            of the previous, and future runs will resume from the terminal</span>
<span class="sd">            state of the last minibatch of this run.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        output_vals : dict of {(tuple of) `~nengo.Probe`: \</span>
<span class="sd">                               (tuple of) `~numpy.ndarray`}</span>
<span class="sd">            The result of computing ``outputs`` on simulation probe values,</span>
<span class="sd">            given ``data``.  This pseudocode may help to understand how the</span>
<span class="sd">            return values are constructed given the various parameters of this</span>
<span class="sd">            function:</span>

<span class="sd">            .. code-block:: python</span>

<span class="sd">                output_vals = {}</span>
<span class="sd">                for probe, func in outputs.items():</span>
<span class="sd">                    probe_vals = []</span>
<span class="sd">                    for i in range(n_epochs):</span>
<span class="sd">                        for minibatch in data:</span>
<span class="sd">                            network_output = run_network(minibatch)</span>
<span class="sd">                            probe_vals.append(func(network_output[probe]))</span>
<span class="sd">                    output_vals[probe] = combine(output_values)</span>

<span class="sd">            Note that this is not how the values are computed in practice,</span>
<span class="sd">            as it would be quite inefficient.  This pseudocode also omits</span>
<span class="sd">            some of the finer details (e.g. truncation and state isolation).</span>

<span class="sd">        Notes</span>
<span class="sd">        -----</span>
<span class="sd">        In general, users should call one of the wrappers for this function</span>
<span class="sd">        (e.g., `.run_steps`, `.train`, or `.loss`),</span>
<span class="sd">        according to their use case.  However, this function can be called</span>
<span class="sd">        directly to run the simulation in a customized way.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">n_steps</span> <span class="o">=</span> <span class="p">(</span><span class="n">data</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span> <span class="k">else</span>
                   <span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">values</span><span class="p">()))</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>

        <span class="c1"># error checking</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">closed</span><span class="p">:</span>
            <span class="k">raise</span> <span class="n">SimulatorClosed</span><span class="p">(</span><span class="s2">&quot;Simulator cannot run because it is closed.&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_check_data</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">n_steps</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">unroll</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="n">ValidationError</span><span class="p">(</span>
                <span class="s2">&quot;The number of timesteps in batch data must be evenly &quot;</span>
                <span class="s2">&quot;divisible by unroll_simulation&quot;</span><span class="p">,</span> <span class="s2">&quot;data&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">truncation</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">truncation</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">unroll</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="n">ValidationError</span><span class="p">(</span>
                <span class="s2">&quot;Truncation length must be evenly divisible by &quot;</span>
                <span class="s2">&quot;unroll_simulation&quot;</span><span class="p">,</span> <span class="s2">&quot;truncation&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">training</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">tensor_graph</span><span class="o">.</span><span class="n">inference_only</span><span class="p">:</span>
            <span class="k">raise</span> <span class="n">ValidationError</span><span class="p">(</span>
                <span class="s2">&quot;Network was created with inference_only=True, cannot &quot;</span>
                <span class="s2">&quot;be run in training mode&quot;</span><span class="p">,</span> <span class="s2">&quot;inference_only&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">extra_fetches</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">extra_fetches</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="c1"># apply functions (if any) to output probes</span>
        <span class="n">output_ops</span><span class="p">,</span> <span class="n">init_ops</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tensor_graph</span><span class="o">.</span><span class="n">build_outputs</span><span class="p">(</span><span class="n">outputs</span><span class="p">)</span>

        <span class="c1"># initialize any new variables</span>
        <span class="k">if</span> <span class="n">init_ops</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">init_ops</span><span class="p">)</span>

        <span class="c1"># save the internal state of the simulator</span>
        <span class="k">if</span> <span class="n">isolate_state</span><span class="p">:</span>
            <span class="n">tmpdir</span> <span class="o">=</span> <span class="n">tempfile</span><span class="o">.</span><span class="n">TemporaryDirectory</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">save_params</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">tmpdir</span><span class="o">.</span><span class="n">name</span><span class="p">,</span> <span class="s2">&quot;tmp&quot;</span><span class="p">),</span>
                             <span class="n">include_local</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">include_global</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

        <span class="c1"># set up profiling</span>
        <span class="k">if</span> <span class="n">profile</span><span class="p">:</span>
            <span class="n">run_options</span> <span class="o">=</span> <span class="n">tf_compat</span><span class="o">.</span><span class="n">RunOptions</span><span class="p">(</span>
                <span class="n">trace_level</span><span class="o">=</span><span class="n">tf_compat</span><span class="o">.</span><span class="n">RunOptions</span><span class="o">.</span><span class="n">FULL_TRACE</span><span class="p">)</span>
            <span class="n">run_metadata</span> <span class="o">=</span> <span class="n">tf_compat</span><span class="o">.</span><span class="n">RunMetadata</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">run_options</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="n">run_metadata</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="c1"># compute outputs on batch</span>
        <span class="n">output_vals</span> <span class="o">=</span> <span class="n">collections</span><span class="o">.</span><span class="n">defaultdict</span><span class="p">(</span><span class="nb">list</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_epochs</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">offset</span><span class="p">,</span> <span class="n">mini_data</span> <span class="ow">in</span> <span class="n">utils</span><span class="o">.</span><span class="n">minibatch_generator</span><span class="p">(</span>
                    <span class="n">data</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">minibatch_size</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="n">truncation</span><span class="p">,</span>
                    <span class="n">shuffle</span><span class="o">=</span><span class="n">shuffle</span><span class="p">,</span> <span class="n">rng</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">rng</span><span class="p">):</span>
                <span class="k">if</span> <span class="n">offset</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">isolate_state</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">soft_reset</span><span class="p">()</span>

                <span class="c1"># fill in feed_dict values</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">mini_data</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
                    <span class="n">steps</span> <span class="o">=</span> <span class="n">mini_data</span>
                    <span class="n">mini_data</span> <span class="o">=</span> <span class="kc">None</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">steps</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">mini_data</span><span class="o">.</span><span class="n">values</span><span class="p">()))</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
                <span class="n">feed</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_fill_feed</span><span class="p">(</span>
                    <span class="n">steps</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">mini_data</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="n">training</span><span class="p">,</span>
                    <span class="n">start</span><span class="o">=</span><span class="n">offset</span> <span class="o">+</span> <span class="p">(</span><span class="mi">0</span> <span class="k">if</span> <span class="n">isolate_state</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_steps</span><span class="p">))</span>
                <span class="k">if</span> <span class="n">extra_feeds</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">feed</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">extra_feeds</span><span class="p">)</span>

                <span class="c1"># run the simulation</span>
                <span class="k">try</span><span class="p">:</span>
                    <span class="n">out_vals</span><span class="p">,</span> <span class="n">extra_vals</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span>
                        <span class="p">(</span><span class="n">output_ops</span><span class="p">,</span> <span class="n">extra_fetches</span><span class="p">),</span> <span class="n">feed_dict</span><span class="o">=</span><span class="n">feed</span><span class="p">,</span>
                        <span class="n">options</span><span class="o">=</span><span class="n">run_options</span><span class="p">,</span> <span class="n">run_metadata</span><span class="o">=</span><span class="n">run_metadata</span><span class="p">)</span>
                <span class="k">except</span> <span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">errors</span><span class="o">.</span><span class="n">InternalError</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">errors</span><span class="o">.</span><span class="n">UnknownError</span><span class="p">)</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                    <span class="k">if</span> <span class="n">e</span><span class="o">.</span><span class="n">op</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">e</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">type</span> <span class="o">==</span> <span class="s2">&quot;PyFunc&quot;</span><span class="p">:</span>
                        <span class="k">raise</span> <span class="n">SimulationError</span><span class="p">(</span>
                            <span class="s2">&quot;Function &#39;</span><span class="si">%s</span><span class="s2">&#39; caused an error (see error log &quot;</span>
                            <span class="s2">&quot;above)&quot;</span> <span class="o">%</span> <span class="n">e</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">name</span><span class="p">)</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="k">raise</span> <span class="n">e</span>  <span class="c1"># pragma: no cover (unknown errors)</span>

                <span class="k">if</span> <span class="n">callback</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">callback</span><span class="p">(</span><span class="n">out_vals</span><span class="p">,</span> <span class="n">extra_vals</span><span class="p">)</span>

                <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">out_vals</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                    <span class="n">output_vals</span><span class="p">[</span><span class="n">k</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>

        <span class="c1"># restore internal state of simulator</span>
        <span class="k">if</span> <span class="n">isolate_state</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">load_params</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">tmpdir</span><span class="o">.</span><span class="n">name</span><span class="p">,</span> <span class="s2">&quot;tmp&quot;</span><span class="p">),</span>
                             <span class="n">include_local</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">include_global</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
            <span class="n">tmpdir</span><span class="o">.</span><span class="n">cleanup</span><span class="p">()</span>

        <span class="c1"># combine outputs from each minibatch</span>
        <span class="k">for</span> <span class="n">probe</span><span class="p">,</span> <span class="n">vals</span> <span class="ow">in</span> <span class="n">output_vals</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="c1"># if the output function returns multiple items, keep those</span>
            <span class="c1"># arrays separate</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">vals</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)):</span>
                <span class="n">output_vals</span><span class="p">[</span><span class="n">probe</span><span class="p">]</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">combine</span><span class="p">(</span><span class="n">v</span><span class="p">)</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="n">vals</span><span class="p">))</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">output_vals</span><span class="p">[</span><span class="n">probe</span><span class="p">]</span> <span class="o">=</span> <span class="n">combine</span><span class="p">(</span><span class="n">vals</span><span class="p">)</span>

        <span class="c1"># convert back from defaultdict</span>
        <span class="n">output_vals</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">output_vals</span><span class="p">)</span>

        <span class="c1"># output profile data to file</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_profile_output</span><span class="p">(</span><span class="n">profile</span><span class="p">,</span> <span class="n">run_metadata</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">output_vals</span></div>

<div class="viewcode-block" id="Simulator.save_params"><a class="viewcode-back" href="../../reference.html#nengo_dl.simulator.Simulator.save_params">[docs]</a>    <span class="k">def</span> <span class="nf">save_params</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">,</span> <span class="n">include_global</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">include_local</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Save network parameters to the given ``path``.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        path : str</span>
<span class="sd">            Filepath of parameter output file</span>
<span class="sd">        include_global : bool</span>
<span class="sd">            If True (default True), save global/trainable network variables</span>
<span class="sd">        include_local : bool</span>
<span class="sd">            If True (default False), save local (non-trainable) network</span>
<span class="sd">            variables</span>

<span class="sd">        Notes</span>
<span class="sd">        -----</span>
<span class="sd">        This function is useful for saving/loading entire models; for</span>
<span class="sd">        saving/loading individual objects within a model, see</span>
<span class="sd">        `.get_nengo_params`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">closed</span><span class="p">:</span>
            <span class="k">raise</span> <span class="n">SimulatorClosed</span><span class="p">(</span><span class="s2">&quot;Simulation has been closed, cannot save &quot;</span>
                                  <span class="s2">&quot;parameters&quot;</span><span class="p">)</span>

        <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">tensor_graph</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">as_default</span><span class="p">():</span>
            <span class="nb">vars</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">if</span> <span class="n">include_global</span><span class="p">:</span>
                <span class="nb">vars</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">tf_compat</span><span class="o">.</span><span class="n">global_variables</span><span class="p">())</span>
            <span class="k">if</span> <span class="n">include_local</span><span class="p">:</span>
                <span class="nb">vars</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">tf_compat</span><span class="o">.</span><span class="n">local_variables</span><span class="p">())</span>

            <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;/cpu:0&quot;</span><span class="p">):</span>
                <span class="n">path</span> <span class="o">=</span> <span class="n">tf_compat</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">Saver</span><span class="p">(</span><span class="nb">vars</span><span class="p">)</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">sess</span><span class="p">,</span> <span class="n">path</span><span class="p">)</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Model parameters saved to </span><span class="si">%s</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">path</span><span class="p">)</span></div>

<div class="viewcode-block" id="Simulator.load_params"><a class="viewcode-back" href="../../reference.html#nengo_dl.simulator.Simulator.load_params">[docs]</a>    <span class="k">def</span> <span class="nf">load_params</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">,</span> <span class="n">include_global</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">include_local</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Load network parameters from the given ``path``.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        path : str</span>
<span class="sd">            Filepath of parameter input file</span>
<span class="sd">        include_global : bool</span>
<span class="sd">            If True (default True), load global (trainable) network variables</span>
<span class="sd">        include_local : bool</span>
<span class="sd">            If True (default False), load local (non-trainable) network</span>
<span class="sd">            variables</span>

<span class="sd">        Notes</span>
<span class="sd">        -----</span>
<span class="sd">        This function is useful for saving/loading entire models; for</span>
<span class="sd">        saving/loading individual objects within a model, see</span>
<span class="sd">        `.get_nengo_params`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">closed</span><span class="p">:</span>
            <span class="k">raise</span> <span class="n">SimulatorClosed</span><span class="p">(</span><span class="s2">&quot;Simulation has been closed, cannot load &quot;</span>
                                  <span class="s2">&quot;parameters&quot;</span><span class="p">)</span>

        <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">tensor_graph</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">as_default</span><span class="p">():</span>
            <span class="nb">vars</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">if</span> <span class="n">include_global</span><span class="p">:</span>
                <span class="nb">vars</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">tf_compat</span><span class="o">.</span><span class="n">global_variables</span><span class="p">())</span>
            <span class="k">if</span> <span class="n">include_local</span><span class="p">:</span>
                <span class="nb">vars</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">tf_compat</span><span class="o">.</span><span class="n">local_variables</span><span class="p">())</span>

            <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;/cpu:0&quot;</span><span class="p">):</span>
                <span class="n">tf_compat</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">Saver</span><span class="p">(</span><span class="nb">vars</span><span class="p">)</span><span class="o">.</span><span class="n">restore</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">sess</span><span class="p">,</span> <span class="n">path</span><span class="p">)</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Model parameters loaded from </span><span class="si">%s</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">path</span><span class="p">)</span></div>

<div class="viewcode-block" id="Simulator.freeze_params"><a class="viewcode-back" href="../../reference.html#nengo_dl.simulator.Simulator.freeze_params">[docs]</a>    <span class="k">def</span> <span class="nf">freeze_params</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">objs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Stores the live parameter values from the simulation back into a</span>
<span class="sd">        Nengo object definition.</span>

<span class="sd">        This can be helpful for reusing a NengoDL model inside a different</span>
<span class="sd">        Simulator.  For example:</span>

<span class="sd">        .. code-block:: python</span>

<span class="sd">            with nengo.Network() as net:</span>
<span class="sd">                &lt; build network &gt;</span>

<span class="sd">            with nengo_dl.Simulator(net) as sim:</span>
<span class="sd">                &lt; run some optimization &gt;</span>
<span class="sd">                sim.freeze_params(net)</span>

<span class="sd">            with nengo.Simulator(net) as sim2:</span>
<span class="sd">                # run the network in the default Nengo simulator, with the</span>
<span class="sd">                # trained parameters</span>
<span class="sd">                sim2.run(1.0)</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        obj : (list of) ``NengoObject``</span>
<span class="sd">            The Nengo object(s) into which parameter values will be stored.</span>
<span class="sd">            Note that these objects must be members of the Network used to</span>
<span class="sd">            initialize the Simulator.</span>

<span class="sd">        Notes</span>
<span class="sd">        -----</span>
<span class="sd">        This modifies the source object in-place, and it may slightly modify</span>
<span class="sd">        the structure of that object.  The goal is to have the object produce</span>
<span class="sd">        the same output as it would if run in the NengoDL simulator.  It may</span>
<span class="sd">        not be possible to accurately freeze all possible object; if you run</span>
<span class="sd">        into errors in this process, try manually extracting the parameters you</span>
<span class="sd">        need in your model (from ``sim.data``).</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">closed</span><span class="p">:</span>
            <span class="k">raise</span> <span class="n">SimulatorClosed</span><span class="p">(</span><span class="s2">&quot;Simulation has been closed, cannot freeze &quot;</span>
                                  <span class="s2">&quot;parameters&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">objs</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)):</span>
            <span class="n">objs</span> <span class="o">=</span> <span class="p">[</span><span class="n">objs</span><span class="p">]</span>

        <span class="k">for</span> <span class="n">obj</span> <span class="ow">in</span> <span class="n">objs</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">obj</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">toplevel</span><span class="p">]</span>
                           <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">toplevel</span><span class="o">.</span><span class="n">all_objects</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">%s</span><span class="s2"> is not a member of the Network used to &quot;</span>
                                 <span class="s2">&quot;initialize the Simulator&quot;</span><span class="p">)</span>

            <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="p">(</span><span class="n">Network</span><span class="p">,</span> <span class="n">Ensemble</span><span class="p">,</span> <span class="n">Connection</span><span class="p">)):</span>
                <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;Objects of type </span><span class="si">%s</span><span class="s2"> do not have parameters &quot;</span>
                                <span class="s2">&quot;to store&quot;</span> <span class="o">%</span> <span class="nb">type</span><span class="p">(</span><span class="n">obj</span><span class="p">))</span>

            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="n">Network</span><span class="p">):</span>
                <span class="n">todo</span> <span class="o">=</span> <span class="n">obj</span><span class="o">.</span><span class="n">all_ensembles</span> <span class="o">+</span> <span class="n">obj</span><span class="o">.</span><span class="n">all_connections</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">todo</span> <span class="o">=</span> <span class="p">[</span><span class="n">obj</span><span class="p">]</span>

            <span class="k">for</span> <span class="n">o</span><span class="p">,</span> <span class="n">params</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">todo</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_nengo_params</span><span class="p">(</span><span class="n">todo</span><span class="p">)):</span>
                <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">params</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                    <span class="nb">setattr</span><span class="p">(</span><span class="n">o</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span><span class="p">)</span></div>

<div class="viewcode-block" id="Simulator.get_nengo_params"><a class="viewcode-back" href="../../reference.html#nengo_dl.simulator.Simulator.get_nengo_params">[docs]</a>    <span class="k">def</span> <span class="nf">get_nengo_params</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">nengo_objs</span><span class="p">,</span> <span class="n">as_dict</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Extract model parameters in a form that can be used to initialize</span>
<span class="sd">        Nengo objects in a different model.</span>

<span class="sd">        For example:</span>

<span class="sd">        .. code-block:: python</span>

<span class="sd">            with nengo.Network() as net:</span>
<span class="sd">                a = nengo.Ensemble(10, 1)</span>
<span class="sd">                b = nengo.Ensemble(10, 1)</span>
<span class="sd">                c = nengo.Connection(a, b)</span>

<span class="sd">            with nengo_dl.Simulator(net) as sim:</span>
<span class="sd">                # &lt; do some optimization &gt;</span>
<span class="sd">                params = sim.get_nengo_params([a, b, c])</span>

<span class="sd">            with nengo.Network() as new_net:</span>
<span class="sd">                # &lt; build some other network &gt;</span>

<span class="sd">                # now we want to insert two connected ensembles with</span>
<span class="sd">                # the same parameters as our previous network:</span>
<span class="sd">                d = nengo.Ensemble(10, 1, **params[0])</span>
<span class="sd">                e = nengo.Ensemble(10, 1, **params[1])</span>
<span class="sd">                f = nengo.Connection(d, e, **params[2])</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        nengo_objs : (list of) `~nengo.Ensemble` or `~nengo.Connection`</span>
<span class="sd">            A single object or list of objects for which we want to get the</span>
<span class="sd">            parameters.</span>
<span class="sd">        as_dict : bool</span>
<span class="sd">            If True, return the values as a dictionary keyed by object label,</span>
<span class="sd">            instead of a list (the default).  Note that in this case labels</span>
<span class="sd">            must be unique.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        params : (list or dict) of dicts</span>
<span class="sd">            kwarg dicts corresponding to ``nengo_objs`` (passing these</span>
<span class="sd">            dicts as kwargs when creating new Nengo objects will result in a</span>
<span class="sd">            new object with the same parameters as the source object).  A</span>
<span class="sd">            single kwarg dict if a single object was passed in, or a list</span>
<span class="sd">            (dict if ``as_dict=True``) of kwargs corresponding to multiple</span>
<span class="sd">            input objects.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">nengo_objs</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)):</span>
            <span class="n">scalar</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">scalar</span> <span class="o">=</span> <span class="kc">True</span>
            <span class="n">nengo_objs</span> <span class="o">=</span> <span class="p">[</span><span class="n">nengo_objs</span><span class="p">]</span>

        <span class="c1"># convert neurons to the parent ensemble</span>
        <span class="n">nengo_objs</span> <span class="o">=</span> <span class="p">[</span><span class="n">obj</span><span class="o">.</span><span class="n">ensemble</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="n">Neurons</span><span class="p">)</span> <span class="k">else</span> <span class="n">obj</span>
                      <span class="k">for</span> <span class="n">obj</span> <span class="ow">in</span> <span class="n">nengo_objs</span><span class="p">]</span>

        <span class="c1"># find all the data we need to fetch</span>
        <span class="n">fetches</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">obj</span> <span class="ow">in</span> <span class="n">nengo_objs</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="n">Connection</span><span class="p">):</span>
                <span class="n">fetches</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">obj</span><span class="p">,</span> <span class="s2">&quot;weights&quot;</span><span class="p">))</span>
            <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="n">Ensemble</span><span class="p">):</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">obj</span><span class="o">.</span><span class="n">neuron_type</span><span class="p">,</span> <span class="n">Direct</span><span class="p">):</span>
                    <span class="c1"># we cannot transfer direct ensemble parameters, because</span>
                    <span class="c1"># the nengo builder ignores the encoders specified for</span>
                    <span class="c1"># a direct ensemble</span>
                    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                        <span class="s2">&quot;get_nengo_params will not work correctly for &quot;</span>
                        <span class="s2">&quot;Direct neuron ensembles. Try manually translating &quot;</span>
                        <span class="s2">&quot;your network using `sim.data` instead.&quot;</span><span class="p">)</span>

                <span class="n">fetches</span><span class="o">.</span><span class="n">extend</span><span class="p">([(</span><span class="n">obj</span><span class="p">,</span> <span class="s2">&quot;scaled_encoders&quot;</span><span class="p">),</span> <span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="s2">&quot;bias&quot;</span><span class="p">)])</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s2">&quot;Can only get Nengo parameters for Ensembles or &quot;</span>
                    <span class="s2">&quot;Connections&quot;</span><span class="p">)</span>

        <span class="c1"># get parameter values from simulation</span>
        <span class="n">data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">get_params</span><span class="p">(</span><span class="o">*</span><span class="n">fetches</span><span class="p">)</span>

        <span class="c1"># store parameter values in a form that can be loaded in nengo</span>
        <span class="n">params</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">idx</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">obj</span> <span class="ow">in</span> <span class="n">nengo_objs</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="n">Connection</span><span class="p">):</span>
                <span class="n">weights</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>
                <span class="n">idx</span> <span class="o">+=</span> <span class="mi">1</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">obj</span><span class="o">.</span><span class="n">pre_obj</span><span class="p">,</span> <span class="n">Ensemble</span><span class="p">):</span>
                    <span class="n">params</span><span class="o">.</span><span class="n">append</span><span class="p">({</span>
                        <span class="s2">&quot;solver&quot;</span><span class="p">:</span> <span class="n">NoSolver</span><span class="p">(</span><span class="n">weights</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="kc">False</span><span class="p">),</span>
                        <span class="s2">&quot;function&quot;</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="n">weights</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span>
                            <span class="n">weights</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span>
                        <span class="s2">&quot;transform&quot;</span><span class="p">:</span> <span class="mi">1</span><span class="p">})</span>
                <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">obj</span><span class="o">.</span><span class="n">transform</span><span class="p">,</span> <span class="n">Convolution</span><span class="p">):</span>
                    <span class="n">transform</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">obj</span><span class="o">.</span><span class="n">transform</span><span class="p">)</span>
                    <span class="c1"># manually bypass the read-only check (we are sure that</span>
                    <span class="c1"># nothing else has a handle to the new transform at this</span>
                    <span class="c1"># point, so this won&#39;t cause any problems)</span>
                    <span class="n">Convolution</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">transform</span><span class="p">]</span> <span class="o">=</span> <span class="n">weights</span>
                    <span class="n">params</span><span class="o">.</span><span class="n">append</span><span class="p">({</span><span class="s2">&quot;transform&quot;</span><span class="p">:</span> <span class="n">transform</span><span class="p">})</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="k">if</span> <span class="nb">all</span><span class="p">(</span><span class="n">x</span> <span class="o">==</span> <span class="mi">1</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">weights</span><span class="o">.</span><span class="n">shape</span><span class="p">):</span>
                        <span class="n">weights</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">weights</span><span class="p">)</span>
                    <span class="n">params</span><span class="o">.</span><span class="n">append</span><span class="p">({</span><span class="s2">&quot;transform&quot;</span><span class="p">:</span> <span class="n">weights</span><span class="p">})</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># note: we don&#39;t want to change the original gain (even though</span>
                <span class="c1"># it is rolled into the encoder values), because connections</span>
                <span class="c1"># direct to `ens.neurons` will still use the gains (and those</span>
                <span class="c1"># gains are not updated during training, only the encoders)</span>
                <span class="n">gain</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="n">obj</span><span class="p">]</span><span class="o">.</span><span class="n">gain</span>

                <span class="c1"># the encoders we get from the simulation are the actual</span>
                <span class="c1"># weights we want in the simulation. but during the build</span>
                <span class="c1"># process, gains and radius will be applied to the encoders.</span>
                <span class="c1"># so we need to undo that scaling here, so that the build</span>
                <span class="c1"># process will result in the correct values.</span>
                <span class="n">encoders</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">*</span> <span class="n">obj</span><span class="o">.</span><span class="n">radius</span> <span class="o">/</span> <span class="n">gain</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">]</span>

                <span class="n">params</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                    <span class="p">{</span><span class="s2">&quot;encoders&quot;</span><span class="p">:</span> <span class="n">encoders</span><span class="p">,</span> <span class="s2">&quot;normalize_encoders&quot;</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span>
                     <span class="s2">&quot;gain&quot;</span><span class="p">:</span> <span class="n">gain</span><span class="p">,</span> <span class="s2">&quot;bias&quot;</span><span class="p">:</span> <span class="n">data</span><span class="p">[</span><span class="n">idx</span> <span class="o">+</span> <span class="mi">1</span><span class="p">],</span>
                     <span class="s2">&quot;max_rates&quot;</span><span class="p">:</span> <span class="n">Ensemble</span><span class="o">.</span><span class="n">max_rates</span><span class="o">.</span><span class="n">default</span><span class="p">,</span>
                     <span class="s2">&quot;intercepts&quot;</span><span class="p">:</span> <span class="n">Ensemble</span><span class="o">.</span><span class="n">intercepts</span><span class="o">.</span><span class="n">default</span><span class="p">})</span>
                <span class="n">idx</span> <span class="o">+=</span> <span class="mi">2</span>

        <span class="c1"># return params in appropriate format</span>
        <span class="k">if</span> <span class="n">scalar</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">params</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

        <span class="k">if</span> <span class="n">as_dict</span><span class="p">:</span>
            <span class="n">param_dict</span> <span class="o">=</span> <span class="p">{}</span>
            <span class="k">for</span> <span class="n">obj</span><span class="p">,</span> <span class="n">p</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">nengo_objs</span><span class="p">,</span> <span class="n">params</span><span class="p">):</span>
                <span class="k">if</span> <span class="n">obj</span><span class="o">.</span><span class="n">label</span> <span class="ow">in</span> <span class="n">param_dict</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                        <span class="s2">&quot;Duplicate label (&#39;</span><span class="si">%s</span><span class="s2">&#39;) detected; cannot return &quot;</span>
                        <span class="s2">&quot;parameters with as_dict=True&quot;</span> <span class="o">%</span> <span class="n">obj</span><span class="o">.</span><span class="n">label</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">param_dict</span><span class="p">[</span><span class="n">obj</span><span class="o">.</span><span class="n">label</span><span class="p">]</span> <span class="o">=</span> <span class="n">p</span>
            <span class="n">params</span> <span class="o">=</span> <span class="n">param_dict</span>

        <span class="k">return</span> <span class="n">params</span></div>

<div class="viewcode-block" id="Simulator.check_gradients"><a class="viewcode-back" href="../../reference.html#nengo_dl.simulator.Simulator.check_gradients">[docs]</a>    <span class="k">def</span> <span class="nf">check_gradients</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">atol</span><span class="o">=</span><span class="mf">1e-5</span><span class="p">,</span> <span class="n">rtol</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Perform gradient checks for the network (used to verify that the</span>
<span class="sd">        analytic gradients are correct).</span>

<span class="sd">        Raises a simulation error if the difference between analytic and</span>
<span class="sd">        numeric gradient is greater than ``atol + rtol * numeric_grad``</span>
<span class="sd">        (elementwise).</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        outputs : ``tf.Tensor`` or list of ``tf.Tensor`` or \</span>
<span class="sd">                  list of `~nengo.Probe`</span>
<span class="sd">            Compute gradients wrt this output (if None, computes wrt each</span>
<span class="sd">            output probe)</span>
<span class="sd">        atol : float</span>
<span class="sd">            Absolute error tolerance</span>
<span class="sd">        rtol : float</span>
<span class="sd">            Relative (to numeric grad) error tolerance</span>

<span class="sd">        Notes</span>
<span class="sd">        -----</span>
<span class="sd">        Calling this function will reset all values in the network, so it</span>
<span class="sd">        should not be intermixed with calls to `.Simulator.run`.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">tensor_graph</span><span class="o">.</span><span class="n">inference_only</span><span class="p">:</span>
            <span class="k">raise</span> <span class="n">ValidationError</span><span class="p">(</span>
                <span class="s2">&quot;Network was created with inference_only=True, cannot &quot;</span>
                <span class="s2">&quot;compute gradients&quot;</span><span class="p">,</span> <span class="s2">&quot;inference_only&quot;</span><span class="p">)</span>

        <span class="n">delta</span> <span class="o">=</span> <span class="mf">1e-3</span>
        <span class="n">n_steps</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">unroll</span> <span class="o">*</span> <span class="mi">2</span>

        <span class="n">data</span> <span class="o">=</span> <span class="p">{</span><span class="n">n</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">minibatch_size</span><span class="p">,</span> <span class="n">n_steps</span><span class="p">,</span> <span class="n">n</span><span class="o">.</span><span class="n">size_out</span><span class="p">))</span>
                <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">tensor_graph</span><span class="o">.</span><span class="n">invariant_inputs</span><span class="p">}</span>
        <span class="n">data</span><span class="o">.</span><span class="n">update</span><span class="p">({</span><span class="n">p</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">minibatch_size</span><span class="p">,</span> <span class="n">n_steps</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">size_in</span><span class="p">))</span>
                     <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">tensor_graph</span><span class="o">.</span><span class="n">target_phs</span><span class="p">})</span>
        <span class="n">feed</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_fill_feed</span><span class="p">(</span><span class="n">n_steps</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">outputs</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># note: the x + 0 is necessary because `gradient_checker`</span>
            <span class="c1"># doesn&#39;t work properly if the output variable is a tensorarray</span>
            <span class="n">outputs</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span> <span class="o">+</span> <span class="mi">0</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">tensor_graph</span><span class="o">.</span><span class="n">probe_arrays</span><span class="o">.</span><span class="n">values</span><span class="p">()]</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
            <span class="n">outputs</span> <span class="o">=</span> <span class="p">[</span><span class="n">outputs</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">outputs</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">tensor_graph</span><span class="o">.</span><span class="n">probe_arrays</span><span class="p">[</span><span class="n">p</span><span class="p">]</span> <span class="o">+</span> <span class="mi">0</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">outputs</span><span class="p">]</span>

        <span class="c1"># check gradient wrt inp</span>
        <span class="k">for</span> <span class="n">node</span><span class="p">,</span> <span class="n">inp</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">tensor_graph</span><span class="o">.</span><span class="n">input_ph</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="n">inp_shape</span> <span class="o">=</span> <span class="n">inp</span><span class="o">.</span><span class="n">get_shape</span><span class="p">()</span><span class="o">.</span><span class="n">as_list</span><span class="p">()</span>
            <span class="n">inp_shape</span> <span class="o">=</span> <span class="p">[</span><span class="n">n_steps</span> <span class="k">if</span> <span class="n">x</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">x</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">inp_shape</span><span class="p">]</span>
            <span class="n">inp_tens</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tensor_graph</span><span class="o">.</span><span class="n">input_ph</span><span class="p">[</span><span class="n">node</span><span class="p">]</span>
            <span class="n">feed</span><span class="p">[</span><span class="n">inp_tens</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ascontiguousarray</span><span class="p">(</span><span class="n">feed</span><span class="p">[</span><span class="n">inp_tens</span><span class="p">])</span>
            <span class="n">inp_val</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ravel</span><span class="p">(</span><span class="n">feed</span><span class="p">[</span><span class="n">inp_tens</span><span class="p">])</span>
            <span class="k">for</span> <span class="n">out</span> <span class="ow">in</span> <span class="n">outputs</span><span class="p">:</span>
                <span class="n">out_shape</span> <span class="o">=</span> <span class="n">out</span><span class="o">.</span><span class="n">get_shape</span><span class="p">()</span><span class="o">.</span><span class="n">as_list</span><span class="p">()</span>
                <span class="n">out_shape</span> <span class="o">=</span> <span class="p">[</span><span class="n">n_steps</span> <span class="k">if</span> <span class="n">x</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">x</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">out_shape</span><span class="p">]</span>

                <span class="c1"># we need to compute the numeric jacobian manually, to</span>
                <span class="c1"># correctly handle variables (tensorflow doesn&#39;t expect</span>
                <span class="c1"># state ops in `compute_gradient`, because it doesn&#39;t define</span>
                <span class="c1"># gradients for them)</span>
                <span class="n">numeric</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">np</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">inp_shape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">),</span>
                                    <span class="n">np</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">out_shape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)))</span>

                <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">numeric</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">soft_reset</span><span class="p">()</span>
                    <span class="n">inp_val</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">delta</span>
                    <span class="n">plus</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="n">feed_dict</span><span class="o">=</span><span class="n">feed</span><span class="p">)</span>

                    <span class="bp">self</span><span class="o">.</span><span class="n">soft_reset</span><span class="p">()</span>
                    <span class="n">inp_val</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="n">delta</span>
                    <span class="n">minus</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="n">feed_dict</span><span class="o">=</span><span class="n">feed</span><span class="p">)</span>

                    <span class="n">numeric</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ravel</span><span class="p">((</span><span class="n">plus</span> <span class="o">-</span> <span class="n">minus</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">delta</span><span class="p">))</span>

                    <span class="n">inp_val</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>

                <span class="bp">self</span><span class="o">.</span><span class="n">soft_reset</span><span class="p">()</span>

                <span class="k">with</span> <span class="n">tf_compat</span><span class="o">.</span><span class="n">variable_scope</span><span class="p">(</span>
                        <span class="n">tf_compat</span><span class="o">.</span><span class="n">get_variable_scope</span><span class="p">())</span> <span class="k">as</span> <span class="n">scope</span><span class="p">:</span>
                    <span class="n">dx</span><span class="p">,</span> <span class="n">dy</span> <span class="o">=</span> <span class="n">gradient_checker</span><span class="o">.</span><span class="n">_compute_dx_and_dy</span><span class="p">(</span>
                        <span class="n">inp</span><span class="p">,</span> <span class="n">out</span><span class="p">,</span> <span class="n">out_shape</span><span class="p">)</span>

                    <span class="bp">self</span><span class="o">.</span><span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">tf_compat</span><span class="o">.</span><span class="n">variables_initializer</span><span class="p">(</span>
                        <span class="n">scope</span><span class="o">.</span><span class="n">get_collection</span><span class="p">(</span><span class="s2">&quot;gradient_vars&quot;</span><span class="p">)))</span>

                <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">sess</span><span class="o">.</span><span class="n">as_default</span><span class="p">():</span>
                    <span class="n">analytic</span> <span class="o">=</span> <span class="n">gradient_checker</span><span class="o">.</span><span class="n">_compute_theoretical_jacobian</span><span class="p">(</span>
                        <span class="n">inp</span><span class="p">,</span> <span class="n">inp_shape</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">inp_shape</span><span class="p">),</span> <span class="n">dy</span><span class="p">,</span> <span class="n">out_shape</span><span class="p">,</span> <span class="n">dx</span><span class="p">,</span>
                        <span class="n">extra_feed_dict</span><span class="o">=</span><span class="n">feed</span><span class="p">)</span>

                <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">analytic</span><span class="p">))</span> <span class="ow">or</span> <span class="n">np</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">numeric</span><span class="p">)):</span>
                    <span class="k">raise</span> <span class="n">SimulationError</span><span class="p">(</span><span class="s2">&quot;NaNs detected in gradient&quot;</span><span class="p">)</span>
                <span class="n">fail</span> <span class="o">=</span> <span class="nb">abs</span><span class="p">(</span><span class="n">analytic</span> <span class="o">-</span> <span class="n">numeric</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="n">atol</span> <span class="o">+</span> <span class="n">rtol</span> <span class="o">*</span> <span class="nb">abs</span><span class="p">(</span><span class="n">numeric</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">fail</span><span class="p">):</span>
                    <span class="k">raise</span> <span class="n">SimulationError</span><span class="p">(</span>
                        <span class="s2">&quot;Gradient check failed for input </span><span class="si">%s</span><span class="s2"> and output </span><span class="si">%s</span><span class="se">\n</span><span class="s2">&quot;</span>
                        <span class="s2">&quot;numeric values:</span><span class="se">\n</span><span class="si">%s</span><span class="se">\n</span><span class="s2">&quot;</span>
                        <span class="s2">&quot;analytic values:</span><span class="se">\n</span><span class="si">%s</span><span class="se">\n</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="n">out</span><span class="p">,</span> <span class="n">numeric</span><span class="p">[</span><span class="n">fail</span><span class="p">],</span>
                                                    <span class="n">analytic</span><span class="p">[</span><span class="n">fail</span><span class="p">]))</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">soft_reset</span><span class="p">()</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Gradient check passed&quot;</span><span class="p">)</span></div>

<div class="viewcode-block" id="Simulator.trange"><a class="viewcode-back" href="../../reference.html#nengo_dl.simulator.Simulator.trange">[docs]</a>    <span class="k">def</span> <span class="nf">trange</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sample_every</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">dt</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Create a vector of times matching probed data.</span>

<span class="sd">        Note that the range does not start at 0 as one might expect, but at</span>
<span class="sd">        the first timestep (i.e., ``dt``).</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        sample_every : float (Default: None)</span>
<span class="sd">            The sampling period of the probe to create a range for.</span>
<span class="sd">            If None, a time value for every ``dt`` will be produced.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="n">dt</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">sample_every</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">raise</span> <span class="n">ValidationError</span><span class="p">(</span>
                    <span class="s2">&quot;Cannot specify both `dt` and `sample_every`. &quot;</span>
                    <span class="s2">&quot;Use `sample_every` only.&quot;</span><span class="p">,</span> <span class="n">attr</span><span class="o">=</span><span class="s2">&quot;dt&quot;</span><span class="p">,</span> <span class="n">obj</span><span class="o">=</span><span class="bp">self</span><span class="p">)</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="s2">&quot;`dt` is deprecated. Use `sample_every` instead.&quot;</span><span class="p">)</span>
            <span class="n">sample_every</span> <span class="o">=</span> <span class="n">dt</span>

        <span class="n">period</span> <span class="o">=</span> <span class="mi">1</span> <span class="k">if</span> <span class="n">sample_every</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">sample_every</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">dt</span>
        <span class="n">steps</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_steps</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">dt</span> <span class="o">*</span> <span class="n">steps</span><span class="p">[</span><span class="n">steps</span> <span class="o">%</span> <span class="n">period</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">]</span></div>

<div class="viewcode-block" id="Simulator.close"><a class="viewcode-back" href="../../reference.html#nengo_dl.simulator.Simulator.close">[docs]</a>    <span class="k">def</span> <span class="nf">close</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Close the simulation, freeing resources.</span>

<span class="sd">        Notes</span>
<span class="sd">        -----</span>
<span class="sd">        The simulation cannot be restarted after it is closed.  This is not a</span>
<span class="sd">        technical limitation, just a design decision made for all Nengo</span>
<span class="sd">        simulators.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">closed</span><span class="p">:</span>
            <span class="c1"># note: we use getattr in case it crashes before the object is</span>
            <span class="c1"># created</span>
            <span class="k">if</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;sess&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">sess</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">sess</span> <span class="o">=</span> <span class="kc">None</span>

            <span class="k">if</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;summary&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">summary</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">closed</span> <span class="o">=</span> <span class="kc">True</span></div>

    <span class="k">def</span> <span class="nf">_fill_feed</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_steps</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">start</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Create a feed dictionary containing values for all the placeholder</span>
<span class="sd">        inputs in the network, which will be passed to ``tf.Session.run``.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        n_steps : int</span>
<span class="sd">            The number of execution steps</span>
<span class="sd">        data : dict of {`~nengo.Node` or `~nengo.Probe` : `~numpy.ndarray`}</span>
<span class="sd">            Input values for Nodes and target values for Probes.  Arrays</span>
<span class="sd">            should have shape ``(sim.minibatch_size, n_steps,</span>
<span class="sd">            node.size_out/probe.size_in)``.</span>
<span class="sd">        start : int</span>
<span class="sd">            Initial value of simulator timestep</span>
<span class="sd">        training : bool</span>
<span class="sd">            Whether we are running in training or inference mode</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        feed_dict : dict of {``tf.Tensor``: `~numpy.ndarray`}</span>
<span class="sd">            Feed values for placeholder tensors in the network</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c1"># fill in constants</span>
        <span class="n">feed_dict</span> <span class="o">=</span> <span class="p">{</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">tensor_graph</span><span class="o">.</span><span class="n">step_var</span><span class="p">:</span> <span class="n">start</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">tensor_graph</span><span class="o">.</span><span class="n">stop_var</span><span class="p">:</span> <span class="n">start</span> <span class="o">+</span> <span class="n">n_steps</span><span class="p">,</span>
        <span class="p">}</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">tensor_graph</span><span class="o">.</span><span class="n">inference_only</span><span class="p">:</span>
            <span class="n">feed_dict</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">tensor_graph</span><span class="o">.</span><span class="n">signals</span><span class="o">.</span><span class="n">training</span><span class="p">]</span> <span class="o">=</span> <span class="n">training</span>

        <span class="n">inputs</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="n">targets</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">if</span> <span class="n">data</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">data</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">Node</span><span class="p">):</span>
                    <span class="n">inputs</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">v</span>
                <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">Probe</span><span class="p">):</span>
                    <span class="n">targets</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">v</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="c1"># this should be caught in check_data</span>
                    <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">()</span>

        <span class="c1"># fill in input values</span>
        <span class="n">feed_dict</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_generate_inputs</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">n_steps</span><span class="p">))</span>

        <span class="c1"># fill in target values</span>
        <span class="k">for</span> <span class="n">p</span><span class="p">,</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">targets</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="k">if</span> <span class="n">p</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">tensor_graph</span><span class="o">.</span><span class="n">target_phs</span><span class="p">:</span>
                <span class="k">raise</span> <span class="n">ValidationError</span><span class="p">(</span>
                    <span class="s2">&quot;</span><span class="si">%s</span><span class="s2"> is not a valid target; this is probably because &quot;</span>
                    <span class="s2">&quot;it is not used in the objective function&quot;</span> <span class="o">%</span> <span class="n">p</span><span class="p">,</span>
                    <span class="s2">&quot;targets&quot;</span><span class="p">)</span>

            <span class="n">feed_dict</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">tensor_graph</span><span class="o">.</span><span class="n">target_phs</span><span class="p">[</span><span class="n">p</span><span class="p">]]</span> <span class="o">=</span> <span class="n">t</span>

        <span class="k">return</span> <span class="n">feed_dict</span>

    <span class="k">def</span> <span class="nf">_generate_inputs</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">n_steps</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Generate inputs for the network (the output values of each Node with</span>
<span class="sd">        no incoming connections).</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        data : dict of {`~nengo.Node`: `~numpy.ndarray`}</span>
<span class="sd">            Override the values of input Nodes with the given data.  Arrays</span>
<span class="sd">            should have shape ``(sim.minibatch_size, n_steps, node.size_out)``.</span>
<span class="sd">        n_steps : int</span>
<span class="sd">            Number of simulation timesteps for which to generate input data</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        feed_vals : dict of {`~nengo.Node`: `~numpy.ndarray}</span>
<span class="sd">            Simulation values for all the input Nodes in the network.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">feed_vals</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="n">n</span><span class="p">,</span> <span class="n">output</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">tensor_graph</span><span class="o">.</span><span class="n">input_funcs</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="k">if</span> <span class="n">n</span> <span class="ow">in</span> <span class="n">data</span><span class="p">:</span>
                <span class="c1"># move minibatch dimension to the end</span>
                <span class="n">feed_val</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">moveaxis</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="n">n</span><span class="p">],</span> <span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
            <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
                <span class="c1"># tile to n_steps/minibatch size</span>
                <span class="n">feed_val</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">tile</span><span class="p">(</span><span class="n">output</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="p">:,</span> <span class="kc">None</span><span class="p">],</span>
                                   <span class="p">(</span><span class="n">n_steps</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">minibatch_size</span><span class="p">))</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># call output function to determine value</span>
                <span class="n">feed_val</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span>
                    <span class="p">(</span><span class="n">n_steps</span><span class="p">,</span> <span class="n">n</span><span class="o">.</span><span class="n">size_out</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">minibatch_size</span><span class="p">),</span>
                    <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tensor_graph</span><span class="o">.</span><span class="n">dtype</span><span class="o">.</span><span class="n">as_numpy_dtype</span><span class="p">)</span>

                <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_steps</span><span class="p">):</span>
                    <span class="c1"># note: need to copy the output of func, as func</span>
                    <span class="c1"># may mutate its outputs in-place on subsequent calls.</span>
                    <span class="c1"># this assignment will broadcast the output along the</span>
                    <span class="c1"># minibatch dimension if required.</span>
                    <span class="n">feed_val</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">transpose</span><span class="p">([</span>
                        <span class="n">func</span><span class="p">((</span><span class="n">i</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_steps</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">dt</span><span class="p">)</span>
                        <span class="k">for</span> <span class="n">func</span> <span class="ow">in</span> <span class="n">output</span><span class="p">])</span>

            <span class="c1"># note: we still call the function (above) even if the output</span>
            <span class="c1"># is not being used, because it may have side-effects</span>
            <span class="k">if</span> <span class="n">n</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">tensor_graph</span><span class="o">.</span><span class="n">input_ph</span><span class="p">:</span>
                <span class="n">feed_vals</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">tensor_graph</span><span class="o">.</span><span class="n">input_ph</span><span class="p">[</span><span class="n">n</span><span class="p">]]</span> <span class="o">=</span> <span class="n">feed_val</span>

        <span class="k">return</span> <span class="n">feed_vals</span>

    <span class="k">def</span> <span class="nf">_check_data</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">n_batch</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">n_steps</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Performs error checking on simulation data.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        data : dict of {`~nengo.Node` or `~nengo.Probe`: `~numpy.ndarray`}</span>
<span class="sd">            Array of data associated with given objects in model (Nodes or</span>
<span class="sd">            Probes)</span>
<span class="sd">        n_batch : int</span>
<span class="sd">            Number of elements in batch (if None, will just verify that all</span>
<span class="sd">            data items have same batch size)</span>
<span class="sd">        n_steps : int</span>
<span class="sd">            Number of simulation steps (if None, will just verify that all</span>
<span class="sd">            data items have same number of steps)</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">for</span> <span class="n">d</span><span class="p">,</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">data</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="k">if</span> <span class="n">x</span><span class="o">.</span><span class="n">ndim</span> <span class="o">!=</span> <span class="mi">3</span><span class="p">:</span>
                <span class="k">raise</span> <span class="n">ValidationError</span><span class="p">(</span>
                    <span class="s2">&quot;should have rank 3 (batch_size, n_steps, dimensions), &quot;</span>
                    <span class="s2">&quot;found rank </span><span class="si">%d</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">x</span><span class="o">.</span><span class="n">ndim</span><span class="p">,</span> <span class="s2">&quot;data&quot;</span><span class="p">)</span>

            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">d</span><span class="p">,</span> <span class="n">Node</span><span class="p">):</span>
                <span class="k">if</span> <span class="n">d</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">tensor_graph</span><span class="o">.</span><span class="n">invariant_inputs</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="n">ValidationError</span><span class="p">(</span>
                        <span class="s2">&quot;</span><span class="si">%s</span><span class="s2"> is not an input Node (a nengo.Node with &quot;</span>
                        <span class="s2">&quot;size_in==0), or is from a different network.&quot;</span> <span class="o">%</span> <span class="n">d</span><span class="p">,</span>
                        <span class="s2">&quot;data&quot;</span><span class="p">)</span>
            <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">d</span><span class="p">,</span> <span class="n">Probe</span><span class="p">):</span>
                <span class="k">if</span> <span class="n">d</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">probes</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="n">ValidationError</span><span class="p">(</span>
                        <span class="s2">&quot;</span><span class="si">%s</span><span class="s2"> is from a different network&quot;</span> <span class="o">%</span> <span class="n">d</span><span class="p">,</span> <span class="s2">&quot;data&quot;</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="n">ValidationError</span><span class="p">(</span>
                    <span class="s2">&quot;Data objects must be Nodes or Probes, not </span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">d</span><span class="p">,</span> <span class="s2">&quot;data&quot;</span><span class="p">)</span>

        <span class="n">args</span> <span class="o">=</span> <span class="p">[</span><span class="n">n_batch</span><span class="p">,</span> <span class="n">n_steps</span><span class="p">]</span>
        <span class="n">labels</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;batch size&quot;</span><span class="p">,</span> <span class="s2">&quot;number of timesteps&quot;</span><span class="p">]</span>

        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">args</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">val</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">values</span><span class="p">()))</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
                <span class="k">for</span> <span class="n">n</span><span class="p">,</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">data</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                    <span class="k">if</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">!=</span> <span class="n">val</span><span class="p">:</span>
                        <span class="k">raise</span> <span class="n">ValidationError</span><span class="p">(</span>
                            <span class="s2">&quot;Elements have different </span><span class="si">%s</span><span class="s2">: </span><span class="si">%s</span><span class="s2"> vs </span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span>
                            <span class="p">(</span><span class="n">labels</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">val</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="s2">&quot;data&quot;</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">for</span> <span class="n">n</span><span class="p">,</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">data</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                    <span class="k">if</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">!=</span> <span class="n">args</span><span class="p">[</span><span class="n">i</span><span class="p">]:</span>
                        <span class="k">raise</span> <span class="n">ValidationError</span><span class="p">(</span>
                            <span class="s2">&quot;Data for </span><span class="si">%s</span><span class="s2"> has </span><span class="si">%s</span><span class="s2">=</span><span class="si">%s</span><span class="s2">, which does not match &quot;</span>
                            <span class="s2">&quot;expected size (</span><span class="si">%s</span><span class="s2">)&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">labels</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="n">i</span><span class="p">],</span>
                                                    <span class="n">args</span><span class="p">[</span><span class="n">i</span><span class="p">]),</span>
                            <span class="s2">&quot;data&quot;</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">n</span><span class="p">,</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">data</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="k">if</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">minibatch_size</span><span class="p">:</span>
                <span class="k">raise</span> <span class="n">ValidationError</span><span class="p">(</span>
                    <span class="s2">&quot;Size of minibatch (</span><span class="si">%d</span><span class="s2">) for </span><span class="si">%s</span><span class="s2"> data less than Simulation &quot;</span>
                    <span class="s2">&quot;`minibatch_size` (</span><span class="si">%d</span><span class="s2">)&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">n</span><span class="p">,</span>
                                               <span class="bp">self</span><span class="o">.</span><span class="n">minibatch_size</span><span class="p">),</span>
                    <span class="s2">&quot;data&quot;</span><span class="p">)</span>

            <span class="n">d</span> <span class="o">=</span> <span class="n">n</span><span class="o">.</span><span class="n">size_out</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">Node</span><span class="p">)</span> <span class="k">else</span> <span class="n">n</span><span class="o">.</span><span class="n">size_in</span>
            <span class="k">if</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">!=</span> <span class="n">d</span><span class="p">:</span>
                <span class="k">raise</span> <span class="n">ValidationError</span><span class="p">(</span>
                    <span class="s2">&quot;Dimensionality of data (</span><span class="si">%s</span><span class="s2">) does not match &quot;</span>
                    <span class="s2">&quot;dimensionality of </span><span class="si">%s</span><span class="s2"> (</span><span class="si">%s</span><span class="s2">)&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">n</span><span class="p">,</span> <span class="n">d</span><span class="p">),</span>
                    <span class="s2">&quot;data&quot;</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_profile_output</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">profile</span><span class="p">,</span> <span class="n">run_metadata</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Outputs profile information to file.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        profile : bool or str</span>
<span class="sd">            If True or a string (filename), output profile information to file</span>
<span class="sd">        run_metadata : ``tf.RunMetadata``</span>
<span class="sd">            TensorFlow RunMetadata proto populated with profiling data</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">profile</span><span class="p">:</span>
            <span class="k">return</span>

        <span class="n">trace</span> <span class="o">=</span> <span class="n">Timeline</span><span class="p">(</span><span class="n">step_stats</span><span class="o">=</span><span class="n">run_metadata</span><span class="o">.</span><span class="n">step_stats</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">profile</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
            <span class="n">filename</span> <span class="o">=</span> <span class="n">profile</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">filename</span> <span class="o">=</span> <span class="s2">&quot;nengo_dl_profile.json&quot;</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="s2">&quot;w&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
            <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">trace</span><span class="o">.</span><span class="n">generate_chrome_trace_format</span><span class="p">())</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">dt</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;The time (in seconds) represented by one simulation timestep.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">dt</span>

    <span class="nd">@dt</span><span class="o">.</span><span class="n">setter</span>
    <span class="k">def</span> <span class="nf">dt</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">_</span><span class="p">):</span>
        <span class="k">raise</span> <span class="n">ReadonlyError</span><span class="p">(</span><span class="n">attr</span><span class="o">=</span><span class="s1">&#39;dt&#39;</span><span class="p">,</span> <span class="n">obj</span><span class="o">=</span><span class="bp">self</span><span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">training_step</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;The number of training iterations that have been executed.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">tensor_graph</span><span class="o">.</span><span class="n">training_step</span>

    <span class="k">def</span> <span class="nf">__enter__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_graph_context</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tensor_graph</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">as_default</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_device_context</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tensor_graph</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">device</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">tensor_graph</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_graph_context</span><span class="o">.</span><span class="fm">__enter__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_device_context</span><span class="o">.</span><span class="fm">__enter__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sess</span><span class="o">.</span><span class="fm">__enter__</span><span class="p">()</span>
        <span class="k">return</span> <span class="bp">self</span>

    <span class="k">def</span> <span class="nf">__exit__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sess</span><span class="o">.</span><span class="fm">__exit__</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_device_context</span><span class="o">.</span><span class="fm">__exit__</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_graph_context</span><span class="o">.</span><span class="fm">__exit__</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">__del__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Raise a RuntimeWarning if the Simulator is deallocated while open.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">closed</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">closed</span><span class="p">:</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                <span class="s2">&quot;Simulator with model=</span><span class="si">%s</span><span class="s2"> was deallocated while open. &quot;</span>
                <span class="s2">&quot;Simulators should be closed manually to ensure resources &quot;</span>
                <span class="s2">&quot;are properly freed.&quot;</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="ne">RuntimeWarning</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">__getstate__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span>
            <span class="s2">&quot;TensorFlow does not support pickling; see &quot;</span>
            <span class="s2">&quot;https://www.nengo.ai/nengo-dl/training.html&quot;</span>
            <span class="s2">&quot;#saving-and-loading-parameters &quot;</span>
            <span class="s2">&quot;for information on how to save/load a NengoDL model.&quot;</span><span class="p">)</span></div>


<div class="viewcode-block" id="SimulationData"><a class="viewcode-back" href="../../reference.html#nengo_dl.simulator.SimulationData">[docs]</a><span class="k">class</span> <span class="nc">SimulationData</span><span class="p">(</span><span class="n">collections</span><span class="o">.</span><span class="n">Mapping</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Data structure used to access simulation data from the model.</span>

<span class="sd">    The main use case for this is to access Probe data; for example,</span>
<span class="sd">    ``probe_data = sim.data[my_probe]``.  However, it is also</span>
<span class="sd">    used to access the parameters of objects in the model; for example, after</span>
<span class="sd">    the model has been optimized via `.Simulator.train`, the updated</span>
<span class="sd">    encoder values for an ensemble can be accessed via</span>
<span class="sd">    ``trained_encoders = sim.data[my_ens].encoders``.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    sim : `.Simulator`</span>
<span class="sd">        The simulator from which data will be drawn</span>
<span class="sd">    minibatched : bool</span>
<span class="sd">        If False, discard the minibatch dimension on probe data</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    SimulationData shouldn&#39;t be created/accessed directly by the user, but</span>
<span class="sd">    rather via ``sim.data`` (which is an instance of SimulationData).</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sim</span><span class="p">,</span> <span class="n">minibatched</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sim</span> <span class="o">=</span> <span class="n">sim</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">minibatched</span> <span class="o">=</span> <span class="n">minibatched</span>

<div class="viewcode-block" id="SimulationData.__getitem__"><a class="viewcode-back" href="../../reference.html#nengo_dl.simulator.SimulationData.__getitem__">[docs]</a>    <span class="k">def</span> <span class="nf">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">obj</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Return the data associated with ``obj``.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        obj : `~nengo.Probe` or `~nengo.Ensemble` or `~nengo.Connection`</span>
<span class="sd">            Object whose simulation data is being accessed</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        data : `~numpy.ndarray` or \</span>
<span class="sd">               `~nengo.builder.ensemble.BuiltEnsemble` or \</span>
<span class="sd">               `~nengo.builder.connection.BuiltConnection`</span>
<span class="sd">            Array containing probed data if ``obj`` is a</span>
<span class="sd">            `~nengo.Probe`, otherwise the corresponding</span>
<span class="sd">            parameter object</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="n">obj</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">sim</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">params</span><span class="p">:</span>
            <span class="k">raise</span> <span class="n">ValidationError</span><span class="p">(</span><span class="s2">&quot;Object is not in parameters of model </span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span>
                                  <span class="bp">self</span><span class="o">.</span><span class="n">sim</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="nb">str</span><span class="p">(</span><span class="n">obj</span><span class="p">))</span>

        <span class="n">data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sim</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="n">obj</span><span class="p">]</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="n">Probe</span><span class="p">):</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="k">return</span> <span class="p">[]</span>
            <span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">minibatched</span><span class="p">:</span>
                <span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

            <span class="n">data</span><span class="o">.</span><span class="n">setflags</span><span class="p">(</span><span class="n">write</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="n">Ensemble</span><span class="p">):</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">obj</span><span class="o">.</span><span class="n">neuron_type</span><span class="p">,</span> <span class="n">Direct</span><span class="p">):</span>
                <span class="c1"># direct mode ensemble</span>
                <span class="n">gain</span> <span class="o">=</span> <span class="n">bias</span> <span class="o">=</span> <span class="kc">None</span>
                <span class="n">scaled_encoders</span> <span class="o">=</span> <span class="n">encoders</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_params</span><span class="p">(</span>
                    <span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="s2">&quot;scaled_encoders&quot;</span><span class="p">))[</span><span class="mi">0</span><span class="p">]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># get the live simulation values</span>
                <span class="n">scaled_encoders</span><span class="p">,</span> <span class="n">bias</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_params</span><span class="p">(</span>
                    <span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="s2">&quot;scaled_encoders&quot;</span><span class="p">),</span> <span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="s2">&quot;bias&quot;</span><span class="p">))</span>

                <span class="c1"># infer the related values (rolled into scaled_encoders)</span>
                <span class="n">gain</span> <span class="o">=</span> <span class="p">(</span><span class="n">obj</span><span class="o">.</span><span class="n">radius</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">scaled_encoders</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
                        <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">encoders</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">))</span>
                <span class="n">encoders</span> <span class="o">=</span> <span class="n">obj</span><span class="o">.</span><span class="n">radius</span> <span class="o">*</span> <span class="n">scaled_encoders</span> <span class="o">/</span> <span class="n">gain</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">]</span>

            <span class="c1"># figure out max_rates/intercepts from neuron model</span>
            <span class="n">max_rates</span><span class="p">,</span> <span class="n">intercepts</span> <span class="o">=</span> <span class="p">(</span>
                <span class="n">obj</span><span class="o">.</span><span class="n">neuron_type</span><span class="o">.</span><span class="n">max_rates_intercepts</span><span class="p">(</span><span class="n">gain</span><span class="p">,</span> <span class="n">bias</span><span class="p">))</span>

            <span class="n">data</span> <span class="o">=</span> <span class="n">BuiltEnsemble</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">eval_points</span><span class="p">,</span> <span class="n">encoders</span><span class="p">,</span> <span class="n">intercepts</span><span class="p">,</span>
                                 <span class="n">max_rates</span><span class="p">,</span> <span class="n">scaled_encoders</span><span class="p">,</span> <span class="n">gain</span><span class="p">,</span> <span class="n">bias</span><span class="p">)</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="n">Connection</span><span class="p">):</span>
            <span class="c1"># get the live simulation values</span>
            <span class="n">weights</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_params</span><span class="p">((</span><span class="n">obj</span><span class="p">,</span> <span class="s2">&quot;weights&quot;</span><span class="p">))[</span><span class="mi">0</span><span class="p">]</span>

            <span class="c1"># impossible to recover transform</span>
            <span class="n">transform</span> <span class="o">=</span> <span class="kc">None</span>

            <span class="n">data</span> <span class="o">=</span> <span class="n">BuiltConnection</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">eval_points</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">solver_info</span><span class="p">,</span> <span class="n">weights</span><span class="p">,</span>
                                   <span class="n">transform</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">data</span></div>

<div class="viewcode-block" id="SimulationData.get_params"><a class="viewcode-back" href="../../reference.html#nengo_dl.simulator.SimulationData.get_params">[docs]</a>    <span class="k">def</span> <span class="nf">get_params</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">obj_attrs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Returns the current parameter values for the given objects.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        obj_attrs : list of (``NengoObject``, str)</span>
<span class="sd">            The Nengo object and attribute of that object for which we want</span>
<span class="sd">            to know the parameter values (each object-attribute pair specified</span>
<span class="sd">            as a tuple argument to the function).</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        params : list of `~numpy.ndarray`</span>
<span class="sd">            Current values of the requested parameters</span>

<span class="sd">        Notes</span>
<span class="sd">        -----</span>
<span class="sd">        Parameter values should be accessed through ``sim.data``</span>
<span class="sd">        (which will call this function if necessary), rather than directly</span>
<span class="sd">        through this function.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">sim</span><span class="o">.</span><span class="n">closed</span><span class="p">:</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="s2">&quot;Checking parameters after simulator is closed; &quot;</span>
                          <span class="s2">&quot;cannot fetch live values, so the initial values &quot;</span>
                          <span class="s2">&quot;will be returned.&quot;</span><span class="p">)</span>

            <span class="k">return</span> <span class="p">[</span><span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">sim</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="n">obj</span><span class="p">],</span> <span class="n">attr</span><span class="p">)</span>
                    <span class="k">for</span> <span class="n">obj</span><span class="p">,</span> <span class="n">attr</span> <span class="ow">in</span> <span class="n">obj_attrs</span><span class="p">]</span>

        <span class="n">params</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">sigs</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">fetches</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="n">obj</span><span class="p">,</span> <span class="n">attr</span> <span class="ow">in</span> <span class="n">obj_attrs</span><span class="p">:</span>

            <span class="n">sig_obj</span><span class="p">,</span> <span class="n">sig_attr</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_attr_map</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="n">attr</span><span class="p">)</span>
            <span class="n">sig</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sim</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">sig</span><span class="p">[</span><span class="n">sig_obj</span><span class="p">][</span><span class="n">sig_attr</span><span class="p">]</span>
            <span class="n">sigs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">sig</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">sig</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">sim</span><span class="o">.</span><span class="n">tensor_graph</span><span class="o">.</span><span class="n">signals</span><span class="p">:</span>
                <span class="c1"># if sig isn&#39;t in sig_map then that means it isn&#39;t used</span>
                <span class="c1"># anywhere in the simulation (and therefore never changes), so</span>
                <span class="c1"># we can safely return the static build value</span>
                <span class="n">params</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">sim</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="n">obj</span><span class="p">],</span> <span class="n">attr</span><span class="p">))</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># this is a live parameter value we need to fetch from the</span>
                <span class="c1"># simulation. we queue them up and fetch them all at once to</span>
                <span class="c1"># be more efficient</span>
                <span class="n">placeholder</span> <span class="o">=</span> <span class="nb">object</span><span class="p">()</span>
                <span class="n">fetches</span><span class="p">[</span><span class="n">placeholder</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sim</span><span class="o">.</span><span class="n">tensor_graph</span><span class="o">.</span><span class="n">get_tensor</span><span class="p">(</span><span class="n">sig</span><span class="p">)</span>
                <span class="n">params</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">placeholder</span><span class="p">)</span>

        <span class="c1"># get the live parameter values</span>
        <span class="n">fetched</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sim</span><span class="o">.</span><span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">fetches</span><span class="p">)</span>

        <span class="c1"># final updating of parameters</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">sig</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">sigs</span><span class="p">):</span>
            <span class="c1"># fill in placeholder values</span>
            <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">params</span><span class="p">[</span><span class="n">i</span><span class="p">])</span> <span class="o">==</span> <span class="nb">object</span><span class="p">:</span>
                <span class="n">params</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">fetched</span><span class="p">[</span><span class="n">params</span><span class="p">[</span><span class="n">i</span><span class="p">]]</span>

            <span class="c1"># handle minibatch dimension</span>
            <span class="k">if</span> <span class="n">sig</span><span class="o">.</span><span class="n">minibatched</span><span class="p">:</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">minibatched</span><span class="p">:</span>
                    <span class="n">params</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">params</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="o">...</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">params</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">moveaxis</span><span class="p">(</span><span class="n">params</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">params</span></div>

    <span class="k">def</span> <span class="nf">_attr_map</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">obj</span><span class="p">,</span> <span class="n">attr</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Maps from ``sim.data[obj].attr`` to the equivalent</span>
<span class="sd">        ``model.sig[obj][attr]``.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        obj : ``NengoObject``</span>
<span class="sd">            The nengo object for which we want to know the parameters</span>
<span class="sd">        attr : str</span>
<span class="sd">            The parameter of ``obj`` to be returned</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        obj : ``NengoObject``</span>
<span class="sd">            The nengo object to key into ``model.sig``</span>
<span class="sd">        attr : str</span>
<span class="sd">            The name of the signal corresponding to input attr</span>

<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="n">Ensemble</span><span class="p">)</span> <span class="ow">and</span> <span class="n">attr</span> <span class="o">==</span> <span class="s2">&quot;bias&quot;</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">obj</span><span class="o">.</span><span class="n">neurons</span><span class="p">,</span> <span class="n">attr</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="n">Ensemble</span><span class="p">)</span> <span class="ow">and</span> <span class="n">attr</span> <span class="o">==</span> <span class="s2">&quot;scaled_encoders&quot;</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">obj</span><span class="p">,</span> <span class="s2">&quot;encoders&quot;</span>

        <span class="k">return</span> <span class="n">obj</span><span class="p">,</span> <span class="n">attr</span>

    <span class="k">def</span> <span class="nf">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">sim</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">params</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">__iter__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">iter</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">sim</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">params</span><span class="p">)</span></div>
</pre></div>

            </div>
          </div>
        </div>
      </div>

    </div>
  </div>
</div><footer class="text-light footer-main gradient-bottom">
  <p class="small text-center mb-0">
    <a href="https://www.nengo.ai/">What is Nengo?</a>
    <a href="https://www.nengo.ai/documentation/">Documentation</a>
    <a href="https://www.nengo.ai/download/">Download</a>
    <a href="https://appliedbrainresearch.com">ABR</a>
    <a href="https://www.nengo.ai/privacy/">Privacy</a>
  </p>
  <p class="small text-center mb-0">&copy; Applied Brain Research</p>
</footer>
<script>
  function switchVersion(select) {
    var option = select.selectedOptions[0];
    if (option.hasAttribute("value")) {
      window.location = option.value;
    }
  }
</script>

<script>
  var elements = document.querySelectorAll('.sidenav');
  Stickyfill.add(elements);
</script>
<script>
  ScrollReveal().reveal(".fade-in", {
      scale: 0.85,
      duration: 1000,
      delay: 250,
      interval: 50
  });
</script>
<script>
  $('a.toggle-sidenav').on('click', function(e) {
    e.preventDefault();
    if ( $(this).hasClass('active') ) {
      $(this).removeClass('active');
      $('.sidenav').removeClass('open');
    } else {
      $(this).addClass('active');
      $('.sidenav').addClass('open');
    }
  });
</script>
<script>
  var lists = document.querySelectorAll('.toctree ul');
  lists.forEach((ul) => {
      ul.classList.add("nav");
  });
  var links = document.querySelectorAll('.toctree a');
  links.forEach((link) => {
      link.classList.add("nav-link");
  });
  $("body").scrollspy({target: ".sidenav"});
</script>
  </body>
</html>