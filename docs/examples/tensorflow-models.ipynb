{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inserting a TensorFlow/Keras network into a Nengo model\n",
    "\n",
    "Often we may want to define one part of our model in Nengo, and another part in TensorFlow.  For example, suppose we are building a biological reinforcement learning model, but we'd like the inputs to our model to be natural images rather than artificial vectors.  We could load a vision network from TensorFlow, insert it into our model using NengoDL, and then build the rest of our model using normal Nengo syntax.\n",
    "\n",
    "NengoDL supports this through the [TensorNode](https://www.nengo.ai/nengo-dl/tensor_node.html) class.  This allows us to write code directly in TensorFlow, and then insert it easily into Nengo.  In this example we will demonstrate this in two different ways: first using a network defined using [Keras](https://keras.io/), and second using a prebuilt vision network from the [tensorflow/models](https://github.com/tensorflow/models) repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "import os\n",
    "from urllib.request import urlopen\n",
    "import io\n",
    "import shutil\n",
    "import stat\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorflow.contrib.slim as slim;\n",
    "\n",
    "import nengo\n",
    "import nengo_dl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Introduction to TensorNodes**\n",
    "\n",
    "`nengo_dl.TensorNode` works very similarly to `nengo.Node`, except instead of using the node to insert Python code into our model we will use it to insert TensorFlow code.  \n",
    "\n",
    "The first thing we need to do is define our TensorNode output.  This is a function that accepts the current simulation time (and, optionally, a batch of vectors) as input, and produces a batch of vectors as output.  All of these variables will be represented as `tf.Tensor` objects, and the internal operations of the TensorNode will be implemented with TensorFlow operations. For example, we could use a TensorNode to output a `sin` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with nengo.Network() as net:\n",
    "    def sin_func(t):\n",
    "        # compute sin wave (based on simulation time)\n",
    "        out = tf.sin(t)\n",
    "        \n",
    "        # convert output to the expected batched vector shape\n",
    "        # (with batch size of 1 and vector dimensionality 1)\n",
    "        out = tf.reshape(out, (1, 1))\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    node = nengo_dl.TensorNode(sin_func)\n",
    "    p = nengo.Probe(node)\n",
    "\n",
    "with nengo_dl.Simulator(net) as sim:\n",
    "    sim.run(5.0)\n",
    "    \n",
    "plt.figure()\n",
    "plt.plot(sim.trange(), sim.data[p]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, outputting a `sin` function is something we could do more easily with a regular `nengo.Node`.  The main use case for `nengo_dl.TensorNode` is to allow us to write more complex TensorFlow code and insert it into a NengoDL model.  We will see two different examples of this below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inserting a Keras network\n",
    "\n",
    "[Keras](https://keras.io/) is a popular software package for building and training deep learning style networks.  It provides a higher-level syntactical wrapper around TensorFlow (or other packages, such as Theano).  And because it is defining a TensorFlow network under the hood, we can define a network using Keras and then insert it into NengoDL using a TensorNode.\n",
    "\n",
    "This example assumes familiarity with the Keras API. Specifically it is based on the [introduction in the Tensorflow documentation](https://www.tensorflow.org/tutorials/keras/basic_classification), so if you are not yet familiar with Keras, you may find it helpful to read those tutorials first.\n",
    "\n",
    "For this example we'll train a neural network to classify the fashion MNIST dataset.  This dataset contains images of clothing, and the goal of the network is to identify what type of clothing it is (e.g. t-shirt, trouser, coat, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = (\n",
    "    fashion_mnist.load_data())\n",
    "num_classes = np.unique(test_labels).shape[0]\n",
    "\n",
    "# normalize images so values are between 0 and 1\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0\n",
    "\n",
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', \n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "\n",
    "for i in range(3):\n",
    "    plt.figure()\n",
    "    plt.imshow(test_images[i], cmap=\"gray\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(class_names[test_labels[i]]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we build and train a simple neural network, using Keras.  In this case we're building a simple two layer, densely connected network.\n",
    "\n",
    "Note that alternatively we could define the network in Keras and then train it in NengoDL (using the `Simulator.train` function).  But for this example we'll show how to do everything in Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_shape = (28, 28)\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=image_shape, name='flatten'),\n",
    "    keras.layers.Dense(128, activation=tf.nn.relu, name='hidden'),\n",
    "    keras.layers.Dense(num_classes, activation=tf.nn.softmax, \n",
    "                       name='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=tf.train.AdamOptimizer(), \n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(train_images, train_labels, epochs=5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll save the trained weights, so that we can load them later within our TensorNode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_weights = \"keras_weights.h5\"\n",
    "model.save_weights(model_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're ready to create our TensorNode.  Instead of using a function for our TensorNode output, in this case we'll use a callable class so that we can include `pre_build` and `post_build` functions.  These allow us to execute code at different stages during the build process, which can be necessary for more complicated TensorNodes.\n",
    "\n",
    "NengoDL will call the `pre_build` function once when the model is first constructed, so we can use this function to perform any initial setup required for our node.  In this case we'll use the `pre_build` function to call the Keras `clone_model` function.  This effectively reruns the Keras model definition from above, but because we're calling it in the `pre_build` stage it will be naturally integrated into the NengoDL model that is being built.\n",
    "\n",
    "The `__call__` function is where we do the main job of constructing the TensorFlow elements that will implement our node.  It will take TensorFlow Tensors as input and produce a `tf.Tensor` as output, as with the `tf.sin` example above.  In this case we apply the Keras model to the TensorNode inputs (stored in the `x` variable).  This adds the TensorFlow elements that implement that Keras model into the simulation graph.\n",
    "\n",
    "The `post_build` function is called after the rest of the graph has been constructed (and whenever the simulation is reset).  We'll use this to load the pretrained weights into the model.  We have to do this at the `post_build` stage because we need access to the initialized simulation session, which has the variables we want to load."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KerasNode:\n",
    "    def __init__(self, keras_model):\n",
    "        self.model = keras_model\n",
    "        \n",
    "    def pre_build(self, *args):\n",
    "        self.model = keras.models.clone_model(self.model)\n",
    "\n",
    "    def __call__(self, t, x):\n",
    "        # reshape the flattened images into their 2D shape\n",
    "        # (plus the batch dimension)\n",
    "        images = tf.reshape(x, (-1,) + image_shape)\n",
    "        # build the rest of the model into the graph\n",
    "        return self.model.call(images)\n",
    "    \n",
    "    def post_build(self, sess, rng):\n",
    "        self.model.load_weights(model_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that in the `__call__` method we pass our input tensor to the `Model.call` method, not `Model.predict` (which you might be more familiar with if you frequently work with Keras). We do this because we want the model to return a `Tensor` object (i.e., an abstract representation of the computations that will be performed in the network), rather than actually simulating the network and computing predictions (as the `predict` function does). This way the returned `Tensor` can become part of the TensorFlow graph that NengoDL is constructing.\n",
    "\n",
    "To better understand the difference between `model.call(images)` and `model.predict(images)`, we can look at the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session():\n",
    "    model.load_weights(model_weights)\n",
    "    \n",
    "    # model.call takes a Tensor as input and returns a Tensor\n",
    "    out1 = model.call(tf.convert_to_tensor(test_images[:10],\n",
    "                                           dtype=tf.float32))\n",
    "    print(\"Type of 'out1':\", type(out1))\n",
    "    \n",
    "    # model.predict takes a numpy array as input and returns a numpy array\n",
    "    out2 = model.predict(test_images[:10])\n",
    "    print(\"Type of 'out2':\", type(out2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our `KerasNode` class, we can use it to insert our Keras model into a Nengo network via a `TensorNode`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_input_shape = np.prod(image_shape)  # because input will be a vector\n",
    "\n",
    "with nengo.Network() as net:\n",
    "    # create a normal input node to feed in our test image.\n",
    "    # the `np.ones` array is a placeholder, these\n",
    "    # values will be replaced with the Fashion MNIST images\n",
    "    # when we run the Simulator.\n",
    "    input_node = nengo.Node(output=np.ones((net_input_shape,)))\n",
    "\n",
    "    # create a TensorNode containing the KerasNode we defined\n",
    "    # above, passing it the Keras model we created.  \n",
    "    # we also need to specify size_in (the dimensionality of\n",
    "    # our input vectors, the flattened images) and size_out (the number\n",
    "    # of classification classes output by the keras network)\n",
    "    keras_node = nengo_dl.TensorNode(\n",
    "        KerasNode(model),\n",
    "        size_in=net_input_shape,\n",
    "        size_out=num_classes)\n",
    "\n",
    "    # connect up our input to our keras node\n",
    "    nengo.Connection(input_node, keras_node, synapse=None)\n",
    "\n",
    "    # add a probes to collect output of keras node\n",
    "    keras_p = nengo.Probe(keras_node)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point we could add any other Nengo components we like to the network, and connect them up to the Keras node (for example, if we wanted to take the classified image labels and use them as input to a spiking neural model).  But to keep things simple, we'll stop here.\n",
    "\n",
    "We'll grab some random images from our test set, in order to demonstrate that we have successfully loaded the trained Keras network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minibatch_size = 20\n",
    "\n",
    "# pick some random images from test set\n",
    "np.random.seed(1)\n",
    "test_inds = np.random.randint(low=0, high=test_images.shape[0],\n",
    "                              size=(minibatch_size,))\n",
    "test_inputs = test_images[test_inds]\n",
    "\n",
    "# flatten images so we can pass them as vectors to the input node\n",
    "test_inputs = test_inputs.reshape((-1, net_input_shape))\n",
    "\n",
    "# unlike in Keras, NengoDl simulations always run over time.\n",
    "# so we need to add the time dimension to our data (even though\n",
    "# in this case we'll just run for a single timestep).\n",
    "test_inputs = test_inputs[:, None, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to run the simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with nengo_dl.Simulator(net, minibatch_size=minibatch_size) as sim:\n",
    "    sim.step(data={input_node: test_inputs})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the results of the simulation using the `Probe` that we added to capture the output from the `TensorNode`. We use it as a key into the `data` attribute of the Simulator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensornode_output = sim.data[keras_p]\n",
    "\n",
    "for i in range(5):\n",
    "    plt.figure()\n",
    "    plt.imshow(test_images[test_inds][i], cmap=\"gray\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(\"%s (%s)\" % (\n",
    "        class_names[test_labels[test_inds][i]],\n",
    "        class_names[np.argmax(tensornode_output[i, 0])]));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the network is doing a pretty good job of classifying the test images (the title shows the correct output, with the networks' output shown in brackets)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inserting a TensorFlow-Slim network\n",
    "\n",
    "In this example we'll show how to insert a more complicated network into NengoDL.  Specifically, we will use an Inception-v1 network to classify Imagenet images.  \n",
    "\n",
    "TensorFlow provides a number of pre-defined models in the [tensorflow/models](https://github.com/tensorflow/models) repository.  These are not included when you install TensorFlow, so we need to separately clone that repository and import the components we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone -q https://github.com/tensorflow/models\n",
    "sys.path.append(os.path.join(\".\", \"models\", \"research\", \"slim\"))\n",
    "from datasets import dataset_utils, imagenet\n",
    "from nets import inception\n",
    "from preprocessing import inception_preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before, we will use a [TensorNode](https://www.nengo.ai/nengo-dl/tensor_node.html) to insert our TensorFlow code into Nengo.  In this case we're going to build a TensorNode that encapsulates the [Inception-v1](https://arxiv.org/abs/1409.4842) network.  However, this same approach could be used for any TensorFlow network.\n",
    "\n",
    "This Inception-v1 network has been trained to perform image classification on the Imagenet dataset; if we show it an image, it will output a set of probabilities for the 1000 different object types it is trained to classify.  So if we show it an image of a tree it should output a high probability for the \"tree\" class and a low probability for the \"car\" class.\n",
    "\n",
    "The first thing we'll do is download a sample image to test our network with (you could use a different image if you want)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://upload.wikimedia.org/wikipedia/commons/7/70/EnglishCockerSpaniel_simon.jpg'\n",
    "image_string = urlopen(url).read()\n",
    "image = np.array(Image.open(io.BytesIO(image_string)))\n",
    "image_shape = image.shape\n",
    "\n",
    "# display the test image\n",
    "plt.figure()\n",
    "plt.imshow(image)\n",
    "plt.axis('off');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're ready to create our TensorNode.  As in the previous example, we will use a callable class so that we can use `pre_build` and `post_build` methods to help construct the model.\n",
    "\n",
    "In this case we'll use the `pre_build` function to download pre-trained weights for the Inception network.  Again, if we wanted we could train the network from scratch using the `sim.train` function, but that would take a long time.\n",
    "\n",
    "In the `__call__` function we apply some pre-processing to transform the TensorNode inputs (stored in the `x` variable) into the form expected by the inception network.  Then we call the `inception_v1` method, which will construct all the TensorFlow elements required to implement that network, and return the resulting output Tensor.\n",
    "\n",
    "We'll use the `post_build` function to load the pretrained weights into the model, as in the previous example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoints_dir = '/tmp/checkpoints'\n",
    "\n",
    "class InceptionNode:\n",
    "    def pre_build(self, *args):\n",
    "        # the shape of the inputs to the inception network\n",
    "        self.input_shape = inception.inception_v1.default_image_size\n",
    "        \n",
    "        # download model checkpoint file\n",
    "        if not tf.gfile.Exists(checkpoints_dir):\n",
    "            tf.gfile.MakeDirs(checkpoints_dir)\n",
    "        dataset_utils.download_and_uncompress_tarball(\n",
    "            \"http://download.tensorflow.org/models/inception_v1_2016_08_28.tar.gz\", \n",
    "            checkpoints_dir)\n",
    "        \n",
    "    def __call__(self, t, x):        \n",
    "        # convert our input vector to the shape/dtype of the input image\n",
    "        img = tf.reshape(tf.cast(x, tf.uint8), image_shape)\n",
    "\n",
    "        # reshape the image to the shape expected by the \n",
    "        # inception network\n",
    "        img = inception_preprocessing.preprocess_image(\n",
    "            img, self.input_shape, self.input_shape, is_training=False)\n",
    "        img = tf.expand_dims(img, 0)\n",
    "\n",
    "        # create inception network\n",
    "        with slim.arg_scope(inception.inception_v1_arg_scope()):\n",
    "            logits, _ = inception.inception_v1(img,\n",
    "                                               num_classes=1001,\n",
    "                                               is_training=False)\n",
    "\n",
    "        # return our classification probabilites\n",
    "        return tf.nn.softmax(logits)\n",
    "        \n",
    "    def post_build(self, sess, rng):\n",
    "        # load checkpoint file into model\n",
    "        init_fn = slim.assign_from_checkpoint_fn(\n",
    "            os.path.join(checkpoints_dir, 'inception_v1.ckpt'),\n",
    "            slim.get_model_variables('InceptionV1'))\n",
    "\n",
    "        init_fn(sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we create a Nengo Network containing our TensorNode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with nengo.Network() as net:\n",
    "    # create a normal input node to feed in our test image\n",
    "    input_node = nengo.Node(output=image.flatten())\n",
    "\n",
    "    # create our TensorNode containing the InceptionNode() we defined\n",
    "    # above.  we also need to specify size_in (the dimensionality of\n",
    "    # our input vectors, the flattened images) and size_out (the number\n",
    "    # of classification classes output by the inception network)\n",
    "    incep_node = nengo_dl.TensorNode(\n",
    "        InceptionNode(), size_in=np.prod(image_shape), size_out=1001)\n",
    "    \n",
    "    # connect up our input to our inception node\n",
    "    nengo.Connection(input_node, incep_node, synapse=None)\n",
    "    \n",
    "    # add some probes to collect data\n",
    "    input_p = nengo.Probe(input_node)\n",
    "    incep_p = nengo.Probe(incep_node)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with the previous example, at this point we could connect up the output of `incep_node` to any other part of our network, if this was part of a larger model.  But to keep this example simple we'll stop here.\n",
    "\n",
    "All that's left is to run our network, using our example image as input, and check the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the network for one timestep\n",
    "with nengo_dl.Simulator(net) as sim:\n",
    "    sim.step()\n",
    "\n",
    "# sort the output labels based on the classification probabilites \n",
    "# output from the network\n",
    "probabilities = sim.data[incep_p][0]\n",
    "sorted_inds = [i[0] for i in sorted(enumerate(-probabilities), \n",
    "                                    key=lambda x: x[1])]\n",
    "\n",
    "# print top 5 classes\n",
    "names = imagenet.create_readable_names_for_imagenet_labels()\n",
    "for i in range(5):\n",
    "    index = sorted_inds[i]\n",
    "    print('Probability %0.2f%% => [%s]' % (\n",
    "        probabilities[index] * 100, names[index]))\n",
    "    \n",
    "# display the test image\n",
    "plt.figure()\n",
    "plt.imshow(sim.data[input_p][0].reshape(image_shape).astype(np.uint8))\n",
    "plt.axis('off');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete the models repo we cloned\n",
    "def onerror(func, path, exc_info):\n",
    "    if not os.access(path, os.W_OK):\n",
    "        os.chmod(path, stat.S_IWUSR)\n",
    "        func(path)\n",
    "    else:\n",
    "        raise exc_info[1]\n",
    "shutil.rmtree(\"models\", onerror=onerror)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
