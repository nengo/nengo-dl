
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="X-UA-Compatible" content="IE=Edge" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <title>nengo_dl.tensor_graph &#8212; NengoDL documentation</title>
    <link rel="stylesheet" href="../../_static/basic.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/css/normalize.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/css/bootstrap.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/css/mmenu.all.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/css/components.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/css/nengo.css" />

<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-GT8XEDLTMJ"></script>
<script>
 window.dataLayer = window.dataLayer || [];
 function gtag(){dataLayer.push(arguments);}
 gtag('js', new Date());
 gtag('config', 'G-GT8XEDLTMJ');
</script>
<!-- End Google tag (gtag.js) -->

<!-- Matomo -->
<script>
 var _paq = window._paq = window._paq || [];
 _paq.push(["setDocumentTitle", document.domain + "/" + document.title]);
 _paq.push(["setCookieDomain", "*.appliedbrainresearch.com"]);
 _paq.push(["setDomains", ["*.appliedbrainresearch.com","*.edge.nengo.ai","*.forum.nengo.ai","*.labs.nengo.ai","*.nengo.ai"]]);
 _paq.push(["enableCrossDomainLinking"]);
 _paq.push(["setDoNotTrack", true]);
 _paq.push(['trackPageView']);
 _paq.push(['enableLinkTracking']);
 (function() {
   var u="https://appliedbrainresearch.matomo.cloud/";
   _paq.push(['setTrackerUrl', u+'matomo.php']);
   _paq.push(['setSiteId', '3']);
   var d=document, g=d.createElement('script'), s=d.getElementsByTagName('script')[0];
   g.async=true; g.src='//cdn.matomo.cloud/appliedbrainresearch.matomo.cloud/matomo.js'; s.parentNode.insertBefore(g,s);
 })();
</script>
<!-- End Matomo Code -->
<script type="text/javascript" src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.1/jquery.min.js"></script>
<!--[if lte IE 9]><script src="https://cdnjs.cloudflare.com/ajax/libs/placeholders/3.0.2/placeholders.min.js"></script><![endif]-->
<script type="text/javascript" src="https://cdn.crate.io/libs/jquery-cookie/1.4.1/jquery.cookie.min.js"></script>
    <script type="text/javascript" id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
    <script type="text/javascript" src="../../_static/jquery.js"></script>
    <script type="text/javascript" src="../../_static/underscore.js"></script>
    <script type="text/javascript" src="../../_static/doctools.js"></script>
    <script type="text/javascript" src="../../_static/language_data.js"></script>
    <script type="text/javascript" src="../../_static/js/modernizr.js"></script>
    <script type="text/javascript" src="../../_static/js/underscore.min.js"></script>
    <script type="text/javascript" src="../../_static/doctools.js"></script>
    <script type="text/javascript" src="../../_static/js/searchtools.js"></script>
    <script type="text/javascript" src="../../_static/js/webflow.js"></script>
    <script type="text/javascript" src="../../_static/js/bootstrap.js"></script>
    <script type="text/javascript" src="../../_static/js/mmenu.all.min.js"></script>
    <script type="text/javascript" src="../../_static/js/fontawesome.js"></script>
    <script type="text/javascript" src="../../_static/js/custom.js"></script>
    <script async="async" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true, "ignoreClass": "document", "processClass": "math|output_area"}})</script>
    <link rel="shortcut icon" href="../../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
<meta charset='utf-8'>
<meta http-equiv='X-UA-Compatible' content='IE=edge,chrome=1'>
<meta name='viewport' content='width=device-width, initial-scale=1.0, maximum-scale=1'>
<meta name="apple-mobile-web-app-capable" content="yes">

  </head><body>
<header class="header-nav">
  <div class="container">
    <div class="navbar w-nav" data-animation="default" data-collapse="small" data-contain="1" data-duration="400">
      <a class="brand w-nav-brand" href="https://www.nengo.ai/">
        <img src="https://www.nengo.ai/design/_images/general-full-light.svg" width="120">
      </a>
      <nav class="w-nav-menu main-nav" role="navigation">
        <div class="dropdownBackground">
          <span class="arrow"></span>
        </div>
        <ul id="menu-top-navigation" class="menu">
          <li class="navlink w-nav-link menu-item menu-item-has-children">
            <a href="https://www.nengo.ai/overview.html">Overview</a>
            <ul class="sub-menu">
                <li class="menu-item"><a href="https://www.nengo.ai/quickstart.html">Quick Start</a></li>
            </ul>
          </li>
          <li class="navlink w-nav-link menu-item menu-item-has-children">
            <a href="https://www.nengo.ai/documentation.html">Documentation</a>
            <table class="sub-menu">
              <tr>
                <td class="menu-heading">Core</td>
                <td class="menu-heading">Backends</td>
                <td class="menu-heading">Add-ons</td>
              </tr>
              <tr>
                <td class="menu-item"><a href="https://www.nengo.ai/nengo">Nengo</a></td>
                <td class="menu-item"><a href="https://www.nengo.ai/nengo-fpga">Nengo FPGA</a></td>
                <td class="menu-item"><a href="https://github.com/nengo/nengo-examples">Nengo Examples</a></td>
              </tr>
              <tr>
                <td class="menu-item"><a href="https://www.nengo.ai/nengo-dl/">Nengo DL</a></td>
                <td class="menu-item"><a href="https://www.nengo.ai/nengo-loihi">Nengo Loihi</a></td>
                <td class="menu-item"><a href="https://www.nengo.ai/nengo-extras/">Nengo Extras</a></td>
              </tr>
              <tr>
                <td class="menu-item"><a href="https://github.com/nengo/nengo-gui">Nengo GUI</a></td>
                <td class="menu-item"><a href="https://github.com/nengo/nengo-mpi">Nengo MPI</a></td>
                <td class="menu-item"><a href="https://arvoelke.github.io/nengolib-docs/">Nengo Lib</a></td>
              </tr>
              <tr>
                <td class="menu-item"><a href="https://www.nengo.ai/nengo-spa/">Nengo SPA</a></td>
                <td class="menu-item"><a href="https://github.com/nengo/nengo-ocl">Nengo OpenCL</a></td>
                <td class="menu-item"></td>
              </tr>
              <tr>
                <td class="menu-item"></td>
                <td class="menu-item"><a href="https://github.com/project-rig/nengo_spinnaker">Nengo SpiNNaker</a></td>
                <td class="menu-item"></td>
              </tr>
            </table>
          </li>
          <li class="navlink w-nav-link menu-item menu-item-has-children">
            <a href="https://www.nengo.ai/community.html">Community</a>
            <ul class="sub-menu">
              <li class="menu-item"><a href="https://forum.nengo.ai/">Forum</a></li>
              <li class="menu-item"><a href="https://www.nengo.ai/publications.html">Publications</a></li>
              <li class="menu-item"><a href="https://www.nengo.ai/summerschool.html">Summer School</a></li>
              <li class="menu-item"><a href="https://www.nengo.ai/videos.html">Videos</a></li>
              <li class="menu-item"><a href="https://www.nengo.ai/people.html">People</a></li>
            </ul>
          </li>
          <li class="navlink w-nav-link menu-item menu-item-has-children">
            <a href="https://www.nengo.ai/projects.html">Development</a>
            <ul class="sub-menu">
              <li class="menu-item"><a href="https://www.nengo.ai/contributing.html">Contributor Guide</a></li>
              <li class="menu-item"><a href="https://www.nengo.ai/projects.html">Ecosystem</a></li>
            </ul>
          </li>
          <li class="navlink w-nav-link menu-item"><a href="https://www.nengo.ai/README.html">About</a></li>
          <li class="btn-link w-nav-link menu-item"><a href="https://www.nengo.ai/download.html">Download</a></li>
        </ul>
      </nav>

      <div id="mobile-nav" class="mm-menu">
        <ul class="offcanvas-menu">
          <li class="navlink w-nav-link menu-item"><a href="https://www.nengo.ai/overview.html">Overview</a></li>
          <li class="navlink w-nav-link menu-item menu-item-has-children">
            <a href="https://www.nengo.ai/documentation.html">Documentation</a>
            <ul class="sub-menu">
              <li class="menu-item"><a href="https://www.nengo.ai/quickstart.html">Quick Start</a></li>
              <li class="menu-item"><a href="http://www.nengo.ai/nengo">NengoCore</a></li>
              <li class="menu-item"><a href="https://github.com/nengo/nengo-gui#nengo-gui">NengoGUI</a></li>
            </ul>
          </li>
          <li class="navlink w-nav-link menu-item menu-item-has-children">
            <a href="https://www.nengo.ai/community.html">Community</a>
            <ul class="sub-menu">
              <li class="menu-item"><a href="https://forum.nengo.ai/">Forum</a></li>
              <li class="menu-item"><a href="https://www.nengo.ai/summerschool.html">Summer School</a></li>
              <li class="menu-item"><a href="https://www.nengo.ai/people.html">People</a></li>
            </ul>
          </li>
          <li class="navlink w-nav-link menu-item menu-item-has-children">
            <a href="https://www.nengo.ai/projects.html">Development</a>
            <ul class="sub-menu">
              <li class="menu-item"><a href="https://www.nengo.ai/contributing.html">Contributor Guide</a></li>
              <li class="menu-item"><a href="https://www.nengo.ai/projects.html">Ecosystem</a></li>
            </ul>
          </li>
          <li class="navlink w-nav-link menu-item"><a href="https://www.nengo.ai/README.html">About</a></li>
          <li class="btn-link w-nav-link menu-item"><a href="https://www.nengo.ai/download.html">Download</a></li>
        </ul>
      </div>

      <a href="#mobile-nav" class="fa fa-bars mobile-nav-button"></a>
    </div>
  </div>
</header>

<div class="w-section section border-top">
  <div class="container">
    <div class="row" id="_modules/nengo_dl/tensor_graph">
      <div class="col-md-4 col-lg-3">
        <aside class="wrapper-navleft"><div role="complementary" class="bs-docs-sidebar hidden-print" id="nav-affix">
  <ul class="bs-docs-sidenav bs-sidenav nav" role="complementary">
    <a href="../../index.html">
      <img class="logo" src="https://www.nengo.ai/design/_images/nengo-dl-full-light.svg" alt="NengoDL" width="200" />
    </a>
    <ul class="toctree nav nav-list">
      <ul>
<li class="toctree-l1"><a class="reference internal" href="../../introduction.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../user-guide.html">User guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../reference.html">API reference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../examples.html">Examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../resources.html">Additional resources</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../project.html">Project information</a></li>
</ul>

    </ul>
  </ul>
</div>
          
        </aside>
      </div>
      <div class="col-md-8 col-lg-9">
        <div class="wrapper-content-right">
          
<div class="version-select-container">
    <div data-delay="0" class="w-dropdown">
        <div class="w-dropdown-toggle toggle">
            <div class="toggle-text">v2.1.1</div>
            <div class="w-icon-dropdown-toggle toggle-icon"></div>
        </div>
        <nav class="w-dropdown-list dropdown-list">
            
            
                <a href="../../../_modules/nengo_dl/tensor_graph.html" class="w-dropdown-link">latest</a>
            

            
                
                <div class="w-dropdown-link">v2.1.1</div>
                
            
                
                    <a href="../../../v2.1.0/_modules/nengo_dl/tensor_graph.html" class="w-dropdown-link">v2.1.0</a>
                
            
                
                    <a href="../../../v2.0.0/_modules/nengo_dl/tensor_graph.html" class="w-dropdown-link">v2.0.0</a>
                
            
                
                    <a href="../../../v1.2.1/_modules/nengo_dl/tensor_graph.html" class="w-dropdown-link">v1.2.1</a>
                
            
                
                    <a href="../../../v1.2.0/_modules/nengo_dl/tensor_graph.html" class="w-dropdown-link">v1.2.0</a>
                
            
                
                    <a href="../../../v1.1.0/_modules/nengo_dl/tensor_graph.html" class="w-dropdown-link">v1.1.0</a>
                
            
                
                    <a href="../../../v1.0.0/_modules/nengo_dl/tensor_graph.html" class="w-dropdown-link">v1.0.0</a>
                
            
                
                    <a href="../../../v0.6.2/_modules/nengo_dl/tensor_graph.html" class="w-dropdown-link">v0.6.2</a>
                
            
                
                    <a href="../../../v0.6.1/_modules/nengo_dl/tensor_graph.html" class="w-dropdown-link">v0.6.1</a>
                
            
                
                    <a href="../../../v0.6.0/_modules/nengo_dl/tensor_graph.html" class="w-dropdown-link">v0.6.0</a>
                
            
                
                    <a href="../../../v0.5.2/_modules/nengo_dl/tensor_graph.html" class="w-dropdown-link">v0.5.2</a>
                
            
                
                    <a href="../../../v0.5.1/_modules/nengo_dl/tensor_graph.html" class="w-dropdown-link">v0.5.1</a>
                
            
                
                    <a href="../../../v0.5.0/_modules/nengo_dl/tensor_graph.html" class="w-dropdown-link">v0.5.0</a>
                
            
                
                    <a href="../../../v0.4.0/_modules/nengo_dl/tensor_graph.html" class="w-dropdown-link">v0.4.0</a>
                
            
                
                    <a href="../../../v0.3.1/_modules/nengo_dl/tensor_graph.html" class="w-dropdown-link">v0.3.1</a>
                
            
                
                    <a href="../../../v0.3.0/_modules/nengo_dl/tensor_graph.html" class="w-dropdown-link">v0.3.0</a>
                
            
                
                    <a href="../../../v0.2.0/_modules/nengo_dl/tensor_graph.html" class="w-dropdown-link">v0.2.0</a>
                
            
        </nav>
    </div>
</div>

          
  <h1>Source code for nengo_dl.tensor_graph</h1><div class="highlight"><pre>
<span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">Manages all the data and build processes associated with the TensorFlow graph.</span>

<span class="sd">The TensorFlow graph is the symbolic description of the computations in the</span>
<span class="sd">network, which will be executed by the simulator.</span>
<span class="sd">&quot;&quot;&quot;</span>

<span class="kn">from</span> <span class="nn">__future__</span> <span class="k">import</span> <span class="n">print_function</span>

<span class="kn">from</span> <span class="nn">collections</span> <span class="k">import</span> <span class="n">OrderedDict</span><span class="p">,</span> <span class="n">defaultdict</span>
<span class="kn">import</span> <span class="nn">inspect</span>
<span class="kn">import</span> <span class="nn">itertools</span>
<span class="kn">import</span> <span class="nn">logging</span>
<span class="kn">import</span> <span class="nn">warnings</span>

<span class="kn">from</span> <span class="nn">nengo</span> <span class="k">import</span> <span class="n">Connection</span><span class="p">,</span> <span class="n">Process</span><span class="p">,</span> <span class="n">Ensemble</span>
<span class="kn">from</span> <span class="nn">nengo.builder.operator</span> <span class="k">import</span> <span class="n">TimeUpdate</span><span class="p">,</span> <span class="n">SimPyFunc</span><span class="p">,</span> <span class="n">Reset</span>
<span class="kn">from</span> <span class="nn">nengo.builder.processes</span> <span class="k">import</span> <span class="n">SimProcess</span>
<span class="kn">from</span> <span class="nn">nengo.config</span> <span class="k">import</span> <span class="n">ConfigError</span>
<span class="kn">from</span> <span class="nn">nengo.ensemble</span> <span class="k">import</span> <span class="n">Neurons</span>
<span class="kn">from</span> <span class="nn">nengo.exceptions</span> <span class="k">import</span> <span class="n">SimulationError</span><span class="p">,</span> <span class="n">ValidationError</span>
<span class="kn">from</span> <span class="nn">nengo.neurons</span> <span class="k">import</span> <span class="n">Direct</span>
<span class="kn">from</span> <span class="nn">nengo.utils.magic</span> <span class="k">import</span> <span class="n">decorator</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>

<span class="kn">from</span> <span class="nn">nengo_dl</span> <span class="k">import</span> <span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">graph_optimizer</span><span class="p">,</span> <span class="n">signals</span><span class="p">,</span> <span class="n">utils</span><span class="p">,</span> <span class="n">tensor_node</span><span class="p">,</span>
                      <span class="n">config</span><span class="p">)</span>

<span class="n">logger</span> <span class="o">=</span> <span class="n">logging</span><span class="o">.</span><span class="n">getLogger</span><span class="p">(</span><span class="vm">__name__</span><span class="p">)</span>


<div class="viewcode-block" id="with_self"><a class="viewcode-back" href="../../reference.html#nengo_dl.tensor_graph.with_self">[docs]</a><span class="nd">@decorator</span>
<span class="k">def</span> <span class="nf">with_self</span><span class="p">(</span><span class="n">wrapped</span><span class="p">,</span> <span class="n">instance</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">kwargs</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;A decorator that can be used to ensure that any ops created within the</span>
<span class="sd">    wrapped method will be added to the TensorGraph object&#39;s graph.&quot;&quot;&quot;</span>

    <span class="k">with</span> <span class="n">instance</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">as_default</span><span class="p">(),</span> <span class="n">instance</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="n">instance</span><span class="o">.</span><span class="n">device</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">wrapped</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></div>


<div class="viewcode-block" id="TensorGraph"><a class="viewcode-back" href="../../reference.html#nengo_dl.tensor_graph.TensorGraph">[docs]</a><span class="k">class</span> <span class="nc">TensorGraph</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Manages the construction of the TensorFlow symbolic computation graph.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    model : `~nengo.builder.Model`</span>
<span class="sd">        Pre-built Nengo model describing the network to be simulated</span>
<span class="sd">    dt : float</span>
<span class="sd">        Length of a simulator timestep, in seconds</span>
<span class="sd">    unroll_simulation : int</span>
<span class="sd">        Unroll simulation loop by explicitly building ``unroll_simulation``</span>
<span class="sd">        iterations into the computation graph</span>
<span class="sd">    dtype : ``tf.DType``</span>
<span class="sd">        Floating point precision to use for simulation</span>
<span class="sd">    minibatch_size : int</span>
<span class="sd">        The number of simultaneous inputs that will be passed through the</span>
<span class="sd">        network</span>
<span class="sd">    device : None or ``&quot;/cpu:0&quot;`` or ``&quot;/gpu:[0-n]&quot;``</span>
<span class="sd">        Device on which to execute computations (if None then uses the</span>
<span class="sd">        default device as determined by TensorFlow)</span>
<span class="sd">    progress : `.utils.ProgressBar`</span>
<span class="sd">        Progress bar for optimization stage</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">dt</span><span class="p">,</span> <span class="n">unroll_simulation</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">minibatch_size</span><span class="p">,</span>
                 <span class="n">device</span><span class="p">,</span> <span class="n">progress</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dt</span> <span class="o">=</span> <span class="n">dt</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">unroll</span> <span class="o">=</span> <span class="n">unroll_simulation</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dtype</span> <span class="o">=</span> <span class="n">dtype</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">minibatch_size</span> <span class="o">=</span> <span class="n">minibatch_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="n">device</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">graph</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Graph</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">signals</span> <span class="o">=</span> <span class="n">signals</span><span class="o">.</span><span class="n">SignalDict</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">minibatch_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">inference_only</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">get_setting</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="s2">&quot;inference_only&quot;</span><span class="p">,</span>
                                                 <span class="kc">False</span><span class="p">)</span>

        <span class="c1"># find invariant inputs (nodes that don&#39;t receive any input other</span>
        <span class="c1"># than the simulation time). we&#39;ll compute these outside the simulation</span>
        <span class="c1"># and feed in the result.</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">toplevel</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">invariant_inputs</span> <span class="o">=</span> <span class="n">OrderedDict</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">invariant_inputs</span> <span class="o">=</span> <span class="n">OrderedDict</span><span class="p">(</span>
                <span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">n</span><span class="o">.</span><span class="n">output</span><span class="p">)</span> <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">toplevel</span><span class="o">.</span><span class="n">all_nodes</span>
                <span class="k">if</span> <span class="n">n</span><span class="o">.</span><span class="n">size_in</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">and</span>
                <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">tensor_node</span><span class="o">.</span><span class="n">TensorNode</span><span class="p">))</span>

        <span class="c1"># filter unused operators</span>
        <span class="c1"># remove TimeUpdate because it is executed as part of the simulation</span>
        <span class="c1"># loop, not part of the step plan. remove input nodes because they</span>
        <span class="c1"># are executed outside the simulation.</span>
        <span class="n">node_processes</span> <span class="o">=</span> <span class="p">[</span><span class="n">n</span><span class="o">.</span><span class="n">output</span> <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">invariant_inputs</span>
                          <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">n</span><span class="o">.</span><span class="n">output</span><span class="p">,</span> <span class="n">Process</span><span class="p">)]</span>
        <span class="n">operators</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">op</span> <span class="k">for</span> <span class="n">op</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">operators</span> <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span>
                <span class="nb">isinstance</span><span class="p">(</span><span class="n">op</span><span class="p">,</span> <span class="n">TimeUpdate</span><span class="p">)</span> <span class="ow">or</span>
                <span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">op</span><span class="p">,</span> <span class="n">SimPyFunc</span><span class="p">)</span> <span class="ow">and</span> <span class="n">op</span><span class="o">.</span><span class="n">x</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">)</span> <span class="ow">or</span>
                <span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">op</span><span class="p">,</span> <span class="n">SimProcess</span><span class="p">)</span> <span class="ow">and</span> <span class="n">op</span><span class="o">.</span><span class="n">input</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span>
                 <span class="n">op</span><span class="o">.</span><span class="n">process</span> <span class="ow">in</span> <span class="n">node_processes</span><span class="p">))]</span>

        <span class="c1"># mark trainable signals</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mark_signals</span><span class="p">()</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Initial plan length: </span><span class="si">%d</span><span class="s2">&quot;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">operators</span><span class="p">))</span>

        <span class="c1"># apply graph simplification functions</span>
        <span class="n">simplifications</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">get_setting</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="s2">&quot;simplifications&quot;</span><span class="p">,</span> <span class="p">[</span>
            <span class="n">graph_optimizer</span><span class="o">.</span><span class="n">remove_constant_copies</span><span class="p">,</span>
            <span class="n">graph_optimizer</span><span class="o">.</span><span class="n">remove_unmodified_resets</span><span class="p">,</span>
            <span class="n">graph_optimizer</span><span class="o">.</span><span class="n">remove_zero_incs</span><span class="p">,</span>
            <span class="n">graph_optimizer</span><span class="o">.</span><span class="n">remove_identity_muls</span><span class="p">,</span>
        <span class="p">])</span>

        <span class="k">with</span> <span class="n">progress</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="s2">&quot;operator simplificaton&quot;</span><span class="p">,</span> <span class="n">max_value</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
            <span class="n">old_operators</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">while</span> <span class="nb">len</span><span class="p">(</span><span class="n">old_operators</span><span class="p">)</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="n">operators</span><span class="p">)</span> <span class="ow">or</span> <span class="nb">any</span><span class="p">(</span>
                    <span class="n">x</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">y</span> <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">operators</span><span class="p">,</span> <span class="n">old_operators</span><span class="p">)):</span>
                <span class="n">old_operators</span> <span class="o">=</span> <span class="n">operators</span>
                <span class="k">for</span> <span class="n">simp</span> <span class="ow">in</span> <span class="n">simplifications</span><span class="p">:</span>
                    <span class="n">operators</span> <span class="o">=</span> <span class="n">simp</span><span class="p">(</span><span class="n">operators</span><span class="p">)</span>

        <span class="c1"># group mergeable operators</span>
        <span class="n">planner</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">get_setting</span><span class="p">(</span>
            <span class="n">model</span><span class="p">,</span> <span class="s2">&quot;planner&quot;</span><span class="p">,</span> <span class="n">graph_optimizer</span><span class="o">.</span><span class="n">tree_planner</span><span class="p">)</span>

        <span class="k">with</span> <span class="n">progress</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="s2">&quot;merging operators&quot;</span><span class="p">,</span> <span class="n">max_value</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
            <span class="n">plan</span> <span class="o">=</span> <span class="n">planner</span><span class="p">(</span><span class="n">operators</span><span class="p">)</span>

        <span class="c1"># TODO: we could also merge operators sequentially (e.g., combine</span>
        <span class="c1"># a copy and dotinc into one op), as long as the intermediate signal</span>
        <span class="c1"># is only written to by one op and read by one op</span>

        <span class="c1"># order signals/operators to promote contiguous reads</span>
        <span class="n">sorter</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">get_setting</span><span class="p">(</span>
            <span class="n">model</span><span class="p">,</span> <span class="s2">&quot;sorter&quot;</span><span class="p">,</span> <span class="n">graph_optimizer</span><span class="o">.</span><span class="n">order_signals</span><span class="p">)</span>

        <span class="k">with</span> <span class="n">progress</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="s2">&quot;ordering signals&quot;</span><span class="p">,</span> <span class="n">max_value</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
            <span class="n">sigs</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">plan</span> <span class="o">=</span> <span class="n">sorter</span><span class="p">(</span><span class="n">plan</span><span class="p">,</span> <span class="n">n_passes</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>

        <span class="c1"># create base arrays and map Signals to TensorSignals (views on those</span>
        <span class="c1"># base arrays)</span>
        <span class="k">with</span> <span class="n">progress</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="s2">&quot;creating signals&quot;</span><span class="p">,</span> <span class="n">max_value</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">create_signals</span><span class="p">(</span><span class="n">sigs</span><span class="p">)</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Optimized plan length: </span><span class="si">%d</span><span class="s2">&quot;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">plan</span><span class="p">))</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Number of base arrays: </span><span class="si">%d</span><span class="s2">&quot;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">base_arrays_init</span><span class="p">))</span>

        <span class="c1"># initialize op builder</span>
        <span class="n">build_config</span> <span class="o">=</span> <span class="n">builder</span><span class="o">.</span><span class="n">BuildConfig</span><span class="p">(</span>
            <span class="n">inference_only</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">inference_only</span><span class="p">,</span>
            <span class="n">lif_smoothing</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">get_setting</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s2">&quot;lif_smoothing&quot;</span><span class="p">),</span>
            <span class="n">cpu_only</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span> <span class="o">==</span> <span class="s2">&quot;/cpu:0&quot;</span> <span class="ow">or</span> <span class="ow">not</span> <span class="n">utils</span><span class="o">.</span><span class="n">tf_gpu_installed</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">op_builder</span> <span class="o">=</span> <span class="n">builder</span><span class="o">.</span><span class="n">Builder</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">plan</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">graph</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">signals</span><span class="p">,</span>
                                          <span class="n">build_config</span><span class="p">)</span>

<div class="viewcode-block" id="TensorGraph.build"><a class="viewcode-back" href="../../reference.html#nengo_dl.tensor_graph.TensorGraph.build">[docs]</a>    <span class="nd">@with_self</span>
    <span class="k">def</span> <span class="nf">build</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">progress</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Constructs a new graph to simulate the model.</span>

<span class="sd">        progress : `.utils.ProgressBar`</span>
<span class="sd">            Progress bar for construction stage</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">target_phs</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">outputs</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">optimizers</span> <span class="o">=</span> <span class="p">{}</span>

        <span class="c1"># create these constants once here for reuse in different operators</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">signals</span><span class="o">.</span><span class="n">dt</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dt</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">signals</span><span class="o">.</span><span class="n">dt_val</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dt</span>  <span class="c1"># store the actual value as well</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">signals</span><span class="o">.</span><span class="n">zero</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">signals</span><span class="o">.</span><span class="n">one</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">inference_only</span><span class="p">:</span>
            <span class="c1"># this variable controls behaviour in the simulation that is</span>
            <span class="c1"># conditional on whether we are doing training or inference</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">signals</span><span class="o">.</span><span class="n">training</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">bool</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(),</span>
                                                   <span class="n">name</span><span class="o">=</span><span class="s2">&quot;training&quot;</span><span class="p">)</span>

            <span class="c1"># variable to track training step</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">training_step</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">get_or_create_global_step</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">training_step</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="c1"># create base arrays</span>
        <span class="n">sub</span> <span class="o">=</span> <span class="n">progress</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="s2">&quot;creating base arrays&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">base_vars</span> <span class="o">=</span> <span class="n">OrderedDict</span><span class="p">()</span>
        <span class="n">unique_ids</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">trainable</span><span class="p">)</span> <span class="ow">in</span> <span class="n">sub</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">base_arrays_init</span><span class="o">.</span><span class="n">items</span><span class="p">()):</span>
            <span class="n">name</span> <span class="o">=</span> <span class="s2">&quot;</span><span class="si">%s</span><span class="s2">_</span><span class="si">%s</span><span class="s2">_</span><span class="si">%s</span><span class="s2">_</span><span class="si">%d</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span>
                <span class="n">v</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="s2">&quot;_&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">v</span><span class="o">.</span><span class="n">shape</span><span class="p">),</span> <span class="n">trainable</span><span class="p">,</span>
                <span class="n">unique_ids</span><span class="p">[(</span><span class="n">v</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">v</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">trainable</span><span class="p">)])</span>
            <span class="n">unique_ids</span><span class="p">[(</span><span class="n">v</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">v</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">trainable</span><span class="p">)]</span> <span class="o">+=</span> <span class="mi">1</span>

            <span class="c1"># we initialize all the variables from placeholders, and then</span>
            <span class="c1"># feed in the initial values when the init op is called. this</span>
            <span class="c1"># prevents TensorFlow from storing large constants in the graph</span>
            <span class="c1"># def, which can cause problems for large models</span>
            <span class="n">ph</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">v</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">v</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;</span><span class="si">%s</span><span class="s2">_init&quot;</span> <span class="o">%</span> <span class="n">name</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">trainable</span><span class="p">:</span>
                <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">variable_scope</span><span class="p">(</span><span class="s2">&quot;trainable_vars&quot;</span><span class="p">,</span> <span class="n">reuse</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
                    <span class="n">var</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">get_variable</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">initializer</span><span class="o">=</span><span class="n">ph</span><span class="p">,</span> <span class="n">trainable</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">variable_scope</span><span class="p">(</span><span class="s2">&quot;local_vars&quot;</span><span class="p">,</span> <span class="n">reuse</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
                    <span class="n">var</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">get_local_variable</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">initializer</span><span class="o">=</span><span class="n">ph</span><span class="p">,</span>
                                                <span class="n">trainable</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">base_vars</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">var</span><span class="p">,</span> <span class="n">ph</span><span class="p">,</span> <span class="n">v</span><span class="p">)</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot;created base arrays&quot;</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">([</span><span class="nb">str</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">base_vars</span><span class="o">.</span><span class="n">values</span><span class="p">()])</span>

        <span class="c1"># set up invariant inputs</span>
        <span class="n">sub</span> <span class="o">=</span> <span class="n">progress</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="s2">&quot;building inputs&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">build_inputs</span><span class="p">(</span><span class="n">sub</span><span class="p">)</span>

        <span class="c1"># pre-build stage</span>
        <span class="k">with</span> <span class="n">progress</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="s2">&quot;pre-build stage&quot;</span><span class="p">,</span> <span class="n">max_value</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">plan</span><span class="p">))</span> <span class="k">as</span> <span class="n">sub</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">op_builder</span><span class="o">.</span><span class="n">pre_build</span><span class="p">(</span><span class="n">sub</span><span class="p">)</span>

        <span class="c1"># build stage</span>
        <span class="k">with</span> <span class="n">progress</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span>
                <span class="s2">&quot;build stage&quot;</span><span class="p">,</span> <span class="n">max_value</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">plan</span><span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">unroll</span><span class="p">)</span> <span class="k">as</span> <span class="n">sub</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">build_loop</span><span class="p">(</span><span class="n">sub</span><span class="p">)</span>

        <span class="c1"># ops for initializing variables (will be called by simulator)</span>
        <span class="n">trainable_vars</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">trainable_variables</span><span class="p">()</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">inference_only</span><span class="p">:</span>
            <span class="n">trainable_vars</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">training_step</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">trainable_init_op</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">variables_initializer</span><span class="p">(</span><span class="n">trainable_vars</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">local_init_op</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">local_variables_initializer</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">global_init_op</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">variables_initializer</span><span class="p">(</span>
            <span class="p">[</span><span class="n">v</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">tf</span><span class="o">.</span><span class="n">global_variables</span><span class="p">()</span> <span class="k">if</span> <span class="n">v</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">trainable_vars</span><span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">constant_init_op</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">variables_initializer</span><span class="p">(</span>
            <span class="n">tf</span><span class="o">.</span><span class="n">get_collection</span><span class="p">(</span><span class="s2">&quot;constants&quot;</span><span class="p">))</span>

        <span class="c1"># logging</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Number of reads: </span><span class="si">%d</span><span class="s2">&quot;</span><span class="p">,</span> <span class="nb">sum</span><span class="p">(</span>
            <span class="n">x</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">signals</span><span class="o">.</span><span class="n">read_types</span><span class="o">.</span><span class="n">values</span><span class="p">()))</span>
        <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">signals</span><span class="o">.</span><span class="n">read_types</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;    </span><span class="si">%s</span><span class="s2">: </span><span class="si">%d</span><span class="s2">&quot;</span><span class="p">,</span> <span class="o">*</span><span class="n">x</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Number of writes: </span><span class="si">%d</span><span class="s2">&quot;</span><span class="p">,</span> <span class="nb">sum</span><span class="p">(</span>
            <span class="n">x</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">signals</span><span class="o">.</span><span class="n">write_types</span><span class="o">.</span><span class="n">values</span><span class="p">()))</span>
        <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">signals</span><span class="o">.</span><span class="n">write_types</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;    </span><span class="si">%s</span><span class="s2">: </span><span class="si">%d</span><span class="s2">&quot;</span><span class="p">,</span> <span class="o">*</span><span class="n">x</span><span class="p">)</span></div>

<div class="viewcode-block" id="TensorGraph.build_step"><a class="viewcode-back" href="../../reference.html#nengo_dl.tensor_graph.TensorGraph.build_step">[docs]</a>    <span class="k">def</span> <span class="nf">build_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">progress</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Build the operators that execute a single simulation timestep</span>
<span class="sd">        into the graph.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        progress : `.utils.ProgressBar`</span>
<span class="sd">            Progress bar for loop construction</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        probe_tensors : list of ``tf.Tensor``</span>
<span class="sd">            The Tensor objects representing the data required for each model</span>
<span class="sd">            Probe</span>
<span class="sd">        side_effects : list of ``tf.Tensor``</span>
<span class="sd">            The output Tensors of computations that may have side-effects</span>
<span class="sd">            (e.g., `~nengo.Node` functions), meaning that they</span>
<span class="sd">            must be executed each time step even if their output doesn&#39;t appear</span>
<span class="sd">            to be used in the simulation</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c1"># manually build TimeUpdate. we don&#39;t include this in the plan,</span>
        <span class="c1"># because loop variables (`step`) are (semi?) pinned to the CPU, which</span>
        <span class="c1"># causes the whole variable to get pinned to the CPU if we include</span>
        <span class="c1"># `step` as part of the normal planning process.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">signals</span><span class="o">.</span><span class="n">time</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">signals</span><span class="o">.</span><span class="n">step</span><span class="p">,</span>
                                    <span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">signals</span><span class="o">.</span><span class="n">dt</span>

        <span class="c1"># build operators</span>
        <span class="n">side_effects</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">op_builder</span><span class="o">.</span><span class="n">build</span><span class="p">(</span><span class="n">progress</span><span class="p">)</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot;collecting probe tensors&quot;</span><span class="p">)</span>
        <span class="n">probe_tensors</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">probes</span><span class="p">:</span>
            <span class="n">probe_sig</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">sig</span><span class="p">[</span><span class="n">p</span><span class="p">][</span><span class="s2">&quot;in&quot;</span><span class="p">]</span>
            <span class="k">if</span> <span class="n">probe_sig</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">signals</span><span class="p">:</span>
                <span class="c1"># TODO: better solution to avoid the forced_copy</span>
                <span class="c1"># we need to make sure that probe reads occur before the</span>
                <span class="c1"># probe value is overwritten on the next timestep. however,</span>
                <span class="c1"># just blocking on the sliced value (probe_tensor) doesn&#39;t</span>
                <span class="c1"># work, because slices of variables don&#39;t perform a</span>
                <span class="c1"># copy, so the slice can be &quot;executed&quot; and then the value</span>
                <span class="c1"># overwritten before the tensorarray write occurs. what we</span>
                <span class="c1"># really want to do is block until the probe_arrays.write</span>
                <span class="c1"># happens, but you can&#39;t block on probe_arrays (and blocking on</span>
                <span class="c1"># probe_array.flow doesn&#39;t work, although I think it should).</span>
                <span class="c1"># so by adding the copy here and then blocking on the copy, we</span>
                <span class="c1"># make sure that the probe value is read before it can be</span>
                <span class="c1"># overwritten.</span>
                <span class="n">probe_tensors</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">signals</span><span class="o">.</span><span class="n">gather</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">signals</span><span class="p">[</span><span class="n">probe_sig</span><span class="p">],</span> <span class="n">force_copy</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># if a probe signal isn&#39;t in sig_map, that means that it isn&#39;t</span>
                <span class="c1"># involved in any simulator ops.  so we know its value never</span>
                <span class="c1"># changes, and we&#39;ll just return a constant containing the</span>
                <span class="c1"># initial value.</span>
                <span class="k">if</span> <span class="n">probe_sig</span><span class="o">.</span><span class="n">minibatched</span><span class="p">:</span>
                    <span class="n">init_val</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">tile</span><span class="p">(</span><span class="n">probe_sig</span><span class="o">.</span><span class="n">initial_value</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="kc">None</span><span class="p">],</span>
                                       <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">minibatch_size</span><span class="p">))</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">init_val</span> <span class="o">=</span> <span class="n">probe_sig</span><span class="o">.</span><span class="n">initial_value</span>
                <span class="n">probe_tensors</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="n">init_val</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">))</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">30</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot;build_step complete&quot;</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot;probe_tensors </span><span class="si">%s</span><span class="s2">&quot;</span><span class="p">,</span> <span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">probe_tensors</span><span class="p">])</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot;side_effects </span><span class="si">%s</span><span class="s2">&quot;</span><span class="p">,</span> <span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">side_effects</span><span class="p">])</span>

        <span class="k">return</span> <span class="n">probe_tensors</span><span class="p">,</span> <span class="n">side_effects</span></div>

<div class="viewcode-block" id="TensorGraph.build_loop"><a class="viewcode-back" href="../../reference.html#nengo_dl.tensor_graph.TensorGraph.build_loop">[docs]</a>    <span class="k">def</span> <span class="nf">build_loop</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">progress</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Build simulation loop.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        progress : `.utils.ProgressBar`</span>
<span class="sd">            Progress bar for loop construction</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">def</span> <span class="nf">loop_condition</span><span class="p">(</span><span class="n">step</span><span class="p">,</span> <span class="n">stop</span><span class="p">,</span> <span class="o">*</span><span class="n">_</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">step</span> <span class="o">&lt;</span> <span class="n">stop</span>

        <span class="k">def</span> <span class="nf">loop_body</span><span class="p">(</span><span class="n">step</span><span class="p">,</span> <span class="n">stop</span><span class="p">,</span> <span class="n">loop_i</span><span class="p">,</span> <span class="n">probe_arrays</span><span class="p">,</span> <span class="n">base_vars</span><span class="p">):</span>
            <span class="c1"># fill in signals.bases (note: we need to do this here because we</span>
            <span class="c1"># need to use the versions of the base vars from inside the</span>
            <span class="c1"># loop, not the static variables in self.base_vars)</span>
            <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">signals</span><span class="o">.</span><span class="n">bases</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span>
            <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">key</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">itertools</span><span class="o">.</span><span class="n">chain</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">base_vars</span><span class="o">.</span><span class="n">keys</span><span class="p">(),</span> <span class="bp">self</span><span class="o">.</span><span class="n">signals</span><span class="o">.</span><span class="n">internal_vars</span><span class="o">.</span><span class="n">keys</span><span class="p">())):</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">signals</span><span class="o">.</span><span class="n">bases</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">base_vars</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>

            <span class="k">for</span> <span class="nb">iter</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">unroll</span><span class="p">):</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot;BUILDING ITERATION </span><span class="si">%d</span><span class="s2">&quot;</span><span class="p">,</span> <span class="nb">iter</span><span class="p">)</span>
                <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="s2">&quot;iteration_</span><span class="si">%d</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="nb">iter</span><span class="p">):</span>
                    <span class="c1"># note: nengo step counter is incremented at the beginning</span>
                    <span class="c1"># of the timestep</span>
                    <span class="n">step</span> <span class="o">+=</span> <span class="mi">1</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">signals</span><span class="o">.</span><span class="n">step</span> <span class="o">=</span> <span class="n">step</span>

                    <span class="c1"># fill in invariant input data</span>
                    <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_ph</span><span class="p">:</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">signals</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span>
                            <span class="bp">self</span><span class="o">.</span><span class="n">signals</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">sig</span><span class="p">[</span><span class="n">n</span><span class="p">][</span><span class="s2">&quot;out&quot;</span><span class="p">]],</span>
                            <span class="bp">self</span><span class="o">.</span><span class="n">input_ph</span><span class="p">[</span><span class="n">n</span><span class="p">][</span><span class="n">loop_i</span><span class="p">])</span>

                    <span class="c1"># build the operators for a single step</span>
                    <span class="c1"># note: we tie things to the `loop_i` variable so that we</span>
                    <span class="c1"># can be sure the other things we&#39;re tying to the</span>
                    <span class="c1"># simulation step (side effects and probes) from the</span>
                    <span class="c1"># previous timestep are executed before the next step</span>
                    <span class="c1"># starts</span>
                    <span class="c1"># note2: we use the variable scope to make sure that we</span>
                    <span class="c1"># aren&#39;t accidentally creating new variables for</span>
                    <span class="c1"># unrolled iterations (this is really only a concern</span>
                    <span class="c1"># with TensorNodes)</span>
                    <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">control_dependencies</span><span class="p">([</span><span class="n">loop_i</span><span class="p">]),</span> \
                            <span class="n">tf</span><span class="o">.</span><span class="n">variable_scope</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">get_variable_scope</span><span class="p">(),</span>
                                              <span class="n">reuse</span><span class="o">=</span><span class="nb">iter</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">):</span>
                        <span class="n">probe_tensors</span><span class="p">,</span> <span class="n">side_effects</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">build_step</span><span class="p">(</span><span class="n">progress</span><span class="p">)</span>

                    <span class="c1"># copy probe data to array</span>
                    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">p</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">probe_tensors</span><span class="p">):</span>
                        <span class="k">if</span> <span class="n">config</span><span class="o">.</span><span class="n">get_setting</span><span class="p">(</span>
                                <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s2">&quot;keep_history&quot;</span><span class="p">,</span>
                                <span class="n">default</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">obj</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">probes</span><span class="p">[</span><span class="n">i</span><span class="p">]):</span>
                            <span class="n">probe_arrays</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">probe_arrays</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">loop_i</span><span class="p">,</span> <span class="n">p</span><span class="p">)</span>
                        <span class="k">else</span><span class="p">:</span>
                            <span class="n">probe_arrays</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">cond</span><span class="p">(</span>
                                <span class="n">tf</span><span class="o">.</span><span class="n">equal</span><span class="p">(</span><span class="n">step</span><span class="p">,</span> <span class="n">stop</span><span class="p">),</span>
                                <span class="k">lambda</span> <span class="n">p</span><span class="o">=</span><span class="n">p</span><span class="p">:</span> <span class="n">probe_arrays</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">p</span><span class="p">),</span>
                                <span class="k">lambda</span><span class="p">:</span> <span class="n">probe_arrays</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>

                    <span class="c1"># need to make sure that any operators that could have side</span>
                    <span class="c1"># effects run each timestep, so we tie them to the loop</span>
                    <span class="c1"># increment. we also need to make sure that all the probe</span>
                    <span class="c1"># reads happen before those values get overwritten on the</span>
                    <span class="c1"># next timestep</span>
                    <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">control_dependencies</span><span class="p">(</span><span class="n">side_effects</span> <span class="o">+</span>
                                                         <span class="n">probe_tensors</span><span class="p">):</span>
                        <span class="n">loop_i</span> <span class="o">+=</span> <span class="mi">1</span>

            <span class="n">base_vars</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">signals</span><span class="o">.</span><span class="n">bases</span><span class="o">.</span><span class="n">values</span><span class="p">())</span>

            <span class="k">return</span> <span class="n">step</span><span class="p">,</span> <span class="n">stop</span><span class="p">,</span> <span class="n">loop_i</span><span class="p">,</span> <span class="n">probe_arrays</span><span class="p">,</span> <span class="n">base_vars</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">step_var</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(),</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;step&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">stop_var</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(),</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;stop&quot;</span><span class="p">)</span>
        <span class="n">loop_i</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

        <span class="n">probe_arrays</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">tf</span><span class="o">.</span><span class="n">TensorArray</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">clear_after_read</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                <span class="n">dynamic_size</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">probes</span><span class="p">]</span>

        <span class="c1"># build simulation loop</span>
        <span class="n">loop_vars</span> <span class="o">=</span> <span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">step_var</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">stop_var</span><span class="p">,</span> <span class="n">loop_i</span><span class="p">,</span> <span class="n">probe_arrays</span><span class="p">,</span>
            <span class="nb">tuple</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">_ref</span><span class="p">()</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">)</span> <span class="k">else</span> <span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
                  <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">base_vars</span><span class="o">.</span><span class="n">values</span><span class="p">())</span> <span class="o">+</span>
            <span class="nb">tuple</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">_ref</span><span class="p">()</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">signals</span><span class="o">.</span><span class="n">internal_vars</span><span class="o">.</span><span class="n">values</span><span class="p">()))</span>

        <span class="n">loop_vars</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">while_loop</span><span class="p">(</span>
            <span class="n">loop_condition</span><span class="p">,</span> <span class="n">loop_body</span><span class="p">,</span> <span class="n">loop_vars</span><span class="o">=</span><span class="n">loop_vars</span><span class="p">,</span>
            <span class="n">parallel_iterations</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">back_prop</span><span class="o">=</span><span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">inference_only</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">steps_run</span> <span class="o">=</span> <span class="n">loop_vars</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">probe_arrays</span> <span class="o">=</span> <span class="n">OrderedDict</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">p</span><span class="p">,</span> <span class="n">a</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">probes</span><span class="p">,</span> <span class="n">loop_vars</span><span class="p">[</span><span class="mi">3</span><span class="p">]):</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">stack</span><span class="p">()</span>

            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">sig</span><span class="p">[</span><span class="n">p</span><span class="p">][</span><span class="s2">&quot;in&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">minibatched</span><span class="p">:</span>
                <span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">roll</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">get_shape</span><span class="p">()</span><span class="o">.</span><span class="n">ndims</span><span class="p">),</span> <span class="mi">1</span><span class="p">))</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">probe_arrays</span><span class="p">[</span><span class="n">p</span><span class="p">]</span> <span class="o">=</span> <span class="n">x</span></div>

<div class="viewcode-block" id="TensorGraph.build_inputs"><a class="viewcode-back" href="../../reference.html#nengo_dl.tensor_graph.TensorGraph.build_inputs">[docs]</a>    <span class="k">def</span> <span class="nf">build_inputs</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">progress</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Sets up the inputs in the model (which will be computed outside of</span>
<span class="sd">        TensorFlow and fed in each simulation block).</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        progress : `.utils.ProgressBar`</span>
<span class="sd">            Progress bar for input construction</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">input_ph</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="n">progress</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">invariant_inputs</span><span class="p">):</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">sig</span><span class="p">[</span><span class="n">n</span><span class="p">][</span><span class="s2">&quot;out&quot;</span><span class="p">]</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">signals</span><span class="p">:</span>
                <span class="c1"># set up a placeholder input for this node</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">input_ph</span><span class="p">[</span><span class="n">n</span><span class="p">]</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">n</span><span class="o">.</span><span class="n">size_out</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">minibatch_size</span><span class="p">),</span>
                    <span class="n">name</span><span class="o">=</span><span class="s2">&quot;</span><span class="si">%s</span><span class="s2">_ph&quot;</span> <span class="o">%</span> <span class="n">utils</span><span class="o">.</span><span class="n">sanitize_name</span><span class="p">(</span><span class="n">n</span><span class="p">))</span></div>

<div class="viewcode-block" id="TensorGraph.build_optimizer_func"><a class="viewcode-back" href="../../reference.html#nengo_dl.tensor_graph.TensorGraph.build_optimizer_func">[docs]</a>    <span class="k">def</span> <span class="nf">build_optimizer_func</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">objective</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Adds elements into the graph to execute the given optimizer.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        optimizer : ``tf.train.Optimizer``</span>
<span class="sd">            Instance of a TensorFlow optimizer class</span>
<span class="sd">        objective : dict of {`~nengo.Probe`: callable or ``None``}</span>
<span class="sd">            The objective to be minimized. This is a dictionary mapping Probes</span>
<span class="sd">            to functions</span>
<span class="sd">            ``f(output, target) -&gt; loss`` that consume the actual output and</span>
<span class="sd">            target output for the given probe(s) and return a ``tf.Tensor``</span>
<span class="sd">            representing a scalar loss value.  The function may also accept a</span>
<span class="sd">            single argument ``f(output) -&gt; loss`` if targets are not required.</span>
<span class="sd">            Some common objective functions can be found in</span>
<span class="sd">            `nengo_dl.objectives`.</span>

<span class="sd">            Passing ``None`` as the probe value (instead of a callable)</span>
<span class="sd">            indicates that the error is being computed outside the simulation,</span>
<span class="sd">            and the value passed for that probe in ``data`` directly specifies</span>
<span class="sd">            the output error gradient.</span>

<span class="sd">            If multiple probes are specified as the key, then the corresponding</span>
<span class="sd">            output/target values will be passed as a list to the objective</span>
<span class="sd">            function.</span>

<span class="sd">            The overall loss value being minimized will be the sum across all</span>
<span class="sd">            the objectives specified.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        apply_optimizer : callable</span>
<span class="sd">            A function that builds the operators required to implement the</span>
<span class="sd">            given optimizer update.  Generally this function will then be</span>
<span class="sd">            passed to `~.build_outputs`.</span>

<span class="sd">        Notes</span>
<span class="sd">        -----</span>
<span class="sd">        This function caches its outputs, so if it is called again with the</span>
<span class="sd">        same arguments then it will return the previous function.  This avoids</span>
<span class="sd">        building duplicates of the same operations over and over.  This can</span>
<span class="sd">        also be important functionally, e.g. if the optimizer has internal</span>
<span class="sd">        state like momentum.  By caching the output we ensure that subsequent</span>
<span class="sd">        calls share the same internal state.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">key</span> <span class="o">=</span> <span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="nb">frozenset</span><span class="p">(</span><span class="n">objective</span><span class="o">.</span><span class="n">items</span><span class="p">()))</span>

        <span class="k">try</span><span class="p">:</span>
            <span class="c1"># return the cached optimizer function if it exists</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimizers</span><span class="p">[</span><span class="n">key</span><span class="p">]</span>
        <span class="k">except</span> <span class="ne">KeyError</span><span class="p">:</span>
            <span class="k">pass</span>

        <span class="c1"># note: the standard workflow is that sim.train calls</span>
        <span class="c1"># build_optimizer_func to get this function. it then passes the</span>
        <span class="c1"># function to run_batch, which calls build_outputs to actually</span>
        <span class="c1"># build these operations into the graph. we do this somewhat</span>
        <span class="c1"># indirect method so that everything passes through build_output,</span>
        <span class="c1"># allowing us to consolidate certain logic there (like capturing</span>
        <span class="c1"># new variables)</span>
        <span class="k">def</span> <span class="nf">apply_optimizer</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">):</span>
            <span class="c1"># note: we don&#39;t actually use outputs/targets, because the same</span>
            <span class="c1"># data is pulled implicitly from `objective` below.</span>
            <span class="c1"># we just check that outputs and targets match up with</span>
            <span class="c1"># objective, to make sure there&#39;s nothing weird going on.</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">):</span>
                <span class="n">outputs</span> <span class="o">=</span> <span class="p">(</span><span class="n">outputs</span><span class="p">,)</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">targets</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">):</span>
                <span class="n">targets</span> <span class="o">=</span> <span class="p">(</span><span class="n">targets</span><span class="p">,)</span>
            <span class="k">assert</span> <span class="nb">set</span><span class="p">(</span><span class="n">outputs</span><span class="p">)</span> <span class="o">==</span> <span class="nb">set</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">probe_arrays</span><span class="p">[</span><span class="n">p</span><span class="p">]</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">objective</span><span class="p">)</span>
            <span class="k">assert</span> <span class="nb">set</span><span class="p">(</span><span class="n">targets</span><span class="p">)</span> <span class="o">==</span> <span class="nb">set</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">target_phs</span><span class="p">[</span><span class="n">p</span><span class="p">]</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">objective</span><span class="p">)</span>

            <span class="n">agg_method</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">AggregationMethod</span><span class="o">.</span><span class="n">DEFAULT</span>
            <span class="n">grads</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="nb">vars</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">trainable_variables</span><span class="p">()</span>

            <span class="c1"># compute loss</span>
            <span class="c1"># note: we drop the `None` items in objective, because we</span>
            <span class="c1"># want to treat those as direct gradients (rather than</span>
            <span class="c1"># returning the probe value, which is the standard behaviour for</span>
            <span class="c1"># build_outputs)</span>
            <span class="n">loss</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">build_outputs</span><span class="p">(</span>
                <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">v</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">objective</span><span class="o">.</span><span class="n">items</span><span class="p">()</span> <span class="k">if</span> <span class="n">v</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">})</span>

            <span class="c1"># compute gradients wrt loss</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="c1"># reduce loss to a scalar</span>
                <span class="n">loss</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">([</span><span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">v</span><span class="p">)</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">loss</span><span class="o">.</span><span class="n">values</span><span class="p">()])</span>

                <span class="n">grads</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">gradients</span><span class="p">(</span>
                    <span class="n">loss</span><span class="p">,</span> <span class="nb">vars</span><span class="p">,</span> <span class="n">aggregation_method</span><span class="o">=</span><span class="n">agg_method</span><span class="p">))</span>

            <span class="c1"># add in any gradients where the user directly specified the output</span>
            <span class="c1"># error grad</span>
            <span class="k">for</span> <span class="n">p</span><span class="p">,</span> <span class="n">g</span> <span class="ow">in</span> <span class="n">objective</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                <span class="k">if</span> <span class="n">g</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">grads</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">gradients</span><span class="p">(</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">probe_arrays</span><span class="p">[</span><span class="n">p</span><span class="p">],</span> <span class="nb">vars</span><span class="p">,</span> <span class="n">grad_ys</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">target_phs</span><span class="p">[</span><span class="n">p</span><span class="p">],</span>
                        <span class="n">aggregation_method</span><span class="o">=</span><span class="n">agg_method</span><span class="p">))</span>

            <span class="c1"># combine gradients for each variable</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">grads</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                <span class="n">grads</span> <span class="o">=</span> <span class="n">grads</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">grads</span> <span class="o">=</span> <span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">gs</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="k">for</span> <span class="n">gs</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="n">grads</span><span class="p">)]</span>

            <span class="n">opt_op</span> <span class="o">=</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">apply_gradients</span><span class="p">(</span>
                <span class="nb">zip</span><span class="p">(</span><span class="n">grads</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">trainable_variables</span><span class="p">()),</span>
                <span class="n">global_step</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">training_step</span><span class="p">)</span>

            <span class="c1"># this is the op that increments the global step. we set it to</span>
            <span class="c1"># be the output value of that op, rather than the op itself, so</span>
            <span class="c1"># that it returns the global step value.</span>
            <span class="n">opt_op</span> <span class="o">=</span> <span class="n">opt_op</span><span class="o">.</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

            <span class="k">return</span> <span class="n">opt_op</span><span class="p">,</span> <span class="n">loss</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">optimizers</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">apply_optimizer</span>

        <span class="k">return</span> <span class="n">apply_optimizer</span></div>

<div class="viewcode-block" id="TensorGraph.build_outputs"><a class="viewcode-back" href="../../reference.html#nengo_dl.tensor_graph.TensorGraph.build_outputs">[docs]</a>    <span class="nd">@with_self</span>
    <span class="k">def</span> <span class="nf">build_outputs</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">outputs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Adds elements into the graph to compute the given outputs.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        outputs : dict of {(tuple of) `~nengo.Probe`: callable or None}</span>
<span class="sd">            The output function to be applied to each probe or group of probes.</span>
<span class="sd">            The function can accept one argument (the output of that probe) or</span>
<span class="sd">            two (output and target values for that probe).  If a tuple of</span>
<span class="sd">            Probes are given as the key, then those output/target parameters</span>
<span class="sd">            will be the corresponding tuple of probe/target values.  The</span>
<span class="sd">            function should return a ``tf.Tensor`` or tuple of Tensors</span>
<span class="sd">            representing the output we want from those probes.  If ``None`` is</span>
<span class="sd">            given instead of a function then the output will simply be the</span>
<span class="sd">            output value from the corresponding probes.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        output_vals : dict of {(tuple of) `~nengo.Probe`: \</span>
<span class="sd">                               (tuple of) ``tf.Tensor``}</span>
<span class="sd">            Tensors representing the result of applying the output functions</span>
<span class="sd">            to the probes.</span>
<span class="sd">        new_vars_init : ``tf.Tensor`` or None</span>
<span class="sd">            Initialization op for any new variables created when building</span>
<span class="sd">            the outputs.</span>

<span class="sd">        Notes</span>
<span class="sd">        -----</span>
<span class="sd">        This function caches its outputs, so if it is called again with the</span>
<span class="sd">        same arguments then it will return the previous Tensors.  This avoids</span>
<span class="sd">        building duplicates of the same operations over and over.  This can</span>
<span class="sd">        also be important functionally, e.g. if the outputs have internal</span>
<span class="sd">        state.  By caching the output we ensure that subsequent</span>
<span class="sd">        calls share the same internal state.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">key</span> <span class="o">=</span> <span class="nb">frozenset</span><span class="p">(</span><span class="n">outputs</span><span class="o">.</span><span class="n">items</span><span class="p">())</span>

        <span class="k">try</span><span class="p">:</span>
            <span class="c1"># return the cached outputs if they exist</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">outputs</span><span class="p">[</span><span class="n">key</span><span class="p">],</span> <span class="kc">None</span>
        <span class="k">except</span> <span class="ne">KeyError</span><span class="p">:</span>
            <span class="k">pass</span>

        <span class="n">output_vals</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="n">new_vars</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">probes</span><span class="p">,</span> <span class="n">out</span> <span class="ow">in</span> <span class="n">outputs</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="n">is_tuple</span> <span class="o">=</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">probes</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)</span>
            <span class="n">probe_arrays</span> <span class="o">=</span> <span class="p">(</span>
                <span class="nb">tuple</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">probe_arrays</span><span class="p">[</span><span class="n">p</span><span class="p">]</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">probes</span><span class="p">)</span> <span class="k">if</span> <span class="n">is_tuple</span> <span class="k">else</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">probe_arrays</span><span class="p">[</span><span class="n">probes</span><span class="p">])</span>

            <span class="k">if</span> <span class="n">out</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="c1"># return probe output value</span>
                <span class="n">output_vals</span><span class="p">[</span><span class="n">probes</span><span class="p">]</span> <span class="o">=</span> <span class="n">probe_arrays</span>
            <span class="k">elif</span> <span class="n">callable</span><span class="p">(</span><span class="n">out</span><span class="p">):</span>
                <span class="c1"># look up number of positional arguments for function</span>
                <span class="n">spec</span> <span class="o">=</span> <span class="n">inspect</span><span class="o">.</span><span class="n">getfullargspec</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>

                <span class="n">nargs</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">spec</span><span class="o">.</span><span class="n">args</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">spec</span><span class="o">.</span><span class="n">defaults</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="c1"># don&#39;t count keyword arguments</span>
                    <span class="n">nargs</span> <span class="o">-=</span> <span class="nb">len</span><span class="p">(</span><span class="n">spec</span><span class="o">.</span><span class="n">defaults</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">inspect</span><span class="o">.</span><span class="n">ismethod</span><span class="p">(</span><span class="n">out</span><span class="p">)</span> <span class="ow">or</span> <span class="ow">not</span> <span class="n">inspect</span><span class="o">.</span><span class="n">isroutine</span><span class="p">(</span><span class="n">out</span><span class="p">):</span>
                    <span class="c1"># don&#39;t count self argument for methods or callable classes</span>
                    <span class="n">nargs</span> <span class="o">-=</span> <span class="mi">1</span>

                <span class="c1"># build function arguments</span>
                <span class="k">if</span> <span class="n">nargs</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                    <span class="n">args</span> <span class="o">=</span> <span class="p">[</span><span class="n">probe_arrays</span><span class="p">]</span>
                <span class="k">elif</span> <span class="n">nargs</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
                    <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">probes</span> <span class="k">if</span> <span class="n">is_tuple</span> <span class="k">else</span> <span class="p">(</span><span class="n">probes</span><span class="p">,):</span>
                        <span class="c1"># create a placeholder for the target values if one</span>
                        <span class="c1"># hasn&#39;t been created yet</span>
                        <span class="k">if</span> <span class="n">p</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">target_phs</span><span class="p">:</span>
                            <span class="bp">self</span><span class="o">.</span><span class="n">target_phs</span><span class="p">[</span><span class="n">p</span><span class="p">]</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span>
                                <span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
                                <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">minibatch_size</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">size_in</span><span class="p">),</span>
                                <span class="n">name</span><span class="o">=</span><span class="s2">&quot;</span><span class="si">%s</span><span class="s2">_ph&quot;</span> <span class="o">%</span> <span class="n">utils</span><span class="o">.</span><span class="n">sanitize_name</span><span class="p">(</span><span class="n">p</span><span class="p">))</span>
                    <span class="n">target_phs</span> <span class="o">=</span> <span class="p">(</span><span class="nb">tuple</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">target_phs</span><span class="p">[</span><span class="n">p</span><span class="p">]</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">probes</span><span class="p">)</span>
                                  <span class="k">if</span> <span class="n">is_tuple</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">target_phs</span><span class="p">[</span><span class="n">probes</span><span class="p">])</span>
                    <span class="n">args</span> <span class="o">=</span> <span class="p">[</span><span class="n">probe_arrays</span><span class="p">,</span> <span class="n">target_phs</span><span class="p">]</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="n">ValidationError</span><span class="p">(</span>
                        <span class="s2">&quot;Output functions must accept 1 or 2 arguments; &#39;</span><span class="si">%s</span><span class="s2">&#39; &quot;</span>
                        <span class="s2">&quot;takes </span><span class="si">%s</span><span class="s2"> arguments&quot;</span> <span class="o">%</span> <span class="p">(</span>
                            <span class="n">utils</span><span class="o">.</span><span class="n">function_name</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="n">sanitize</span><span class="o">=</span><span class="kc">False</span><span class="p">),</span> <span class="n">nargs</span><span class="p">),</span>
                        <span class="s2">&quot;outputs&quot;</span><span class="p">)</span>

                <span class="c1"># apply output function</span>
                <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">variable_scope</span><span class="p">(</span><span class="n">utils</span><span class="o">.</span><span class="n">function_name</span><span class="p">(</span><span class="n">out</span><span class="p">))</span> <span class="k">as</span> <span class="n">scope</span><span class="p">:</span>
                    <span class="n">output_vals</span><span class="p">[</span><span class="n">probes</span><span class="p">]</span> <span class="o">=</span> <span class="n">out</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">)</span>

                <span class="c1"># collect any new variables from building the outputs</span>
                <span class="k">for</span> <span class="n">collection</span> <span class="ow">in</span> <span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">GraphKeys</span><span class="o">.</span><span class="n">GLOBAL_VARIABLES</span><span class="p">,</span>
                                   <span class="n">tf</span><span class="o">.</span><span class="n">GraphKeys</span><span class="o">.</span><span class="n">LOCAL_VARIABLES</span><span class="p">,</span>
                                   <span class="s2">&quot;gradient_vars&quot;</span><span class="p">]:</span>
                    <span class="n">new_vars</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">scope</span><span class="o">.</span><span class="n">get_collection</span><span class="p">(</span><span class="n">collection</span><span class="p">))</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="n">ValidationError</span><span class="p">(</span><span class="s2">&quot;Outputs must be callable or None)&quot;</span><span class="p">,</span>
                                      <span class="s2">&quot;outputs&quot;</span><span class="p">)</span>

        <span class="n">new_vars_init</span> <span class="o">=</span> <span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">variables_initializer</span><span class="p">(</span><span class="n">new_vars</span><span class="p">)</span>
                         <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">new_vars</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="kc">None</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">outputs</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">output_vals</span>

        <span class="k">return</span> <span class="n">output_vals</span><span class="p">,</span> <span class="n">new_vars_init</span></div>

<div class="viewcode-block" id="TensorGraph.build_post"><a class="viewcode-back" href="../../reference.html#nengo_dl.tensor_graph.TensorGraph.build_post">[docs]</a>    <span class="nd">@with_self</span>
    <span class="k">def</span> <span class="nf">build_post</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sess</span><span class="p">,</span> <span class="n">rng</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Executes post-build processes for operators (after the graph has</span>
<span class="sd">        been constructed and session/variables initialized).</span>

<span class="sd">        Note that unlike other build functions, this is called every time</span>
<span class="sd">        the simulator is reset.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        sess : ``tf.Session``</span>
<span class="sd">            The TensorFlow session for the simulator</span>
<span class="sd">        rng : `~numpy.random.RandomState`</span>
<span class="sd">            Seeded random number generator</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c1"># build input functions (we need to do this here, because in the case</span>
        <span class="c1"># of processes these functions depend on the rng, and need to be be</span>
        <span class="c1"># rebuilt on reset)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">input_funcs</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="n">n</span><span class="p">,</span> <span class="n">output</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">invariant_inputs</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">input_funcs</span><span class="p">[</span><span class="n">n</span><span class="p">]</span> <span class="o">=</span> <span class="n">output</span>
            <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">Process</span><span class="p">):</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">input_funcs</span><span class="p">[</span><span class="n">n</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span>
                    <span class="n">output</span><span class="o">.</span><span class="n">make_step</span><span class="p">(</span>
                        <span class="p">(</span><span class="n">n</span><span class="o">.</span><span class="n">size_in</span><span class="p">,),</span> <span class="p">(</span><span class="n">n</span><span class="o">.</span><span class="n">size_out</span><span class="p">,),</span> <span class="bp">self</span><span class="o">.</span><span class="n">dt</span><span class="p">,</span>
                        <span class="n">output</span><span class="o">.</span><span class="n">get_rng</span><span class="p">(</span><span class="n">rng</span><span class="p">))</span>
                    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">minibatch_size</span><span class="p">)]</span>
            <span class="k">elif</span> <span class="n">n</span><span class="o">.</span><span class="n">size_out</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">input_funcs</span><span class="p">[</span><span class="n">n</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span>
                    <span class="n">utils</span><span class="o">.</span><span class="n">align_func</span><span class="p">((</span><span class="n">n</span><span class="o">.</span><span class="n">size_out</span><span class="p">,),</span> <span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">)(</span><span class="n">output</span><span class="p">)]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># a node with no inputs and no outputs, but it can still</span>
                <span class="c1"># have side effects</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">input_funcs</span><span class="p">[</span><span class="n">n</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">output</span><span class="p">]</span>

        <span class="c1"># execute post_build on all the op builders</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">op_builder</span><span class="o">.</span><span class="n">post_build</span><span class="p">(</span><span class="n">sess</span><span class="p">,</span> <span class="n">rng</span><span class="p">)</span></div>

<div class="viewcode-block" id="TensorGraph.build_summaries"><a class="viewcode-back" href="../../reference.html#nengo_dl.tensor_graph.TensorGraph.build_summaries">[docs]</a>    <span class="nd">@with_self</span>
    <span class="k">def</span> <span class="nf">build_summaries</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">summaries</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Adds ops to collect summary data for the given objects.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        summaries : list of dict or \</span>
<span class="sd">                            `~nengo.Connection` or \</span>
<span class="sd">                            `~nengo.Ensemble` or \</span>
<span class="sd">                            `~nengo.ensemble.Neurons` or \</span>
<span class="sd">                            ``tf.Tensor``}</span>
<span class="sd">            List of objects for which we want to collect data.  Object can be a</span>
<span class="sd">            Connection (in which case data on weights will be collected),</span>
<span class="sd">            Ensemble (encoders), Neurons (biases), a dict of</span>
<span class="sd">            ``{probe: objective}`` that indicates a loss function that will</span>
<span class="sd">            be tracked, or a pre-built summary tensor.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        op : ``tf.Tensor``</span>
<span class="sd">            Merged summary op for the given summaries</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">summary_ops</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">inits</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;/cpu:0&quot;</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">obj</span> <span class="ow">in</span> <span class="n">summaries</span><span class="p">:</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
                    <span class="c1"># overall loss</span>
                    <span class="n">loss</span><span class="p">,</span> <span class="n">init</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">build_outputs</span><span class="p">(</span><span class="n">obj</span><span class="p">)</span>
                    <span class="k">if</span> <span class="n">init</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                        <span class="n">inits</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">init</span><span class="p">)</span>
                    <span class="n">summary_ops</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">summary</span><span class="o">.</span><span class="n">scalar</span><span class="p">(</span>
                        <span class="s2">&quot;loss&quot;</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">([</span><span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>
                                               <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">loss</span><span class="o">.</span><span class="n">values</span><span class="p">()]),</span>
                        <span class="n">family</span><span class="o">=</span><span class="s2">&quot;loss&quot;</span><span class="p">))</span>

                    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">obj</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
                        <span class="c1"># get loss for each probe</span>
                        <span class="k">for</span> <span class="n">p</span><span class="p">,</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">loss</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                            <span class="n">summary_ops</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">summary</span><span class="o">.</span><span class="n">scalar</span><span class="p">(</span>
                                <span class="n">utils</span><span class="o">.</span><span class="n">sanitize_name</span><span class="p">(</span><span class="s2">&quot;Probe_</span><span class="si">%s</span><span class="s2">_loss&quot;</span> <span class="o">%</span> <span class="n">p</span><span class="o">.</span><span class="n">label</span><span class="p">),</span>
                                <span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">t</span><span class="p">),</span> <span class="n">family</span><span class="o">=</span><span class="s2">&quot;loss&quot;</span><span class="p">))</span>
                <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="p">(</span><span class="n">Ensemble</span><span class="p">,</span> <span class="n">Neurons</span><span class="p">,</span> <span class="n">Connection</span><span class="p">)):</span>
                    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="n">Ensemble</span><span class="p">):</span>
                        <span class="n">param</span> <span class="o">=</span> <span class="s2">&quot;encoders&quot;</span>
                        <span class="n">name</span> <span class="o">=</span> <span class="s2">&quot;Ensemble_</span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">obj</span><span class="o">.</span><span class="n">label</span>
                    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="n">Neurons</span><span class="p">):</span>
                        <span class="n">param</span> <span class="o">=</span> <span class="s2">&quot;bias&quot;</span>
                        <span class="n">name</span> <span class="o">=</span> <span class="s2">&quot;Ensemble.neurons_</span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">obj</span><span class="o">.</span><span class="n">ensemble</span><span class="o">.</span><span class="n">label</span>
                    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="n">Connection</span><span class="p">):</span>
                        <span class="n">param</span> <span class="o">=</span> <span class="s2">&quot;weights&quot;</span>
                        <span class="n">name</span> <span class="o">=</span> <span class="s2">&quot;Connection_</span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">obj</span><span class="o">.</span><span class="n">label</span>

                    <span class="n">summary_ops</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">summary</span><span class="o">.</span><span class="n">histogram</span><span class="p">(</span>
                        <span class="n">utils</span><span class="o">.</span><span class="n">sanitize_name</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">%s</span><span class="s2">_</span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">param</span><span class="p">)),</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">get_tensor</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">sig</span><span class="p">[</span><span class="n">obj</span><span class="p">][</span><span class="n">param</span><span class="p">])))</span>
                <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
                    <span class="c1"># we assume that obj is a summary op</span>
                    <span class="n">summary_ops</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">obj</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="n">SimulationError</span><span class="p">(</span>
                        <span class="s2">&quot;Unknown summary object: </span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">obj</span><span class="p">)</span>

            <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">summary</span><span class="o">.</span><span class="n">merge</span><span class="p">(</span><span class="n">summary_ops</span><span class="p">),</span> <span class="p">(</span><span class="kc">None</span> <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">inits</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span> <span class="k">else</span>
                                                   <span class="n">inits</span><span class="p">)</span></div>

<div class="viewcode-block" id="TensorGraph.get_tensor"><a class="viewcode-back" href="../../reference.html#nengo_dl.tensor_graph.TensorGraph.get_tensor">[docs]</a>    <span class="nd">@with_self</span>
    <span class="k">def</span> <span class="nf">get_tensor</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sig</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Returns a Tensor corresponding to the given Signal.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        sig : `~nengo.builder.Signal`</span>
<span class="sd">            A signal in the model</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        tensor : ``tf.Tensor``</span>
<span class="sd">            Tensor containing the value of the given Signal</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">tensor_sig</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">signals</span><span class="p">[</span><span class="n">sig</span><span class="p">]</span>

        <span class="n">base</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">base_vars</span><span class="p">[</span><span class="n">tensor_sig</span><span class="o">.</span><span class="n">key</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>

        <span class="k">if</span> <span class="s2">&quot;while/&quot;</span> <span class="ow">in</span> <span class="n">tensor_sig</span><span class="o">.</span><span class="n">tf_indices</span><span class="o">.</span><span class="n">name</span><span class="p">:</span>
            <span class="c1"># rebuild tf indices outside the while loop</span>
            <span class="n">tensor_sig</span><span class="o">.</span><span class="n">_tf_indices</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">gather</span><span class="p">(</span><span class="n">base</span><span class="p">,</span> <span class="n">tensor_sig</span><span class="o">.</span><span class="n">tf_indices</span><span class="p">)</span></div>

<div class="viewcode-block" id="TensorGraph.mark_signals"><a class="viewcode-back" href="../../reference.html#nengo_dl.tensor_graph.TensorGraph.mark_signals">[docs]</a>    <span class="k">def</span> <span class="nf">mark_signals</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Mark all the signals in ``self.model`` according to whether they</span>
<span class="sd">        represent trainable parameters of the model (parameters that can be</span>
<span class="sd">        optimized by deep learning methods).</span>

<span class="sd">        Trainable parameters include connection weights, ensemble encoders, and</span>
<span class="sd">        neuron biases.  Unless one of those signals is targeted by a Nengo</span>
<span class="sd">        learning rule (otherwise the learning rule update conflicts with the</span>
<span class="sd">        deep learning optimization).</span>

<span class="sd">        Users can manually specify whether signals are trainable or not using</span>
<span class="sd">        the config system (e.g.,</span>
<span class="sd">        ``net.config[nengo.Ensemble].trainable = False``)</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">def</span> <span class="nf">get_trainable</span><span class="p">(</span><span class="n">net_config</span><span class="p">,</span> <span class="n">obj</span><span class="p">,</span> <span class="n">network_trainable</span><span class="p">):</span>
            <span class="sd">&quot;&quot;&quot;Looks up the current value of ``obj.trainable``.&quot;&quot;&quot;</span>

            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">inference_only</span><span class="p">:</span>
                <span class="k">return</span> <span class="kc">False</span>

            <span class="k">try</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">obj</span> <span class="ow">in</span> <span class="n">net_config</span><span class="o">.</span><span class="n">params</span><span class="p">:</span>
                    <span class="c1"># priority #1: instance config</span>
                    <span class="n">trainable</span> <span class="o">=</span> <span class="n">net_config</span><span class="p">[</span><span class="n">obj</span><span class="p">]</span><span class="o">.</span><span class="n">trainable</span>
                <span class="k">elif</span> <span class="n">network_trainable</span> <span class="ow">is</span> <span class="ow">not</span> <span class="mi">1</span><span class="p">:</span>
                    <span class="c1"># priority #2: network setting</span>
                    <span class="n">trainable</span> <span class="o">=</span> <span class="n">network_trainable</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="c1"># priority #3: class config</span>
                    <span class="n">trainable</span> <span class="o">=</span> <span class="n">net_config</span><span class="p">[</span><span class="n">obj</span><span class="p">]</span><span class="o">.</span><span class="n">trainable</span>
            <span class="k">except</span> <span class="p">(</span><span class="n">ConfigError</span><span class="p">,</span> <span class="ne">AttributeError</span><span class="p">):</span>
                <span class="n">trainable</span> <span class="o">=</span> <span class="n">network_trainable</span>

            <span class="c1"># we return 1 if trainable isn&#39;t configured, since the default is</span>
            <span class="c1"># for everything to be trainable but we want to be able to</span>
            <span class="c1"># distinguish whether something was specifically set to be</span>
            <span class="c1"># trainable (True) or just defaulting to trainable (1)</span>
            <span class="k">return</span> <span class="mi">1</span> <span class="k">if</span> <span class="n">trainable</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">trainable</span>

        <span class="k">def</span> <span class="nf">mark_network</span><span class="p">(</span><span class="n">net_config</span><span class="p">,</span> <span class="n">net</span><span class="p">,</span> <span class="n">network_trainable</span><span class="p">):</span>
            <span class="sd">&quot;&quot;&quot;Recursively marks the signals for objects within each</span>
<span class="sd">            subnetwork.&quot;&quot;&quot;</span>

            <span class="k">for</span> <span class="n">subnet</span> <span class="ow">in</span> <span class="n">net</span><span class="o">.</span><span class="n">networks</span><span class="p">:</span>
                <span class="n">mark_network</span><span class="p">(</span><span class="n">net_config</span><span class="p">,</span> <span class="n">subnet</span><span class="p">,</span>
                             <span class="n">get_trainable</span><span class="p">(</span><span class="n">net_config</span><span class="p">,</span> <span class="n">subnet</span><span class="p">,</span>
                                           <span class="n">network_trainable</span><span class="p">))</span>

            <span class="c1"># encoders and biases are trainable</span>
            <span class="k">for</span> <span class="n">ens</span> <span class="ow">in</span> <span class="n">net</span><span class="o">.</span><span class="n">ensembles</span><span class="p">:</span>
                <span class="n">ens_trainable</span> <span class="o">=</span> <span class="n">get_trainable</span><span class="p">(</span><span class="n">net_config</span><span class="p">,</span> <span class="n">ens</span><span class="p">,</span>
                                              <span class="n">network_trainable</span><span class="p">)</span>

                <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">sig</span><span class="p">[</span><span class="n">ens</span><span class="p">][</span><span class="s2">&quot;encoders&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">trainable</span> <span class="o">=</span> <span class="n">ens_trainable</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">sig</span><span class="p">[</span><span class="n">ens</span><span class="p">][</span><span class="s2">&quot;encoders&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">minibatched</span> <span class="o">=</span> <span class="kc">False</span>

                <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">ens</span><span class="o">.</span><span class="n">neuron_type</span><span class="p">,</span> <span class="n">Direct</span><span class="p">):</span>
                    <span class="n">neurons_trainable</span> <span class="o">=</span> <span class="n">get_trainable</span><span class="p">(</span><span class="n">net_config</span><span class="p">,</span> <span class="n">ens</span><span class="o">.</span><span class="n">neurons</span><span class="p">,</span>
                                                      <span class="n">network_trainable</span><span class="p">)</span>
                    <span class="k">if</span> <span class="n">neurons_trainable</span> <span class="ow">is</span> <span class="mi">1</span><span class="p">:</span>
                        <span class="n">neurons_trainable</span> <span class="o">=</span> <span class="n">ens_trainable</span>

                    <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">sig</span><span class="p">[</span><span class="n">ens</span><span class="o">.</span><span class="n">neurons</span><span class="p">][</span><span class="s2">&quot;bias&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">trainable</span> <span class="o">=</span> <span class="p">(</span>
                        <span class="n">neurons_trainable</span><span class="p">)</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">sig</span><span class="p">[</span><span class="n">ens</span><span class="o">.</span><span class="n">neurons</span><span class="p">][</span><span class="s2">&quot;bias&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">minibatched</span> <span class="o">=</span> <span class="kc">False</span>

            <span class="c1"># connection weights are trainable</span>
            <span class="k">for</span> <span class="n">conn</span> <span class="ow">in</span> <span class="n">net</span><span class="o">.</span><span class="n">connections</span><span class="p">:</span>
                <span class="c1"># note: this doesn&#39;t include probe connections, since they</span>
                <span class="c1"># aren&#39;t added to the network</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">sig</span><span class="p">[</span><span class="n">conn</span><span class="p">][</span><span class="s2">&quot;weights&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">trainable</span> <span class="o">=</span> <span class="n">get_trainable</span><span class="p">(</span>
                    <span class="n">net_config</span><span class="p">,</span> <span class="n">conn</span><span class="p">,</span> <span class="n">network_trainable</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">sig</span><span class="p">[</span><span class="n">conn</span><span class="p">][</span><span class="s2">&quot;weights&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">minibatched</span> <span class="o">=</span> <span class="kc">False</span>

            <span class="c1"># parameters can&#39;t be modified by an online Nengo learning rule</span>
            <span class="c1"># and offline training at the same time. (it is possible in</span>
            <span class="c1"># theory, but it complicates things a lot and is probably not a</span>
            <span class="c1"># common use case). we also make those signals minibatched</span>
            <span class="c1"># (they wouldn&#39;t be normally), because we want to be able to</span>
            <span class="c1"># learn independently in each minibatch</span>
            <span class="k">for</span> <span class="n">conn</span> <span class="ow">in</span> <span class="n">net</span><span class="o">.</span><span class="n">connections</span><span class="p">:</span>
                <span class="n">rule</span> <span class="o">=</span> <span class="n">conn</span><span class="o">.</span><span class="n">learning_rule</span>
                <span class="k">if</span> <span class="n">rule</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">rule</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
                        <span class="n">rule</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">rule</span><span class="o">.</span><span class="n">values</span><span class="p">())</span>
                    <span class="k">elif</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">rule</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
                        <span class="n">rule</span> <span class="o">=</span> <span class="p">[</span><span class="n">rule</span><span class="p">]</span>

                    <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="n">rule</span><span class="p">:</span>
                        <span class="k">if</span> <span class="n">r</span><span class="o">.</span><span class="n">modifies</span> <span class="ow">in</span> <span class="p">(</span><span class="s2">&quot;weights&quot;</span><span class="p">,</span> <span class="s2">&quot;decoders&quot;</span><span class="p">):</span>
                            <span class="n">obj</span> <span class="o">=</span> <span class="n">conn</span>
                            <span class="n">attr</span> <span class="o">=</span> <span class="s2">&quot;weights&quot;</span>
                        <span class="k">elif</span> <span class="n">r</span><span class="o">.</span><span class="n">modifies</span> <span class="o">==</span> <span class="s2">&quot;encoders&quot;</span><span class="p">:</span>
                            <span class="n">obj</span> <span class="o">=</span> <span class="n">conn</span><span class="o">.</span><span class="n">post_obj</span>
                            <span class="n">attr</span> <span class="o">=</span> <span class="s2">&quot;encoders&quot;</span>
                        <span class="k">else</span><span class="p">:</span>
                            <span class="k">raise</span> <span class="ne">NotImplementedError</span>

                        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">sig</span><span class="p">[</span><span class="n">obj</span><span class="p">][</span><span class="n">attr</span><span class="p">]</span><span class="o">.</span><span class="n">trainable</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
                            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                                <span class="s2">&quot;</span><span class="si">%s</span><span class="s2"> has a learning rule and is also set &quot;</span>
                                <span class="s2">&quot;to be trainable; this is likely to &quot;</span>
                                <span class="s2">&quot;produce strange training behaviour.&quot;</span> <span class="o">%</span>
                                <span class="n">obj</span><span class="p">)</span>
                        <span class="k">else</span><span class="p">:</span>
                            <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">sig</span><span class="p">[</span><span class="n">obj</span><span class="p">][</span><span class="n">attr</span><span class="p">]</span><span class="o">.</span><span class="n">trainable</span> <span class="o">=</span> <span class="kc">False</span>

                        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">sig</span><span class="p">[</span><span class="n">obj</span><span class="p">][</span><span class="n">attr</span><span class="p">]</span><span class="o">.</span><span class="n">minibatched</span> <span class="o">=</span> <span class="kc">True</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">toplevel</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                <span class="s2">&quot;No top-level network in model; assuming no trainable &quot;</span>
                <span class="s2">&quot;parameters&quot;</span><span class="p">,</span> <span class="ne">UserWarning</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">net_config</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">toplevel</span><span class="o">.</span><span class="n">config</span>
            <span class="n">mark_network</span><span class="p">(</span><span class="n">net_config</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">toplevel</span><span class="p">,</span>
                         <span class="n">get_trainable</span><span class="p">(</span><span class="n">net_config</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">toplevel</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>

            <span class="c1"># the connections to connection probes are not trainable, but</span>
            <span class="c1"># also not minibatched</span>
            <span class="n">probe_seeds</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">seeds</span><span class="p">[</span><span class="n">p</span><span class="p">]</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">probes</span><span class="p">]</span>
            <span class="k">for</span> <span class="n">obj</span><span class="p">,</span> <span class="n">seed</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">seeds</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="n">Connection</span><span class="p">)</span> <span class="ow">and</span> <span class="n">seed</span> <span class="ow">in</span> <span class="n">probe_seeds</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">sig</span><span class="p">[</span><span class="n">obj</span><span class="p">][</span><span class="s2">&quot;weights&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">trainable</span> <span class="o">=</span> <span class="kc">False</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">sig</span><span class="p">[</span><span class="n">obj</span><span class="p">][</span><span class="s2">&quot;weights&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">minibatched</span> <span class="o">=</span> <span class="kc">False</span>

        <span class="c1"># fill in defaults for all other signals</span>
        <span class="c1"># signals are not trainable by default, and views take on the</span>
        <span class="c1"># properties of their bases</span>
        <span class="k">for</span> <span class="n">op</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">operators</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">sig</span> <span class="ow">in</span> <span class="n">op</span><span class="o">.</span><span class="n">all_signals</span><span class="p">:</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">sig</span><span class="o">.</span><span class="n">base</span><span class="p">,</span> <span class="s2">&quot;trainable&quot;</span><span class="p">):</span>
                    <span class="n">sig</span><span class="o">.</span><span class="n">base</span><span class="o">.</span><span class="n">trainable</span> <span class="o">=</span> <span class="kc">False</span>

                <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">sig</span><span class="o">.</span><span class="n">base</span><span class="p">,</span> <span class="s2">&quot;minibatched&quot;</span><span class="p">):</span>
                    <span class="n">sig</span><span class="o">.</span><span class="n">base</span><span class="o">.</span><span class="n">minibatched</span> <span class="o">=</span> <span class="ow">not</span> <span class="n">sig</span><span class="o">.</span><span class="n">base</span><span class="o">.</span><span class="n">trainable</span>

                <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">sig</span><span class="p">,</span> <span class="s2">&quot;trainable&quot;</span><span class="p">):</span>
                    <span class="n">sig</span><span class="o">.</span><span class="n">trainable</span> <span class="o">=</span> <span class="n">sig</span><span class="o">.</span><span class="n">base</span><span class="o">.</span><span class="n">trainable</span>

                <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">sig</span><span class="p">,</span> <span class="s2">&quot;minibatched&quot;</span><span class="p">):</span>
                    <span class="n">sig</span><span class="o">.</span><span class="n">minibatched</span> <span class="o">=</span> <span class="n">sig</span><span class="o">.</span><span class="n">base</span><span class="o">.</span><span class="n">minibatched</span></div>

<div class="viewcode-block" id="TensorGraph.create_signals"><a class="viewcode-back" href="../../reference.html#nengo_dl.tensor_graph.TensorGraph.create_signals">[docs]</a>    <span class="k">def</span> <span class="nf">create_signals</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sigs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Groups signal data together into larger arrays, and represent each</span>
<span class="sd">        individual signal as a slice into that array.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        sigs : list of `~nengo.builder.Signal`</span>
<span class="sd">            Base signals arranged into the order in which they should reside in</span>
<span class="sd">            memory (e.g., output from `.graph_optimizer.order_signals`)</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">float_type</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="o">.</span><span class="n">as_numpy_dtype</span>
        <span class="n">base_arrays</span> <span class="o">=</span> <span class="n">OrderedDict</span><span class="p">()</span>
        <span class="n">curr_keys</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="n">sig_idxs</span> <span class="o">=</span> <span class="p">{</span><span class="n">s</span><span class="p">:</span> <span class="n">i</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">s</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">sigs</span><span class="p">)}</span>

        <span class="c1"># find the non-overlapping partitions of the signals</span>
        <span class="n">breaks</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">diff</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">ops</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">plan</span><span class="p">:</span>
            <span class="c1"># note: we don&#39;t include Resets, otherwise the big reset block</span>
            <span class="c1"># overrides most of the partitioning</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">ops</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">Reset</span><span class="p">):</span>
                <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">ops</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">all_signals</span><span class="p">)):</span>
                    <span class="n">op_sigs</span> <span class="o">=</span> <span class="p">[</span><span class="n">op</span><span class="o">.</span><span class="n">all_signals</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">base</span> <span class="k">for</span> <span class="n">op</span> <span class="ow">in</span> <span class="n">ops</span><span class="p">]</span>
                    <span class="n">idxs</span> <span class="o">=</span> <span class="p">[</span><span class="n">sig_idxs</span><span class="p">[</span><span class="n">s</span><span class="p">]</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">op_sigs</span><span class="p">]</span>
                    <span class="n">diff</span><span class="p">[</span><span class="n">op_sigs</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">argmin</span><span class="p">(</span><span class="n">idxs</span><span class="p">)]]</span> <span class="o">+=</span> <span class="mi">1</span>
                    <span class="n">diff</span><span class="p">[</span><span class="n">op_sigs</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">idxs</span><span class="p">)]]</span> <span class="o">-=</span> <span class="mi">1</span>

        <span class="c1"># find the partition points in signal list</span>
        <span class="nb">open</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">s</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">sigs</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">diff</span><span class="p">:</span>
                <span class="nb">open</span> <span class="o">+=</span> <span class="n">diff</span><span class="p">[</span><span class="n">s</span><span class="p">]</span>

            <span class="k">if</span> <span class="nb">open</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">breaks</span> <span class="o">+=</span> <span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span>

        <span class="n">logging</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot;partitions&quot;</span><span class="p">)</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="si">%s</span><span class="s2">&quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="s2">&quot;|&quot;</span> <span class="k">if</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">breaks</span> <span class="k">else</span> <span class="s2">&quot; &quot;</span>
                                      <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">sigs</span><span class="p">))))</span>

        <span class="c1"># create all the base signals</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">sig</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">sigs</span><span class="p">):</span>
            <span class="k">assert</span> <span class="n">sig</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">signals</span>
            <span class="k">assert</span> <span class="ow">not</span> <span class="n">sig</span><span class="o">.</span><span class="n">is_view</span>

            <span class="k">if</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">breaks</span><span class="p">:</span>
                <span class="c1"># start a new array for all current bases</span>
                <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">curr_keys</span><span class="p">:</span>
                    <span class="n">curr_keys</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="nb">object</span><span class="p">()</span>

            <span class="c1"># convert to appropriate dtype</span>
            <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">issubdtype</span><span class="p">(</span><span class="n">sig</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">floating</span><span class="p">):</span>
                <span class="n">dtype</span> <span class="o">=</span> <span class="n">float_type</span>
            <span class="k">elif</span> <span class="n">np</span><span class="o">.</span><span class="n">issubdtype</span><span class="p">(</span><span class="n">sig</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">integer</span><span class="p">):</span>
                <span class="n">dtype</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">int32</span>
            <span class="k">elif</span> <span class="n">np</span><span class="o">.</span><span class="n">issubdtype</span><span class="p">(</span><span class="n">sig</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">bool_</span><span class="p">):</span>
                <span class="n">dtype</span> <span class="o">=</span> <span class="n">sig</span><span class="o">.</span><span class="n">dtype</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">&quot;Unsupported signal dtype&quot;</span><span class="p">)</span>

            <span class="c1"># resize scalars to length 1 vectors</span>
            <span class="n">shape</span> <span class="o">=</span> <span class="n">sig</span><span class="o">.</span><span class="n">shape</span> <span class="k">if</span> <span class="n">sig</span><span class="o">.</span><span class="n">shape</span> <span class="o">!=</span> <span class="p">()</span> <span class="k">else</span> <span class="p">(</span><span class="mi">1</span><span class="p">,)</span>

            <span class="c1"># parameters of signal that affect the base array</span>
            <span class="n">array_params</span> <span class="o">=</span> <span class="p">(</span><span class="n">dtype</span><span class="p">,</span> <span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:],</span> <span class="n">sig</span><span class="o">.</span><span class="n">trainable</span><span class="p">,</span> <span class="n">sig</span><span class="o">.</span><span class="n">minibatched</span><span class="p">)</span>

            <span class="c1"># key used to map signals to base arrays</span>
            <span class="k">if</span> <span class="n">array_params</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">curr_keys</span><span class="p">:</span>
                <span class="n">curr_keys</span><span class="p">[</span><span class="n">array_params</span><span class="p">]</span> <span class="o">=</span> <span class="nb">object</span><span class="p">()</span>
            <span class="n">key</span> <span class="o">=</span> <span class="n">curr_keys</span><span class="p">[</span><span class="n">array_params</span><span class="p">]</span>

            <span class="n">initial_value</span> <span class="o">=</span> <span class="n">sig</span><span class="o">.</span><span class="n">initial_value</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">dtype</span><span class="p">,</span> <span class="n">copy</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

            <span class="c1"># broadcast scalars up to full size</span>
            <span class="k">if</span> <span class="n">initial_value</span><span class="o">.</span><span class="n">shape</span> <span class="o">!=</span> <span class="n">shape</span><span class="p">:</span>
                <span class="n">initial_value</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">resize</span><span class="p">(</span><span class="n">initial_value</span><span class="p">,</span> <span class="n">shape</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">sig</span><span class="o">.</span><span class="n">minibatched</span><span class="p">:</span>
                <span class="c1"># duplicate along minibatch dimension</span>
                <span class="n">initial_value</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">tile</span><span class="p">(</span>
                    <span class="n">initial_value</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="kc">None</span><span class="p">],</span>
                    <span class="nb">tuple</span><span class="p">(</span><span class="mi">1</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">shape</span><span class="p">)</span> <span class="o">+</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">minibatch_size</span><span class="p">,))</span>

            <span class="k">if</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">base_arrays</span><span class="p">:</span>
                <span class="n">base_arrays</span><span class="p">[</span><span class="n">key</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">initial_value</span><span class="p">)</span>
                <span class="n">base_arrays</span><span class="p">[</span><span class="n">key</span><span class="p">][</span><span class="mi">2</span><span class="p">]</span> <span class="o">+=</span> <span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">base_arrays</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="p">[[</span><span class="n">initial_value</span><span class="p">],</span> <span class="n">sig</span><span class="o">.</span><span class="n">trainable</span><span class="p">,</span> <span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span>

            <span class="n">n</span> <span class="o">=</span> <span class="n">base_arrays</span><span class="p">[</span><span class="n">key</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
            <span class="n">indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">n</span> <span class="o">-</span> <span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">n</span><span class="p">)</span>

            <span class="n">tensor_sig</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">signals</span><span class="o">.</span><span class="n">get_tensor_signal</span><span class="p">(</span>
                <span class="n">indices</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">shape</span><span class="p">,</span> <span class="n">sig</span><span class="o">.</span><span class="n">minibatched</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="n">sig</span><span class="o">.</span><span class="n">name</span><span class="p">,</span>
                <span class="n">signal</span><span class="o">=</span><span class="n">sig</span><span class="p">)</span>

            <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot;created base signal&quot;</span><span class="p">)</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="n">sig</span><span class="p">)</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="n">tensor_sig</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">base_arrays</span><span class="p">:</span>
            <span class="n">arrs</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">base_arrays</span><span class="p">[</span><span class="n">key</span><span class="p">]</span>
            <span class="n">base_arrays</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">arrs</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span> <span class="n">t</span><span class="p">)</span>

        <span class="c1"># add any signal views to the sig_map</span>
        <span class="n">all_views</span> <span class="o">=</span> <span class="p">[</span><span class="n">sig</span> <span class="k">for</span> <span class="n">ops</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">plan</span> <span class="k">for</span> <span class="n">op</span> <span class="ow">in</span> <span class="n">ops</span> <span class="k">for</span> <span class="n">sig</span> <span class="ow">in</span>
                     <span class="n">op</span><span class="o">.</span><span class="n">all_signals</span> <span class="k">if</span> <span class="n">sig</span><span class="o">.</span><span class="n">is_view</span><span class="p">]</span>
        <span class="k">for</span> <span class="n">sig</span> <span class="ow">in</span> <span class="n">all_views</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">sig</span><span class="o">.</span><span class="n">size</span> <span class="o">==</span> <span class="n">sig</span><span class="o">.</span><span class="n">base</span><span class="o">.</span><span class="n">size</span><span class="p">:</span>
                <span class="c1"># reshape view</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">signals</span><span class="p">[</span><span class="n">sig</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">signals</span><span class="p">[</span><span class="n">sig</span><span class="o">.</span><span class="n">base</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">sig</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">sig</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span> <span class="o">!=</span> <span class="n">sig</span><span class="o">.</span><span class="n">base</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:]:</span>
                    <span class="c1"># TODO: support this?</span>
                    <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span>
                        <span class="s2">&quot;Slicing on axes &gt; 0 is not supported&quot;</span><span class="p">)</span>

                <span class="c1"># slice view</span>
                <span class="k">assert</span> <span class="n">np</span><span class="o">.</span><span class="n">all</span><span class="p">([</span><span class="n">x</span> <span class="o">==</span> <span class="mi">1</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">sig</span><span class="o">.</span><span class="n">elemstrides</span><span class="p">[</span><span class="mi">1</span><span class="p">:]])</span>

                <span class="n">start</span> <span class="o">=</span> <span class="n">sig</span><span class="o">.</span><span class="n">elemoffset</span>
                <span class="n">stride</span> <span class="o">=</span> <span class="n">sig</span><span class="o">.</span><span class="n">elemstrides</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
                <span class="n">stop</span> <span class="o">=</span> <span class="n">start</span> <span class="o">+</span> <span class="n">sig</span><span class="o">.</span><span class="n">size</span> <span class="o">*</span> <span class="n">stride</span>
                <span class="k">if</span> <span class="n">stop</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="n">stop</span> <span class="o">=</span> <span class="kc">None</span>

                <span class="bp">self</span><span class="o">.</span><span class="n">signals</span><span class="p">[</span><span class="n">sig</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">signals</span><span class="p">[</span><span class="n">sig</span><span class="o">.</span><span class="n">base</span><span class="p">][</span><span class="nb">slice</span><span class="p">(</span><span class="n">start</span><span class="p">,</span> <span class="n">stop</span><span class="p">,</span>
                                                                 <span class="n">stride</span><span class="p">)]</span>

        <span class="c1"># error checking</span>
        <span class="k">for</span> <span class="n">sig</span><span class="p">,</span> <span class="n">tensor_sig</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">signals</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="c1"># tensorsignal shapes should match signal shapes</span>
            <span class="k">assert</span> <span class="n">tensor_sig</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="n">sig</span><span class="o">.</span><span class="n">shape</span> <span class="k">if</span> <span class="n">sig</span><span class="o">.</span><span class="n">shape</span> <span class="o">!=</span> <span class="p">()</span> <span class="k">else</span> <span class="p">(</span><span class="mi">1</span><span class="p">,))</span>

            <span class="c1"># tensorsignal values should match signal values</span>
            <span class="n">initial_value</span> <span class="o">=</span> <span class="n">sig</span><span class="o">.</span><span class="n">initial_value</span>
            <span class="k">if</span> <span class="n">sig</span><span class="o">.</span><span class="n">minibatched</span><span class="p">:</span>
                <span class="n">initial_value</span> <span class="o">=</span> <span class="n">initial_value</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="kc">None</span><span class="p">]</span>

            <span class="k">assert</span> <span class="n">np</span><span class="o">.</span><span class="n">allclose</span><span class="p">(</span>
                <span class="n">base_arrays</span><span class="p">[</span><span class="n">tensor_sig</span><span class="o">.</span><span class="n">key</span><span class="p">][</span><span class="mi">0</span><span class="p">][</span><span class="n">tensor_sig</span><span class="o">.</span><span class="n">indices</span><span class="p">],</span>
                <span class="n">initial_value</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">dtype</span><span class="p">))</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot;base arrays&quot;</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="nb">str</span><span class="p">((</span><span class="n">k</span><span class="p">,</span> <span class="n">v</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">v</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">trainable</span><span class="p">))</span>
                                <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">trainable</span><span class="p">)</span> <span class="ow">in</span> <span class="n">base_arrays</span><span class="o">.</span><span class="n">items</span><span class="p">()]))</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">base_arrays_init</span> <span class="o">=</span> <span class="n">base_arrays</span></div></div>
</pre></div>

        </div>
      </div>
    </div>
  </div>
</div><footer class="footer">
  <div class="w-container">
    <div class="w-clearfix">
      <div class="w-row mobileAlign">
        <div class="w-col w-col-2 footer-menu">
          <p class="menu-Label">ABR, Inc.</p>
          <ul class="vertical-menu">
            <li class="footer-listitem-new"><a href="https://appliedbrainresearch.com/products/">Products</a></li>
            <li class="footer-listitem-new "><a href="https://appliedbrainresearch.com/services/">Services</a></li>
            <li class="footer-listitem-new"><a href="https://appliedbrainresearch.com/research/">Research</a></li>
          </ul>
        </div>
        <div class="w-col w-col-2 footer-menu">
          <p class="menu-Label">About Us</p>
          <ul class="vertical-menu">
            <li class="footer-listitem-new"><a href="https://appliedbrainresearch.com/about-us/">Contact</a></li>
            <li class="footer-listitem-new"><a href="https://appliedbrainresearch.com/about-us/#team">Team</a></li>
            <li class="footer-listitem-new"><a href="https://appliedbrainresearch.com/about-us/#culture">Culture</a></li>
          </ul>
        </div>
        <a class="brand footer-brand" href="https://appliedbrainresearch.com">
          <img src="https://appliedbrainresearch.com/img/logo-light-notext.svg" width="80">
        </a>
      </div>
    </div>
  </div>
</footer>
  </body>
</html>