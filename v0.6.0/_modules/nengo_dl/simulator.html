

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>nengo_dl.simulator &mdash; NengoDL documentation</title>
  

  
  
    <link rel="shortcut icon" href="../../_static/favicon.ico"/>
  
  
  

  

  
  
    

  

  
    <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../_static\custom.css" type="text/css" />
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" /> 

  

<!-- Google Tag Manager -->
<script>
 (function (w, d, s, l, i) {
   w[l] = w[l] || [];
   w[l].push({ "gtm.start": new Date().getTime(), event: "gtm.js" });
   var f = d.getElementsByTagName(s)[0],
       j = d.createElement(s),
       dl = l != "dataLayer" ? "&l=" + l : "";
   j.async = true;
   j.src = "https://www.googletagmanager.com/gtm.js?id=" + i + dl;
   f.parentNode.insertBefore(j, f);
 })(window, document, "script", "dataLayer", "GTM-KWCR2HN");
</script>
<!-- End Google Tag Manager -->
  <script src="../../_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="../../index.html" class="icon icon-home"> NengoDL
          

          
            
            <img src="../../_static/logo.png" class="logo" alt="Logo"/>
          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul>
<li class="toctree-l1"><a class="reference internal" href="../../introduction.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../frontend.html">User documentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../examples.html">Examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../resources.html">Additional resources</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../backend.html">Developer documentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../project.html">Project information</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">NengoDL</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../index.html">Docs</a> &raquo;</li>
        
          <li><a href="../index.html">Module code</a> &raquo;</li>
        
      <li>nengo_dl.simulator</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <h1>Source code for nengo_dl.simulator</h1><div class="highlight"><pre>
<span></span><span class="kn">from</span> <span class="nn">__future__</span> <span class="k">import</span> <span class="n">print_function</span><span class="p">,</span> <span class="n">division</span>

<span class="kn">import</span> <span class="nn">collections</span>
<span class="kn">import</span> <span class="nn">datetime</span>
<span class="kn">import</span> <span class="nn">logging</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">sys</span>
<span class="kn">import</span> <span class="nn">tempfile</span>
<span class="kn">import</span> <span class="nn">time</span>
<span class="kn">import</span> <span class="nn">warnings</span>

<span class="kn">from</span> <span class="nn">nengo</span> <span class="k">import</span> <span class="n">Process</span><span class="p">,</span> <span class="n">Ensemble</span><span class="p">,</span> <span class="n">Connection</span><span class="p">,</span> <span class="n">Probe</span>
<span class="kn">from</span> <span class="nn">nengo.builder</span> <span class="k">import</span> <span class="n">Model</span>
<span class="kn">from</span> <span class="nn">nengo.builder.connection</span> <span class="k">import</span> <span class="n">BuiltConnection</span>
<span class="kn">from</span> <span class="nn">nengo.builder.ensemble</span> <span class="k">import</span> <span class="n">BuiltEnsemble</span>
<span class="kn">from</span> <span class="nn">nengo.exceptions</span> <span class="k">import</span> <span class="p">(</span>
    <span class="n">ReadonlyError</span><span class="p">,</span> <span class="n">SimulatorClosed</span><span class="p">,</span> <span class="n">NengoWarning</span><span class="p">,</span> <span class="n">SimulationError</span><span class="p">,</span>
    <span class="n">ValidationError</span><span class="p">)</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.ops</span> <span class="k">import</span> <span class="n">gradient_checker</span>

<span class="kn">from</span> <span class="nn">nengo_dl</span> <span class="k">import</span> <span class="n">utils</span><span class="p">,</span> <span class="n">DATA_DIR</span>
<span class="kn">from</span> <span class="nn">nengo_dl.tensor_graph</span> <span class="k">import</span> <span class="n">TensorGraph</span>

<span class="n">logger</span> <span class="o">=</span> <span class="n">logging</span><span class="o">.</span><span class="n">getLogger</span><span class="p">(</span><span class="vm">__name__</span><span class="p">)</span>

<span class="k">if</span> <span class="n">sys</span><span class="o">.</span><span class="n">version_info</span> <span class="o">&lt;</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">):</span>
    <span class="kn">import</span> <span class="nn">backports.tempfile</span> <span class="k">as</span> <span class="nn">tempfile</span>  <span class="c1"># noqa: F811</span>


<div class="viewcode-block" id="Simulator"><a class="viewcode-back" href="../../simulator.html#nengo_dl.simulator.Simulator">[docs]</a><span class="k">class</span> <span class="nc">Simulator</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Simulate network using the ``nengo_dl`` backend.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    network : :class:`~nengo:nengo.Network` or None</span>
<span class="sd">        A network object to be built and then simulated. If None,</span>
<span class="sd">        then a built model must be passed to ``model`` instead</span>
<span class="sd">    dt : float, optional</span>
<span class="sd">        Length of a simulator timestep, in seconds</span>
<span class="sd">    seed : int, optional</span>
<span class="sd">        Seed for all stochastic operators used in this simulator</span>
<span class="sd">    model : :class:`~nengo:nengo.builder.Model`, optional</span>
<span class="sd">        Pre-built model object</span>
<span class="sd">    dtype : ``tf.DType``, optional</span>
<span class="sd">        Floating point precision to use for simulation</span>
<span class="sd">    device : None or ``&quot;/cpu:0&quot;`` or ``&quot;/gpu:[0-n]&quot;``, optional</span>
<span class="sd">        Device on which to execute computations (if None then uses the</span>
<span class="sd">        default device as determined by TensorFlow)</span>
<span class="sd">    unroll_simulation : int, optional</span>
<span class="sd">        Unroll simulation loop by explicitly building the given number of</span>
<span class="sd">        iterations into the computation graph (improves simulation speed</span>
<span class="sd">        but increases build time)</span>
<span class="sd">    minibatch_size : int, optional</span>
<span class="sd">        The number of simultaneous inputs that will be passed through the</span>
<span class="sd">        network</span>
<span class="sd">    tensorboard : str, optional</span>
<span class="sd">        If not None, save network output in the TensorFlow summary format to</span>
<span class="sd">        the given directory, which can be loaded into TensorBoard</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="c1"># unsupported unit tests</span>
    <span class="n">unsupported</span> <span class="o">=</span> <span class="p">[</span>
        <span class="p">(</span><span class="s2">&quot;nengo/tests/test_simulator.py:test_warn_on_opensim_del&quot;</span><span class="p">,</span>
         <span class="s2">&quot;nengo_dl raises a different (more visible) warning (see &quot;</span>
         <span class="s2">&quot;tests/test_nengo_tests.py:test_warn_on_opensim_del&quot;</span><span class="p">),</span>

        <span class="p">(</span><span class="s2">&quot;nengo/tests/test_simulator.py:test_signal_init_values&quot;</span><span class="p">,</span>
         <span class="s2">&quot;different method required to manually step simulator (see &quot;</span>
         <span class="s2">&quot;tests/test_nengo_tests.py:test_signal_init_values&quot;</span><span class="p">),</span>

        <span class="p">(</span><span class="s2">&quot;nengo/tests/test_simulator.py:test_entry_point&quot;</span><span class="p">,</span>
         <span class="s2">&quot;overridden so we can pass custom test simulators (see &quot;</span>
         <span class="s2">&quot;tests/test_nengo_tests.py:test_entry_point&quot;</span><span class="p">),</span>

        <span class="p">(</span><span class="s2">&quot;nengo/tests/test_node.py:test_args&quot;</span><span class="p">,</span>
         <span class="s2">&quot;time is passed as np.float32, not a float (see &quot;</span>
         <span class="s2">&quot;tests/test_nengo_tests.py:test_args&quot;</span><span class="p">),</span>

        <span class="p">(</span><span class="s2">&quot;nengo/tests/test_node.py:test_unconnected_node&quot;</span><span class="p">,</span>
         <span class="s2">&quot;need to set `unroll_simulation` to ensure node runs the correct &quot;</span>
         <span class="s2">&quot;number of times (see &quot;</span>
         <span class="s2">&quot;tests/test_nengo_tests.py:test_unconnected_node&quot;</span><span class="p">),</span>

        <span class="p">(</span><span class="s2">&quot;nengo/tests/test_synapses.py:test_alpha&quot;</span><span class="p">,</span>
         <span class="s2">&quot;need to set looser tolerances due to float32 implementation (see &quot;</span>
         <span class="s2">&quot;tests/test_processes.py:test_alpha&quot;</span><span class="p">),</span>

        <span class="p">(</span><span class="s2">&quot;nengo/tests/test_ensemble.py:test_gain_bias&quot;</span><span class="p">,</span>
         <span class="s2">&quot;use allclose instead of array_equal (see &quot;</span>
         <span class="s2">&quot;tests/test_simulator.py:test_gain_bias&quot;</span><span class="p">)</span>
    <span class="p">]</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">network</span><span class="p">,</span> <span class="n">dt</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                 <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">unroll_simulation</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                 <span class="n">minibatch_size</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">tensorboard</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">closed</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">unroll</span> <span class="o">=</span> <span class="n">unroll_simulation</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">minibatch_size</span> <span class="o">=</span> <span class="mi">1</span> <span class="k">if</span> <span class="n">minibatch_size</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">minibatch_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">SimulationData</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">minibatch_size</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">seed</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">iinfo</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span><span class="o">.</span><span class="n">max</span><span class="p">)</span> <span class="k">if</span> <span class="n">seed</span> <span class="ow">is</span> <span class="kc">None</span>
                     <span class="k">else</span> <span class="n">seed</span><span class="p">)</span>

        <span class="c1"># TODO: multi-GPU support</span>

        <span class="c1"># build model (uses default nengo builder)</span>
        <span class="k">if</span> <span class="n">model</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">dt</span><span class="o">=</span><span class="nb">float</span><span class="p">(</span><span class="n">dt</span><span class="p">),</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;</span><span class="si">%s</span><span class="s2">, dt=</span><span class="si">%f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">network</span><span class="p">,</span> <span class="n">dt</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">dt</span> <span class="o">!=</span> <span class="n">model</span><span class="o">.</span><span class="n">dt</span><span class="p">:</span>
                <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="s2">&quot;Model dt (</span><span class="si">%g</span><span class="s2">) does not match Simulator &quot;</span>
                              <span class="s2">&quot;dt (</span><span class="si">%g</span><span class="s2">)&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">dt</span><span class="p">,</span> <span class="n">dt</span><span class="p">),</span> <span class="n">NengoWarning</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span>

        <span class="k">if</span> <span class="n">network</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Building network&quot;</span><span class="p">)</span>
            <span class="n">start</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">build</span><span class="p">(</span><span class="n">network</span><span class="p">,</span> <span class="n">progress_bar</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\r</span><span class="s2">Build finished in </span><span class="si">%s</span><span class="s2"> &quot;</span> <span class="o">%</span>
                  <span class="n">datetime</span><span class="o">.</span><span class="n">timedelta</span><span class="p">(</span><span class="n">seconds</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start</span><span class="p">)))</span>

        <span class="c1"># set up tensorflow graph plan</span>
        <span class="k">with</span> <span class="n">utils</span><span class="o">.</span><span class="n">ProgressBar</span><span class="p">(</span><span class="s2">&quot;Optimizing graph&quot;</span><span class="p">,</span> <span class="s2">&quot;Optimization&quot;</span><span class="p">,</span>
                               <span class="n">max_value</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span> <span class="k">as</span> <span class="n">progress</span><span class="p">:</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">tensor_graph</span> <span class="o">=</span> <span class="n">TensorGraph</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dt</span><span class="p">,</span> <span class="n">unroll_simulation</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">minibatch_size</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">progress</span><span class="p">)</span>

        <span class="c1"># construct graph</span>
        <span class="k">with</span> <span class="n">utils</span><span class="o">.</span><span class="n">ProgressBar</span><span class="p">(</span><span class="s2">&quot;Constructing graph&quot;</span><span class="p">,</span> <span class="s2">&quot;Construction&quot;</span><span class="p">,</span>
                               <span class="n">max_value</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span> <span class="k">as</span> <span class="n">progress</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">tensor_graph</span><span class="o">.</span><span class="n">build</span><span class="p">(</span><span class="n">progress</span><span class="p">)</span>

        <span class="c1"># output simulation data for viewing via TensorBoard</span>
        <span class="k">if</span> <span class="n">tensorboard</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">tensorboard</span><span class="p">):</span>
                <span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">tensorboard</span><span class="p">)</span>

            <span class="n">run_number</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span>
                <span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">4</span><span class="p">:])</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="n">tensorboard</span><span class="p">)</span>
                 <span class="k">if</span> <span class="n">x</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">&quot;run&quot;</span><span class="p">)]</span> <span class="ow">or</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span> <span class="o">+</span> <span class="mi">1</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">summary</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">summary</span><span class="o">.</span><span class="n">FileWriter</span><span class="p">(</span>
                <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">tensorboard</span><span class="p">,</span> <span class="s2">&quot;run_</span><span class="si">%d</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">run_number</span><span class="p">),</span>
                <span class="n">graph</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tensor_graph</span><span class="o">.</span><span class="n">graph</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">summary</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="c1"># start session</span>
        <span class="n">config</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">ConfigProto</span><span class="p">(</span>
            <span class="n">allow_soft_placement</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="n">log_device_placement</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="c1"># TODO: XLA compiling doesn&#39;t seem to provide any benefit at the</span>
        <span class="c1"># moment, revisit later after tensorflow has developed it further</span>
        <span class="c1"># config.graph_options.optimizer_options.global_jit_level = (</span>
        <span class="c1">#     tf.OptimizerOptions.ON_1)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">sess</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">(</span><span class="n">graph</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tensor_graph</span><span class="o">.</span><span class="n">graph</span><span class="p">,</span>
                               <span class="n">config</span><span class="o">=</span><span class="n">config</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">reset</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="n">seed</span><span class="p">)</span>

<div class="viewcode-block" id="Simulator.reset"><a class="viewcode-back" href="../../simulator.html#nengo_dl.simulator.Simulator.reset">[docs]</a>    <span class="k">def</span> <span class="nf">reset</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Resets the simulator to initial conditions.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        seed : int, optional</span>
<span class="sd">            If not None, overwrite the default simulator seed with this value</span>
<span class="sd">            (note: this becomes the new default simulator seed)</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">closed</span><span class="p">:</span>
            <span class="k">raise</span> <span class="n">SimulatorClosed</span><span class="p">(</span><span class="s2">&quot;Cannot reset closed Simulator.&quot;</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">input_funcs</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_steps</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">time</span> <span class="o">=</span> <span class="mf">0.0</span>

        <span class="c1"># initialize variables</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">soft_reset</span><span class="p">(</span><span class="n">include_trainable</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">include_probes</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="c1"># execute post-build processes (we do this here because</span>
        <span class="c1"># seed can change each call to reset)</span>
        <span class="k">if</span> <span class="n">seed</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">seed</span> <span class="o">=</span> <span class="n">seed</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">RandomState</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">seed</span><span class="p">)</span>
        <span class="n">tf</span><span class="o">.</span><span class="n">set_random_seed</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">seed</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">tensor_graph</span><span class="o">.</span><span class="n">build_post</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">sess</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">rng</span><span class="p">)</span></div>

<div class="viewcode-block" id="Simulator.soft_reset"><a class="viewcode-back" href="../../simulator.html#nengo_dl.simulator.Simulator.soft_reset">[docs]</a>    <span class="k">def</span> <span class="nf">soft_reset</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">include_trainable</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">include_probes</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Resets the internal state of the simulation, but doesn&#39;t</span>
<span class="sd">        rebuild the graph.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        include_trainable : bool, optional</span>
<span class="sd">            If True, also reset any training that has been performed on</span>
<span class="sd">            network parameters (e.g., connection weights)</span>
<span class="sd">        include_probes : bool, optional</span>
<span class="sd">            If True, also clear probe data</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">init_ops</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">tensor_graph</span><span class="o">.</span><span class="n">local_init_op</span><span class="p">,</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">tensor_graph</span><span class="o">.</span><span class="n">global_init_op</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">include_trainable</span><span class="p">:</span>
            <span class="n">init_ops</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tensor_graph</span><span class="o">.</span><span class="n">trainable_init_op</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">init_ops</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">include_probes</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">probes</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="n">p</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">n_steps</span> <span class="o">=</span> <span class="mi">0</span></div>

<div class="viewcode-block" id="Simulator.step"><a class="viewcode-back" href="../../simulator.html#nengo_dl.simulator.Simulator.step">[docs]</a>    <span class="k">def</span> <span class="nf">step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Run the simulation for one time step.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        kwargs : dict</span>
<span class="sd">            See :meth:`.run_steps`</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">run_steps</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></div>

<div class="viewcode-block" id="Simulator.run"><a class="viewcode-back" href="../../simulator.html#nengo_dl.simulator.Simulator.run">[docs]</a>    <span class="k">def</span> <span class="nf">run</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">time_in_seconds</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Simulate for the given length of time.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        time_in_seconds : float</span>
<span class="sd">            Run the simulator for the given number of simulated seconds</span>
<span class="sd">        kwargs : dict</span>
<span class="sd">            See :meth:`.run_steps`</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="n">time_in_seconds</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="n">ValidationError</span><span class="p">(</span>
                <span class="s2">&quot;Must be positive (got </span><span class="si">%g</span><span class="s2">)&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">time_in_seconds</span><span class="p">,),</span>
                <span class="n">attr</span><span class="o">=</span><span class="s2">&quot;time_in_seconds&quot;</span><span class="p">)</span>

        <span class="n">steps</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="nb">float</span><span class="p">(</span><span class="n">time_in_seconds</span><span class="p">)</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">dt</span><span class="p">))</span>

        <span class="k">if</span> <span class="n">steps</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">%g</span><span class="s2"> results in running for 0 timesteps. Simulator &quot;</span>
                          <span class="s2">&quot;still at time </span><span class="si">%g</span><span class="s2">.&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">time_in_seconds</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">time</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">run_steps</span><span class="p">(</span><span class="n">steps</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></div>

<div class="viewcode-block" id="Simulator.run_steps"><a class="viewcode-back" href="../../simulator.html#nengo_dl.simulator.Simulator.run_steps">[docs]</a>    <span class="k">def</span> <span class="nf">run_steps</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_steps</span><span class="p">,</span> <span class="n">input_feeds</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">profile</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                  <span class="n">progress_bar</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Simulate for the given number of steps.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        n_steps : int</span>
<span class="sd">            The number of simulation steps to be executed</span>
<span class="sd">        input_feeds : dict of {:class:`~nengo:nengo.Node`: \</span>
<span class="sd">                               :class:`~numpy:numpy.ndarray`}</span>
<span class="sd">            Override the values of input Nodes with the given data.  Arrays</span>
<span class="sd">            should have shape ``(sim.minibatch_size, n_steps, node.size_out)``.</span>
<span class="sd">        profile : bool, optional</span>
<span class="sd">            If True, collect TensorFlow profiling information while the</span>
<span class="sd">            simulation is running (this will slow down the simulation).</span>
<span class="sd">            Can also pass a dict of `config options for the profiler</span>
<span class="sd">            &lt;https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/profiler/g3doc/options.md&gt;`__.</span>
<span class="sd">        progress_bar : bool, optional</span>
<span class="sd">            If True, print information about the simulation status to standard</span>
<span class="sd">            output.</span>

<span class="sd">        Notes</span>
<span class="sd">        -----</span>
<span class="sd">        If ``unroll_simulation=x`` is specified, and ``n_steps &gt; x``, this will</span>
<span class="sd">        repeatedly execute ``x`` timesteps until the the number of steps</span>
<span class="sd">        executed is &gt;= ``n_steps``.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">closed</span><span class="p">:</span>
            <span class="k">raise</span> <span class="n">SimulatorClosed</span><span class="p">(</span><span class="s2">&quot;Simulator cannot run because it is closed.&quot;</span><span class="p">)</span>

        <span class="n">actual_steps</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">unroll</span> <span class="o">*</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="n">n_steps</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">unroll</span><span class="p">))</span>

        <span class="k">if</span> <span class="n">actual_steps</span> <span class="o">!=</span> <span class="n">n_steps</span><span class="p">:</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                <span class="s2">&quot;Number of steps (</span><span class="si">%d</span><span class="s2">) is not an even multiple of &quot;</span>
                <span class="s2">&quot;`unroll_simulation` (</span><span class="si">%d</span><span class="s2">).  Simulation will run for </span><span class="si">%d</span><span class="s2"> steps, &quot;</span>
                <span class="s2">&quot;which may have unintended side effects.&quot;</span> <span class="o">%</span>
                <span class="p">(</span><span class="n">n_steps</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">unroll</span><span class="p">,</span> <span class="n">actual_steps</span><span class="p">),</span> <span class="ne">RuntimeWarning</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">input_feeds</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_check_data</span><span class="p">(</span><span class="n">input_feeds</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;input&quot;</span><span class="p">,</span>
                             <span class="n">n_batch</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">minibatch_size</span><span class="p">,</span> <span class="n">n_steps</span><span class="o">=</span><span class="n">n_steps</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">profile</span><span class="p">:</span>
            <span class="n">run_options</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">RunOptions</span><span class="p">(</span><span class="n">trace_level</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">RunOptions</span><span class="o">.</span><span class="n">FULL_TRACE</span><span class="p">)</span>
            <span class="n">run_metadata</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">RunMetadata</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">run_options</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="n">run_metadata</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="n">progress</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">utils</span><span class="o">.</span><span class="n">ProgressBar</span><span class="p">(</span><span class="s2">&quot;Simulating&quot;</span><span class="p">,</span> <span class="s2">&quot;Simulation&quot;</span><span class="p">,</span> <span class="n">max_value</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">progress_bar</span> <span class="k">else</span> <span class="n">utils</span><span class="o">.</span><span class="n">NullProgressBar</span><span class="p">())</span>

        <span class="c1"># execute the simulation loop</span>
        <span class="k">with</span> <span class="n">progress</span><span class="p">:</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">steps_run</span><span class="p">,</span> <span class="n">probe_data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span>
                    <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">tensor_graph</span><span class="o">.</span><span class="n">steps_run</span><span class="p">,</span>
                     <span class="bp">self</span><span class="o">.</span><span class="n">tensor_graph</span><span class="o">.</span><span class="n">probe_arrays</span><span class="p">],</span>
                    <span class="n">feed_dict</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_fill_feed</span><span class="p">(</span><span class="n">actual_steps</span><span class="p">,</span> <span class="n">input_feeds</span><span class="p">,</span>
                                              <span class="n">start</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">n_steps</span><span class="p">),</span>
                    <span class="n">options</span><span class="o">=</span><span class="n">run_options</span><span class="p">,</span> <span class="n">run_metadata</span><span class="o">=</span><span class="n">run_metadata</span><span class="p">)</span>
            <span class="k">except</span> <span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">errors</span><span class="o">.</span><span class="n">InternalError</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">errors</span><span class="o">.</span><span class="n">UnknownError</span><span class="p">)</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">e</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">type</span> <span class="o">==</span> <span class="s2">&quot;PyFunc&quot;</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="n">SimulationError</span><span class="p">(</span>
                        <span class="s2">&quot;Function &#39;</span><span class="si">%s</span><span class="s2">&#39; caused an error (see error log above)&quot;</span> <span class="o">%</span>
                        <span class="n">e</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">name</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="n">e</span>  <span class="c1"># pragma: no cover</span>

            <span class="c1"># update probe data</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_update_probe_data</span><span class="p">(</span><span class="n">probe_data</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_steps</span><span class="p">,</span> <span class="n">n_steps</span><span class="p">)</span>

            <span class="c1"># update n_steps</span>
            <span class="c1"># note: we update n_steps according to the number of steps that the</span>
            <span class="c1"># user asked for, not the number of steps that were actually run (</span>
            <span class="c1"># in the case of uneven unroll_simulation)</span>
            <span class="k">assert</span> <span class="n">steps_run</span> <span class="o">==</span> <span class="n">actual_steps</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">n_steps</span> <span class="o">+=</span> <span class="n">n_steps</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">time</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_steps</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">dt</span>

        <span class="k">if</span> <span class="n">profile</span><span class="p">:</span>
            <span class="n">filename</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">DATA_DIR</span><span class="p">,</span> <span class="s2">&quot;nengo_dl_profile.json&quot;</span><span class="p">)</span>
            <span class="n">options</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">profiler</span><span class="o">.</span><span class="n">ProfileOptionBuilder</span><span class="o">.</span><span class="n">time_and_memory</span><span class="p">()</span>
            <span class="n">options</span><span class="p">[</span><span class="s2">&quot;output&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;timeline:outfile=</span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">filename</span>
            <span class="n">options</span><span class="p">[</span><span class="s2">&quot;min_bytes&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">profile</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
                <span class="n">options</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">profile</span><span class="p">)</span>
            <span class="n">tf</span><span class="o">.</span><span class="n">profiler</span><span class="o">.</span><span class="n">profile</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">tensor_graph</span><span class="o">.</span><span class="n">graph</span><span class="p">,</span> <span class="n">run_meta</span><span class="o">=</span><span class="n">run_metadata</span><span class="p">,</span>
                <span class="n">cmd</span><span class="o">=</span><span class="s2">&quot;scope&quot;</span><span class="p">,</span> <span class="n">options</span><span class="o">=</span><span class="n">options</span><span class="p">)</span></div>

<div class="viewcode-block" id="Simulator.train"><a class="viewcode-back" href="../../simulator.html#nengo_dl.simulator.Simulator.train">[docs]</a>    <span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">n_epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">objective</span><span class="o">=</span><span class="s2">&quot;mse&quot;</span><span class="p">,</span>
              <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">summaries</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">profile</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Optimize the trainable parameters of the network using the given</span>
<span class="sd">        optimization method, minimizing the objective value over the given</span>
<span class="sd">        inputs and targets.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        inputs : dict of {:class:`~nengo:nengo.Node`: \</span>
<span class="sd">                          :class:`~numpy:numpy.ndarray`}</span>
<span class="sd">            Input values for Nodes in the network; arrays should have shape</span>
<span class="sd">            ``(batch_size, n_steps, node.size_out)``</span>
<span class="sd">        targets : dict of {:class:`~nengo:nengo.Probe`: \</span>
<span class="sd">                           :class:`~numpy:numpy.ndarray`}</span>
<span class="sd">            Desired output value at Probes, corresponding to each value in</span>
<span class="sd">            ``inputs``; arrays should have shape</span>
<span class="sd">            ``(batch_size, n_steps, probe.size_in)``</span>
<span class="sd">        optimizer : ``tf.train.Optimizer``</span>
<span class="sd">            TensorFlow optimizer, e.g.</span>
<span class="sd">            ``tf.train.GradientDescentOptimizer(learning_rate=0.1)``</span>
<span class="sd">        n_epochs : int, optional</span>
<span class="sd">            Run training for the given number of epochs (complete passes</span>
<span class="sd">            through ``inputs``)</span>
<span class="sd">        objective : ``&quot;mse&quot;`` or callable, optional</span>
<span class="sd">            The objective to be minimized. Passing ``&quot;mse&quot;`` will train with</span>
<span class="sd">            mean squared error. A custom function</span>
<span class="sd">            ``f(output, target) -&gt; loss`` can be passed that consumes the</span>
<span class="sd">            actual output and target output for a probe in ``targets``</span>
<span class="sd">            and returns a ``tf.Tensor`` representing the scalar loss value for</span>
<span class="sd">            that Probe (loss will be averaged across Probes).  Note that by</span>
<span class="sd">            default the same objective will be used for all probes in</span>
<span class="sd">            ``targets``; a dictionary of ``{probe: obj, ...}`` can be passed</span>
<span class="sd">            for ``objective`` to specify a different objective for each probe.</span>
<span class="sd">        shuffle : bool, optional</span>
<span class="sd">            If True, randomize the data into different minibatches each epoch</span>
<span class="sd">        truncation: int, optional</span>
<span class="sd">            If not None, use truncated backpropagation when training the</span>
<span class="sd">            network, with the given truncation length.</span>
<span class="sd">        summaries : list of :class:`~nengo:nengo.Connection` or \</span>
<span class="sd">                            :class:`~nengo:nengo.Ensemble` or \</span>
<span class="sd">                            :class:`~nengo:nengo.ensemble.Neurons` or \</span>
<span class="sd">                            ``&quot;loss&quot;`` or \</span>
<span class="sd">                            ``tf.Tensor``}</span>
<span class="sd">            If not None, collect data during the training process using</span>
<span class="sd">            TensorFlow&#39;s ``tf.summary`` format.  The summary objects can be a</span>
<span class="sd">            Connection (in which case data on the corresponding weights will be</span>
<span class="sd">            collected), Ensemble (encoders), Neurons (biases), or ``&quot;loss&quot;``</span>
<span class="sd">            (the loss value for ``objective``).  The user can also create their</span>
<span class="sd">            own summaries and pass in the Tensors representing the summary ops.</span>
<span class="sd">        profile : bool, optional</span>
<span class="sd">            If True, collect TensorFlow profiling information while training</span>
<span class="sd">            (this will slow down the training).  Can also pass a dict of</span>
<span class="sd">            `config options for the profiler</span>
<span class="sd">            &lt;https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/profiler/g3doc/options.md&gt;`__.</span>

<span class="sd">        Notes</span>
<span class="sd">        -----</span>
<span class="sd">        Most deep learning methods require the network to be differentiable,</span>
<span class="sd">        which means that trying to train a network with non-differentiable</span>
<span class="sd">        elements will result in an error.  Examples of common</span>
<span class="sd">        non-differentiable elements include :class:`~nengo:nengo.LIF`,</span>
<span class="sd">        :class:`~nengo:nengo.Direct`, or processes/neurons that don&#39;t have a</span>
<span class="sd">        custom TensorFlow implementation (see</span>
<span class="sd">        :class:`.process_builders.SimProcessBuilder`/</span>
<span class="sd">        :class:`.neuron_builders.SimNeuronsBuilder`)</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">batch_size</span><span class="p">,</span> <span class="n">n_steps</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">inputs</span><span class="o">.</span><span class="n">values</span><span class="p">()))</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="mi">2</span><span class="p">]</span>

        <span class="c1"># error checking</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">closed</span><span class="p">:</span>
            <span class="k">raise</span> <span class="n">SimulatorClosed</span><span class="p">(</span><span class="s2">&quot;Simulator cannot be trained because it is &quot;</span>
                                  <span class="s2">&quot;closed.&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_check_data</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;input&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_check_data</span><span class="p">(</span><span class="n">targets</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;target&quot;</span><span class="p">,</span> <span class="n">n_steps</span><span class="o">=</span><span class="n">n_steps</span><span class="p">,</span>
                         <span class="n">n_batch</span><span class="o">=</span><span class="n">batch_size</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">n_steps</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">unroll</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="n">ValidationError</span><span class="p">(</span>
                <span class="s2">&quot;The number of timesteps in training data must be evenly &quot;</span>
                <span class="s2">&quot;divisible by unroll_simulation&quot;</span><span class="p">,</span> <span class="s2">&quot;inputs&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">truncation</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">truncation</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">unroll</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="n">ValidationError</span><span class="p">(</span>
                <span class="s2">&quot;Truncation length must be evenly divisible by &quot;</span>
                <span class="s2">&quot;unroll_simulation&quot;</span><span class="p">,</span> <span class="s2">&quot;inputs&quot;</span><span class="p">)</span>

        <span class="c1"># check for non-differentiable elements in graph</span>
        <span class="c1"># utils.find_non_differentiable(</span>
        <span class="c1">#     [self.tensor_graph.invariant_ph[n] for n in inputs],</span>
        <span class="c1">#     [self.tensor_graph.probe_arrays[self.model.probes.index(p)]</span>
        <span class="c1">#      for p in targets])</span>

        <span class="c1"># apply objective to all probes if individual objectives weren&#39;t given</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">objective</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
            <span class="n">objective</span> <span class="o">=</span> <span class="p">{</span><span class="n">p</span><span class="p">:</span> <span class="n">objective</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">targets</span><span class="p">}</span>

        <span class="c1"># build optimizer op</span>
        <span class="n">opt_op</span><span class="p">,</span> <span class="n">opt_slots_init</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tensor_graph</span><span class="o">.</span><span class="n">build_optimizer</span><span class="p">(</span>
            <span class="n">optimizer</span><span class="p">,</span> <span class="n">objective</span><span class="p">)</span>
        <span class="n">fetches</span> <span class="o">=</span> <span class="p">[</span><span class="n">opt_op</span><span class="p">]</span>

        <span class="c1"># get loss op</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tensor_graph</span><span class="o">.</span><span class="n">build_loss</span><span class="p">(</span><span class="n">objective</span><span class="p">)</span>
        <span class="n">fetches</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>

        <span class="c1"># add summaries</span>
        <span class="n">summary_op</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="n">summaries</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">summary</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="s2">&quot;Simulator was created with tensorboard=False; &quot;</span>
                              <span class="s2">&quot;ignoring requested summaries&quot;</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">summaries</span><span class="p">):</span>
                    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span> <span class="ow">and</span> <span class="n">v</span> <span class="o">==</span> <span class="s2">&quot;loss&quot;</span><span class="p">:</span>
                        <span class="n">summaries</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">objective</span>
                <span class="n">summary_op</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tensor_graph</span><span class="o">.</span><span class="n">build_summaries</span><span class="p">(</span><span class="n">summaries</span><span class="p">)</span>
                <span class="n">fetches</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">summary_op</span><span class="p">)</span>

        <span class="c1"># increment training step</span>
        <span class="n">fetches</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tensor_graph</span><span class="o">.</span><span class="n">training_step_inc</span><span class="p">)</span>

        <span class="c1"># save the internal state of the simulator</span>
        <span class="n">tmpdir</span> <span class="o">=</span> <span class="n">tempfile</span><span class="o">.</span><span class="n">TemporaryDirectory</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">save_params</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">tmpdir</span><span class="o">.</span><span class="n">name</span><span class="p">,</span> <span class="s2">&quot;tmp&quot;</span><span class="p">),</span> <span class="n">include_local</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                         <span class="n">include_global</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

        <span class="c1"># initialize any variables that were created by the optimizer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">opt_slots_init</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">profile</span><span class="p">:</span>
            <span class="n">run_options</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">RunOptions</span><span class="p">(</span><span class="n">trace_level</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">RunOptions</span><span class="o">.</span><span class="n">FULL_TRACE</span><span class="p">)</span>
            <span class="n">run_metadata</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">RunMetadata</span><span class="p">()</span>
            <span class="n">profiler</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">profiler</span><span class="o">.</span><span class="n">Profiler</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tensor_graph</span><span class="o">.</span><span class="n">graph</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">run_options</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="n">run_metadata</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="n">progress</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">ProgressBar</span><span class="p">(</span>
            <span class="s2">&quot;Training&quot;</span><span class="p">,</span> <span class="n">max_value</span><span class="o">=</span><span class="n">n_epochs</span> <span class="o">*</span> <span class="n">batch_size</span> <span class="o">//</span> <span class="bp">self</span><span class="o">.</span><span class="n">minibatch_size</span><span class="p">,</span>
            <span class="nb">vars</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;loss&quot;</span><span class="p">])</span>

        <span class="c1"># run training</span>
        <span class="k">with</span> <span class="n">progress</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_epochs</span><span class="p">):</span>
                <span class="k">for</span> <span class="n">offset</span><span class="p">,</span> <span class="n">inp</span><span class="p">,</span> <span class="n">tar</span> <span class="ow">in</span> <span class="n">utils</span><span class="o">.</span><span class="n">minibatch_generator</span><span class="p">(</span>
                        <span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">minibatch_size</span><span class="p">,</span> <span class="n">rng</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">rng</span><span class="p">,</span>
                        <span class="n">shuffle</span><span class="o">=</span><span class="n">shuffle</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="n">truncation</span><span class="p">):</span>
                    <span class="k">if</span> <span class="n">offset</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">soft_reset</span><span class="p">()</span>

                    <span class="n">steps</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">inp</span><span class="o">.</span><span class="n">values</span><span class="p">()))</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
                    <span class="n">feed</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_fill_feed</span><span class="p">(</span><span class="n">steps</span><span class="p">,</span> <span class="n">inp</span><span class="p">,</span> <span class="n">tar</span><span class="p">,</span> <span class="n">start</span><span class="o">=</span><span class="n">offset</span><span class="p">)</span>
                    <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span>
                        <span class="n">fetches</span><span class="p">,</span> <span class="n">feed_dict</span><span class="o">=</span><span class="n">feed</span><span class="p">,</span>
                        <span class="n">options</span><span class="o">=</span><span class="n">run_options</span><span class="p">,</span> <span class="n">run_metadata</span><span class="o">=</span><span class="n">run_metadata</span><span class="p">)</span>

                    <span class="k">if</span> <span class="n">summary_op</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">summary</span><span class="o">.</span><span class="n">add_summary</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">outputs</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>

                    <span class="k">if</span> <span class="n">profile</span><span class="p">:</span>
                        <span class="n">profiler</span><span class="o">.</span><span class="n">add_step</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]),</span> <span class="n">run_metadata</span><span class="p">)</span>

                    <span class="k">if</span> <span class="n">offset</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                        <span class="n">progress</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s2">&quot;</span><span class="si">%.4f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">outputs</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>

        <span class="c1"># restore internal state of simulator</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">load_params</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">tmpdir</span><span class="o">.</span><span class="n">name</span><span class="p">,</span> <span class="s2">&quot;tmp&quot;</span><span class="p">),</span> <span class="n">include_local</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                         <span class="n">include_global</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="n">tmpdir</span><span class="o">.</span><span class="n">cleanup</span><span class="p">()</span>

        <span class="k">if</span> <span class="n">profile</span><span class="p">:</span>
            <span class="n">filename</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">DATA_DIR</span><span class="p">,</span> <span class="s2">&quot;nengo_dl_profile.json&quot;</span><span class="p">)</span>
            <span class="n">options</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">profiler</span><span class="o">.</span><span class="n">ProfileOptionBuilder</span><span class="o">.</span><span class="n">time_and_memory</span><span class="p">()</span>
            <span class="n">options</span><span class="p">[</span><span class="s2">&quot;output&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;timeline:outfile=</span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">filename</span>
            <span class="n">options</span><span class="p">[</span><span class="s2">&quot;min_bytes&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">profile</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
                <span class="n">options</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">profile</span><span class="p">)</span>
            <span class="n">profiler</span><span class="o">.</span><span class="n">profile_name_scope</span><span class="p">(</span><span class="n">options</span><span class="p">)</span></div>

<div class="viewcode-block" id="Simulator.loss"><a class="viewcode-back" href="../../simulator.html#nengo_dl.simulator.Simulator.loss">[docs]</a>    <span class="k">def</span> <span class="nf">loss</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">objective</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Compute the loss value for the given objective and inputs/targets.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        inputs : dict of {:class:`~nengo:nengo.Node`: \</span>
<span class="sd">                          :class:`~numpy:numpy.ndarray`}</span>
<span class="sd">            Input values for Nodes in the network; arrays should have shape</span>
<span class="sd">            ``(batch_size, n_steps, node.size_out)``</span>
<span class="sd">        targets : dict of {:class:`~nengo:nengo.Probe`: \</span>
<span class="sd">                           :class:`~numpy:numpy.ndarray`}</span>
<span class="sd">            Desired output value at Probes, corresponding to each value in</span>
<span class="sd">            ``inputs``; arrays should have shape</span>
<span class="sd">            ``(batch_size, n_steps, probe.size_in)``</span>
<span class="sd">        objective : ``&quot;mse&quot;`` or callable</span>
<span class="sd">            The objective used to compute loss. Passing ``&quot;mse&quot;`` will use</span>
<span class="sd">            mean squared error. A custom function</span>
<span class="sd">            ``f(output, target) -&gt; loss`` can be passed that consumes the</span>
<span class="sd">            actual output and target output for a probe in ``targets``</span>
<span class="sd">            and returns a ``tf.Tensor`` representing the scalar loss value for</span>
<span class="sd">            that Probe (loss will be averaged across Probes). Note that by</span>
<span class="sd">            default the same objective will be used for all probes in</span>
<span class="sd">            ``targets``; a dictionary of ``{probe: obj, ...}`` can be passed</span>
<span class="sd">            for ``objective`` to specify a different objective for each probe.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">batch_size</span><span class="p">,</span> <span class="n">n_steps</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">inputs</span><span class="o">.</span><span class="n">values</span><span class="p">()))</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="mi">2</span><span class="p">]</span>

        <span class="c1"># error checking</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">closed</span><span class="p">:</span>
            <span class="k">raise</span> <span class="n">SimulatorClosed</span><span class="p">(</span><span class="s2">&quot;Loss cannot be computed after simulator is &quot;</span>
                                  <span class="s2">&quot;closed.&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_check_data</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;input&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_check_data</span><span class="p">(</span><span class="n">targets</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;target&quot;</span><span class="p">,</span> <span class="n">n_steps</span><span class="o">=</span><span class="n">n_steps</span><span class="p">,</span>
                         <span class="n">n_batch</span><span class="o">=</span><span class="n">batch_size</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">n_steps</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">unroll</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="n">ValidationError</span><span class="p">(</span>
                <span class="s2">&quot;The number of timesteps in loss data must be evenly &quot;</span>
                <span class="s2">&quot;divisible by unroll_simulation&quot;</span><span class="p">,</span> <span class="s2">&quot;inputs&quot;</span><span class="p">)</span>

        <span class="c1"># apply objective to all probes if individual objectives weren&#39;t given</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">objective</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
            <span class="n">objective</span> <span class="o">=</span> <span class="p">{</span><span class="n">p</span><span class="p">:</span> <span class="n">objective</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">targets</span><span class="p">}</span>

        <span class="c1"># get loss op</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tensor_graph</span><span class="o">.</span><span class="n">build_loss</span><span class="p">(</span><span class="n">objective</span><span class="p">)</span>

        <span class="c1"># save the internal state of the simulator</span>
        <span class="n">tmpdir</span> <span class="o">=</span> <span class="n">tempfile</span><span class="o">.</span><span class="n">TemporaryDirectory</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">save_params</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">tmpdir</span><span class="o">.</span><span class="n">name</span><span class="p">,</span> <span class="s2">&quot;tmp&quot;</span><span class="p">),</span> <span class="n">include_local</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                         <span class="n">include_global</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

        <span class="c1"># compute loss on data</span>
        <span class="n">loss_val</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">_</span><span class="p">,</span> <span class="n">inp</span><span class="p">,</span> <span class="n">tar</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">utils</span><span class="o">.</span><span class="n">minibatch_generator</span><span class="p">(</span>
                <span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">minibatch_size</span><span class="p">,</span> <span class="n">rng</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">rng</span><span class="p">)):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">soft_reset</span><span class="p">()</span>
            <span class="n">loss_val</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span>
                <span class="n">loss</span><span class="p">,</span> <span class="n">feed_dict</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_fill_feed</span><span class="p">(</span><span class="n">n_steps</span><span class="p">,</span> <span class="n">inp</span><span class="p">,</span> <span class="n">tar</span><span class="p">))</span>
        <span class="n">loss_val</span> <span class="o">/=</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span>

        <span class="c1"># restore internal state of simulator</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">load_params</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">tmpdir</span><span class="o">.</span><span class="n">name</span><span class="p">,</span> <span class="s2">&quot;tmp&quot;</span><span class="p">),</span> <span class="n">include_local</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                         <span class="n">include_global</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="n">tmpdir</span><span class="o">.</span><span class="n">cleanup</span><span class="p">()</span>

        <span class="k">return</span> <span class="n">loss_val</span></div>

<div class="viewcode-block" id="Simulator.save_params"><a class="viewcode-back" href="../../simulator.html#nengo_dl.simulator.Simulator.save_params">[docs]</a>    <span class="k">def</span> <span class="nf">save_params</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">,</span> <span class="n">include_global</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">include_local</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Save network parameters to the given ``path``.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        path : str</span>
<span class="sd">            Filepath of parameter output file</span>
<span class="sd">        include_global : bool, optional</span>
<span class="sd">            If True (default True), save global (trainable) network variables</span>
<span class="sd">        include_local : bool, optional</span>
<span class="sd">            If True (default False), save local (non-trainable) network</span>
<span class="sd">            variables</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">closed</span><span class="p">:</span>
            <span class="k">raise</span> <span class="n">SimulationError</span><span class="p">(</span><span class="s2">&quot;Simulation has been closed, cannot save &quot;</span>
                                  <span class="s2">&quot;parameters&quot;</span><span class="p">)</span>

        <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">tensor_graph</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">as_default</span><span class="p">():</span>
            <span class="nb">vars</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">if</span> <span class="n">include_global</span><span class="p">:</span>
                <span class="nb">vars</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">global_variables</span><span class="p">())</span>
            <span class="k">if</span> <span class="n">include_local</span><span class="p">:</span>
                <span class="nb">vars</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">local_variables</span><span class="p">())</span>

            <span class="n">path</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">Saver</span><span class="p">(</span><span class="nb">vars</span><span class="p">)</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">sess</span><span class="p">,</span> <span class="n">path</span><span class="p">)</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Model parameters saved to </span><span class="si">%s</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">path</span><span class="p">)</span></div>

<div class="viewcode-block" id="Simulator.load_params"><a class="viewcode-back" href="../../simulator.html#nengo_dl.simulator.Simulator.load_params">[docs]</a>    <span class="k">def</span> <span class="nf">load_params</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">,</span> <span class="n">include_global</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">include_local</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Load network parameters from the given ``path``.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        path : str</span>
<span class="sd">            Filepath of parameter input file</span>
<span class="sd">        include_global : bool, optional</span>
<span class="sd">            If True (default True), load global (trainable) network variables</span>
<span class="sd">        include_local : bool, optional</span>
<span class="sd">            If True (default False), load local (non-trainable) network</span>
<span class="sd">            variables</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">closed</span><span class="p">:</span>
            <span class="k">raise</span> <span class="n">SimulationError</span><span class="p">(</span><span class="s2">&quot;Simulation has been closed, cannot load &quot;</span>
                                  <span class="s2">&quot;parameters&quot;</span><span class="p">)</span>

        <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">tensor_graph</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">as_default</span><span class="p">():</span>
            <span class="nb">vars</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">if</span> <span class="n">include_global</span><span class="p">:</span>
                <span class="nb">vars</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">global_variables</span><span class="p">())</span>
            <span class="k">if</span> <span class="n">include_local</span><span class="p">:</span>
                <span class="nb">vars</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">local_variables</span><span class="p">())</span>

            <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">Saver</span><span class="p">(</span><span class="nb">vars</span><span class="p">)</span><span class="o">.</span><span class="n">restore</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">sess</span><span class="p">,</span> <span class="n">path</span><span class="p">)</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Model parameters loaded from </span><span class="si">%s</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">path</span><span class="p">)</span></div>

<div class="viewcode-block" id="Simulator.check_gradients"><a class="viewcode-back" href="../../simulator.html#nengo_dl.simulator.Simulator.check_gradients">[docs]</a>    <span class="k">def</span> <span class="nf">check_gradients</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">atol</span><span class="o">=</span><span class="mf">1e-5</span><span class="p">,</span> <span class="n">rtol</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Perform gradient checks for the network (used to verify that the</span>
<span class="sd">        analytic gradients are correct).</span>

<span class="sd">        Raises a simulation error if the difference between analytic and</span>
<span class="sd">        numeric gradient is greater than ``atol + rtol * numeric_grad``</span>
<span class="sd">        (elementwise).</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        outputs : ``tf.Tensor`` or list of ``tf.Tensor`` or \</span>
<span class="sd">                  list of :class:`~nengo:nengo.Probe`</span>
<span class="sd">            Compute gradients wrt this output (if None, computes wrt each</span>
<span class="sd">            output probe)</span>
<span class="sd">        atol : float, optional</span>
<span class="sd">            Absolute error tolerance</span>
<span class="sd">        rtol : float, optional</span>
<span class="sd">            Relative (to numeric grad) error tolerance</span>

<span class="sd">        Notes</span>
<span class="sd">        -----</span>
<span class="sd">        Calling this function will reset all values in the network, so it</span>
<span class="sd">        should not be intermixed with calls to :meth:`.Simulator.run`.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">delta</span> <span class="o">=</span> <span class="mf">1e-3</span>
        <span class="n">n_steps</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">unroll</span> <span class="o">*</span> <span class="mi">2</span>

        <span class="n">feed</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_fill_feed</span><span class="p">(</span>
            <span class="n">n_steps</span><span class="p">,</span> <span class="p">{</span><span class="n">n</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">minibatch_size</span><span class="p">,</span> <span class="n">n_steps</span><span class="p">,</span> <span class="n">n</span><span class="o">.</span><span class="n">size_out</span><span class="p">))</span>
                      <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">tensor_graph</span><span class="o">.</span><span class="n">invariant_inputs</span><span class="p">},</span>
            <span class="p">{</span><span class="n">p</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">minibatch_size</span><span class="p">,</span> <span class="n">n_steps</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">size_in</span><span class="p">))</span>
             <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">tensor_graph</span><span class="o">.</span><span class="n">target_phs</span><span class="p">})</span>

        <span class="k">if</span> <span class="n">outputs</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># note: the x + 0 is necessary because `gradient_checker`</span>
            <span class="c1"># doesn&#39;t work properly if the output variable is a tensorarray</span>
            <span class="n">outputs</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span> <span class="o">+</span> <span class="mi">0</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">tensor_graph</span><span class="o">.</span><span class="n">probe_arrays</span><span class="p">]</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
            <span class="n">outputs</span> <span class="o">=</span> <span class="p">[</span><span class="n">outputs</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">outputs</span> <span class="o">=</span> <span class="p">[</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">tensor_graph</span><span class="o">.</span><span class="n">probe_arrays</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">probes</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="n">p</span><span class="p">)]</span> <span class="o">+</span> <span class="mi">0</span>
                <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">outputs</span><span class="p">]</span>

        <span class="c1"># check gradient wrt inp</span>
        <span class="k">for</span> <span class="n">node</span><span class="p">,</span> <span class="n">inp</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">tensor_graph</span><span class="o">.</span><span class="n">invariant_ph</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="n">inp_shape</span> <span class="o">=</span> <span class="n">inp</span><span class="o">.</span><span class="n">get_shape</span><span class="p">()</span><span class="o">.</span><span class="n">as_list</span><span class="p">()</span>
            <span class="n">inp_shape</span> <span class="o">=</span> <span class="p">[</span><span class="n">n_steps</span> <span class="k">if</span> <span class="n">x</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">x</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">inp_shape</span><span class="p">]</span>
            <span class="n">inp_tens</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tensor_graph</span><span class="o">.</span><span class="n">invariant_ph</span><span class="p">[</span><span class="n">node</span><span class="p">]</span>
            <span class="n">feed</span><span class="p">[</span><span class="n">inp_tens</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ascontiguousarray</span><span class="p">(</span><span class="n">feed</span><span class="p">[</span><span class="n">inp_tens</span><span class="p">])</span>
            <span class="n">inp_val</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ravel</span><span class="p">(</span><span class="n">feed</span><span class="p">[</span><span class="n">inp_tens</span><span class="p">])</span>
            <span class="k">for</span> <span class="n">out</span> <span class="ow">in</span> <span class="n">outputs</span><span class="p">:</span>
                <span class="n">out_shape</span> <span class="o">=</span> <span class="n">out</span><span class="o">.</span><span class="n">get_shape</span><span class="p">()</span><span class="o">.</span><span class="n">as_list</span><span class="p">()</span>
                <span class="n">out_shape</span> <span class="o">=</span> <span class="p">[</span><span class="n">n_steps</span> <span class="k">if</span> <span class="n">x</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">x</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">out_shape</span><span class="p">]</span>

                <span class="c1"># we need to compute the numeric jacobian manually, to</span>
                <span class="c1"># correctly handle variables (tensorflow doesn&#39;t expect</span>
                <span class="c1"># state ops in `compute_gradient`, because it doesn&#39;t define</span>
                <span class="c1"># gradients for them)</span>
                <span class="n">numeric</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">np</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">inp_shape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">),</span>
                                    <span class="n">np</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">out_shape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)))</span>

                <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">numeric</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">soft_reset</span><span class="p">()</span>
                    <span class="n">inp_val</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">delta</span>
                    <span class="n">plus</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="n">feed_dict</span><span class="o">=</span><span class="n">feed</span><span class="p">)</span>

                    <span class="bp">self</span><span class="o">.</span><span class="n">soft_reset</span><span class="p">()</span>
                    <span class="n">inp_val</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="n">delta</span>
                    <span class="n">minus</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="n">feed_dict</span><span class="o">=</span><span class="n">feed</span><span class="p">)</span>

                    <span class="n">numeric</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ravel</span><span class="p">((</span><span class="n">plus</span> <span class="o">-</span> <span class="n">minus</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">delta</span><span class="p">))</span>

                    <span class="n">inp_val</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>

                <span class="bp">self</span><span class="o">.</span><span class="n">soft_reset</span><span class="p">()</span>

                <span class="n">dx</span><span class="p">,</span> <span class="n">dy</span> <span class="o">=</span> <span class="n">gradient_checker</span><span class="o">.</span><span class="n">_compute_dx_and_dy</span><span class="p">(</span>
                    <span class="n">inp</span><span class="p">,</span> <span class="n">out</span><span class="p">,</span> <span class="n">out_shape</span><span class="p">)</span>

                <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">sess</span><span class="o">.</span><span class="n">as_default</span><span class="p">():</span>
                    <span class="n">analytic</span> <span class="o">=</span> <span class="n">gradient_checker</span><span class="o">.</span><span class="n">_compute_theoretical_jacobian</span><span class="p">(</span>
                        <span class="n">inp</span><span class="p">,</span> <span class="n">inp_shape</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">inp_shape</span><span class="p">),</span> <span class="n">dy</span><span class="p">,</span> <span class="n">out_shape</span><span class="p">,</span> <span class="n">dx</span><span class="p">,</span>
                        <span class="n">extra_feed_dict</span><span class="o">=</span><span class="n">feed</span><span class="p">)</span>

                <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">analytic</span><span class="p">))</span> <span class="ow">or</span> <span class="n">np</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">numeric</span><span class="p">)):</span>
                    <span class="k">raise</span> <span class="n">SimulationError</span><span class="p">(</span><span class="s2">&quot;NaNs detected in gradient&quot;</span><span class="p">)</span>
                <span class="n">fail</span> <span class="o">=</span> <span class="nb">abs</span><span class="p">(</span><span class="n">analytic</span> <span class="o">-</span> <span class="n">numeric</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="n">atol</span> <span class="o">+</span> <span class="n">rtol</span> <span class="o">*</span> <span class="nb">abs</span><span class="p">(</span><span class="n">numeric</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">fail</span><span class="p">):</span>
                    <span class="k">raise</span> <span class="n">SimulationError</span><span class="p">(</span>
                        <span class="s2">&quot;Gradient check failed for input </span><span class="si">%s</span><span class="s2"> and output </span><span class="si">%s</span><span class="se">\n</span><span class="s2">&quot;</span>
                        <span class="s2">&quot;numeric values:</span><span class="se">\n</span><span class="si">%s</span><span class="se">\n</span><span class="s2">&quot;</span>
                        <span class="s2">&quot;analytic values:</span><span class="se">\n</span><span class="si">%s</span><span class="se">\n</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="n">out</span><span class="p">,</span> <span class="n">numeric</span><span class="p">[</span><span class="n">fail</span><span class="p">],</span>
                                                    <span class="n">analytic</span><span class="p">[</span><span class="n">fail</span><span class="p">]))</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">soft_reset</span><span class="p">()</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Gradient check passed&quot;</span><span class="p">)</span></div>

<div class="viewcode-block" id="Simulator.trange"><a class="viewcode-back" href="../../simulator.html#nengo_dl.simulator.Simulator.trange">[docs]</a>    <span class="k">def</span> <span class="nf">trange</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dt</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Create a vector of times matching probed data.</span>

<span class="sd">        Note that the range does not start at 0 as one might expect, but at</span>
<span class="sd">        the first timestep (i.e., ``dt``).</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        dt : float, optional</span>
<span class="sd">            The sampling period of the probe to create a range for;</span>
<span class="sd">            if None, the simulator&#39;s ``dt`` will be used.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">dt</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dt</span> <span class="k">if</span> <span class="n">dt</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">dt</span>
        <span class="n">n_steps</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_steps</span> <span class="o">*</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dt</span> <span class="o">/</span> <span class="n">dt</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">dt</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_steps</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span></div>

<div class="viewcode-block" id="Simulator.close"><a class="viewcode-back" href="../../simulator.html#nengo_dl.simulator.Simulator.close">[docs]</a>    <span class="k">def</span> <span class="nf">close</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Close the simulation, freeing resources.</span>

<span class="sd">        Notes</span>
<span class="sd">        -----</span>
<span class="sd">        The simulation cannot be restarted after it is closed.  This is not a</span>
<span class="sd">        technical limitation, just a design decision made for all Nengo</span>
<span class="sd">        simulators.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">closed</span><span class="p">:</span>
            <span class="c1"># note: we use getattr in case it crashes before the object is</span>
            <span class="c1"># created</span>
            <span class="k">if</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;sess&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">sess</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">sess</span> <span class="o">=</span> <span class="kc">None</span>

            <span class="k">if</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;summary&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">summary</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">closed</span> <span class="o">=</span> <span class="kc">True</span></div>

    <span class="k">def</span> <span class="nf">_fill_feed</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_steps</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">start</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Create a feed dictionary containing values for all the placeholder</span>
<span class="sd">        inputs in the network, which will be passed to ``tf.Session.run``.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        n_steps : int</span>
<span class="sd">            The number of execution steps</span>
<span class="sd">        input_feeds : dict of {:class:`~nengo:nengo.Node`: \</span>
<span class="sd">                               :class:`~numpy:numpy.ndarray`}</span>
<span class="sd">            Override the values of input Nodes with the given data.  Arrays</span>
<span class="sd">            should have shape ``(sim.minibatch_size, n_steps, node.size_out)``.</span>
<span class="sd">        targets : dict of {:class:`~nengo:nengo.Probe`: \</span>
<span class="sd">                           :class:`~numpy:numpy.ndarray`}, optional</span>
<span class="sd">            Values for target placeholders (only necessary if loss is being</span>
<span class="sd">            computed, e.g. when training the network)</span>
<span class="sd">        start : int, optional</span>
<span class="sd">            Initial value of simulator timestep</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        dict of {``tf.Tensor``: :class:`~numpy:numpy.ndarray`}</span>
<span class="sd">            Feed values for placeholder tensors in the network</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c1"># fill in loop variables</span>
        <span class="n">feed_dict</span> <span class="o">=</span> <span class="p">{</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">tensor_graph</span><span class="o">.</span><span class="n">step_var</span><span class="p">:</span> <span class="n">start</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">tensor_graph</span><span class="o">.</span><span class="n">stop_var</span><span class="p">:</span> <span class="n">start</span> <span class="o">+</span> <span class="n">n_steps</span>
        <span class="p">}</span>

        <span class="c1"># fill in input values</span>
        <span class="n">tmp</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_generate_inputs</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">n_steps</span><span class="p">)</span>
        <span class="n">feed_dict</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">tmp</span><span class="p">)</span>

        <span class="c1"># fill in target values</span>
        <span class="k">if</span> <span class="n">targets</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">feed_dict</span><span class="o">.</span><span class="n">update</span><span class="p">(</span>
                <span class="p">{</span><span class="bp">self</span><span class="o">.</span><span class="n">tensor_graph</span><span class="o">.</span><span class="n">target_phs</span><span class="p">[</span><span class="n">p</span><span class="p">]:</span> <span class="n">np</span><span class="o">.</span><span class="n">moveaxis</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
                 <span class="k">for</span> <span class="n">p</span><span class="p">,</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">targets</span><span class="o">.</span><span class="n">items</span><span class="p">()})</span>

        <span class="k">return</span> <span class="n">feed_dict</span>

    <span class="k">def</span> <span class="nf">_generate_inputs</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_feeds</span><span class="p">,</span> <span class="n">n_steps</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Generate inputs for the network (the output values of each Node with</span>
<span class="sd">        no incoming connections).</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        input_feeds : dict of {:class:`~nengo:nengo.Node`: \</span>
<span class="sd">                               :class:`~numpy:numpy.ndarray`}</span>
<span class="sd">            Override the values of input Nodes with the given data.  Arrays</span>
<span class="sd">            should have shape ``(sim.minibatch_size, n_steps, node.size_out)``.</span>
<span class="sd">        n_steps : int</span>
<span class="sd">            Number of simulation timesteps for which to generate input data</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        dict of {:class:`~nengo:nengo.Node`: :class:`~numpy:numpy.ndarray}</span>
<span class="sd">            Simulation values for all the input Nodes in the network.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="n">input_feeds</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">input_feeds</span> <span class="o">=</span> <span class="p">{}</span>

        <span class="n">feed_vals</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">tensor_graph</span><span class="o">.</span><span class="n">invariant_inputs</span><span class="p">:</span>
            <span class="c1"># if the output signal is not in sig map, that means no operators</span>
            <span class="c1"># use the output of this node. similarly, if node.size_out is 0,</span>
            <span class="c1"># the node isn&#39;t producing any output values.</span>
            <span class="n">using_output</span> <span class="o">=</span> <span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">sig</span><span class="p">[</span><span class="n">n</span><span class="p">][</span><span class="s2">&quot;out&quot;</span><span class="p">]</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">tensor_graph</span><span class="o">.</span><span class="n">sig_map</span> <span class="ow">and</span>
                <span class="n">n</span><span class="o">.</span><span class="n">size_out</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span>

            <span class="k">if</span> <span class="p">(</span><span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">n</span><span class="o">.</span><span class="n">output</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="ow">and</span>
                    <span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">n</span><span class="o">.</span><span class="n">output</span><span class="p">)</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_funcs</span><span class="p">):</span>
                <span class="c1"># note: we include n.output in the input_funcs hash to handle</span>
                <span class="c1"># the case where the node output is changed after the model</span>
                <span class="c1"># is constructed.  this isn&#39;t technically supported behaviour</span>
                <span class="c1"># in nengo, but the gui does it.</span>

                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">n</span><span class="o">.</span><span class="n">output</span><span class="p">,</span> <span class="n">Process</span><span class="p">):</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">input_funcs</span><span class="p">[(</span><span class="n">n</span><span class="p">,</span> <span class="n">n</span><span class="o">.</span><span class="n">output</span><span class="p">)]</span> <span class="o">=</span> <span class="p">[</span>
                        <span class="n">n</span><span class="o">.</span><span class="n">output</span><span class="o">.</span><span class="n">make_step</span><span class="p">(</span>
                            <span class="p">(</span><span class="n">n</span><span class="o">.</span><span class="n">size_in</span><span class="p">,),</span> <span class="p">(</span><span class="n">n</span><span class="o">.</span><span class="n">size_out</span><span class="p">,),</span> <span class="bp">self</span><span class="o">.</span><span class="n">dt</span><span class="p">,</span>
                            <span class="n">n</span><span class="o">.</span><span class="n">output</span><span class="o">.</span><span class="n">get_rng</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">rng</span><span class="p">))</span>
                        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">minibatch_size</span><span class="p">)]</span>
                <span class="k">elif</span> <span class="n">n</span><span class="o">.</span><span class="n">size_out</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">input_funcs</span><span class="p">[(</span><span class="n">n</span><span class="p">,</span> <span class="n">n</span><span class="o">.</span><span class="n">output</span><span class="p">)]</span> <span class="o">=</span> <span class="p">[</span><span class="n">utils</span><span class="o">.</span><span class="n">align_func</span><span class="p">(</span>
                        <span class="p">(</span><span class="n">n</span><span class="o">.</span><span class="n">size_out</span><span class="p">,),</span> <span class="bp">self</span><span class="o">.</span><span class="n">tensor_graph</span><span class="o">.</span><span class="n">dtype</span><span class="p">)(</span><span class="n">n</span><span class="o">.</span><span class="n">output</span><span class="p">)]</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="c1"># a node with no inputs and no outputs, but it can still</span>
                    <span class="c1"># have side effects</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">input_funcs</span><span class="p">[(</span><span class="n">n</span><span class="p">,</span> <span class="n">n</span><span class="o">.</span><span class="n">output</span><span class="p">)]</span> <span class="o">=</span> <span class="p">[</span><span class="n">n</span><span class="o">.</span><span class="n">output</span><span class="p">]</span>

            <span class="k">if</span> <span class="n">using_output</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">n</span> <span class="ow">in</span> <span class="n">input_feeds</span><span class="p">:</span>
                    <span class="c1"># move minibatch dimension to the end</span>
                    <span class="n">feed_val</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">moveaxis</span><span class="p">(</span><span class="n">input_feeds</span><span class="p">[</span><span class="n">n</span><span class="p">],</span> <span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
                <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">n</span><span class="o">.</span><span class="n">output</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
                    <span class="n">feed_val</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">tile</span><span class="p">(</span><span class="n">n</span><span class="o">.</span><span class="n">output</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="p">:,</span> <span class="kc">None</span><span class="p">],</span>
                                       <span class="p">(</span><span class="n">n_steps</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">minibatch_size</span><span class="p">))</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">feed_val</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span>
                        <span class="p">(</span><span class="n">n_steps</span><span class="p">,</span> <span class="n">n</span><span class="o">.</span><span class="n">size_out</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">minibatch_size</span><span class="p">),</span>
                        <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tensor_graph</span><span class="o">.</span><span class="n">dtype</span><span class="o">.</span><span class="n">as_numpy_dtype</span><span class="p">)</span>

                    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_steps</span><span class="p">):</span>
                        <span class="c1"># note: need to copy the output of func, as func</span>
                        <span class="c1"># may mutate its outputs in-place on subsequent calls</span>
                        <span class="n">feed_val</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">transpose</span><span class="p">([</span>
                            <span class="n">func</span><span class="p">((</span><span class="n">i</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_steps</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">dt</span><span class="p">)</span>
                            <span class="k">for</span> <span class="n">func</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_funcs</span><span class="p">[(</span><span class="n">n</span><span class="p">,</span> <span class="n">n</span><span class="o">.</span><span class="n">output</span><span class="p">)]])</span>

                <span class="n">feed_vals</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">tensor_graph</span><span class="o">.</span><span class="n">invariant_ph</span><span class="p">[</span><span class="n">n</span><span class="p">]]</span> <span class="o">=</span> <span class="n">feed_val</span>
            <span class="k">elif</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">n</span><span class="o">.</span><span class="n">output</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
                <span class="c1"># note: we still call the function even if the output</span>
                <span class="c1"># is not being used, because it may have side-effects</span>
                <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_steps</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_steps</span> <span class="o">+</span> <span class="n">n_steps</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
                    <span class="k">for</span> <span class="n">func</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_funcs</span><span class="p">[(</span><span class="n">n</span><span class="p">,</span> <span class="n">n</span><span class="o">.</span><span class="n">output</span><span class="p">)]:</span>
                        <span class="n">func</span><span class="p">(</span><span class="n">i</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">dt</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">feed_vals</span>

    <span class="k">def</span> <span class="nf">_update_probe_data</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">probe_data</span><span class="p">,</span> <span class="n">start</span><span class="p">,</span> <span class="n">n_steps</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Updates the stored probe data (since the last reset) with the data</span>
<span class="sd">        from the latest run.</span>

<span class="sd">        Downsamples the probe data returned from tensorflow (from every</span>
<span class="sd">        simulation timestep) according to probe `sample_every` and the number</span>
<span class="sd">        of steps run.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        probe_data : list of `np.ndarray`</span>
<span class="sd">            Probe data from every timestep</span>
<span class="sd">        start : int</span>
<span class="sd">            The simulation timestep at which probe data starts</span>
<span class="sd">        n_steps : int</span>
<span class="sd">            The number of timesteps over which we want to collect data</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c1"># remove any extra timesteps (due to `unroll_simulation` mismatch)</span>
        <span class="n">probe_data</span> <span class="o">=</span> <span class="p">[</span><span class="n">p</span><span class="p">[:</span><span class="n">n_steps</span><span class="p">]</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">probe_data</span><span class="p">]</span>

        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">p</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">probes</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">sample_every</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="c1"># downsample probe according to `sample_every`</span>
                <span class="n">period</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">sample_every</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">dt</span>
                <span class="n">steps</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">start</span><span class="p">,</span> <span class="n">start</span> <span class="o">+</span> <span class="n">n_steps</span><span class="p">)</span>
                <span class="n">probe_data</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">probe_data</span><span class="p">[</span><span class="n">i</span><span class="p">][(</span><span class="n">steps</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="n">period</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">]</span>

            <span class="c1"># update stored probe data</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="n">p</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">probe_data</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>

    <span class="k">def</span> <span class="nf">_check_data</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;input&quot;</span><span class="p">,</span> <span class="n">n_batch</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">n_steps</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Performs error checking on simulation data.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        data : dict of {:class:`~nengo:nengo.Node` or \</span>
<span class="sd">                            :class:`~nengo:nengo.Probe`: \</span>
<span class="sd">                        :class:`~numpy:numpy.ndarray`}</span>
<span class="sd">            Array of data associated with given objects in model (Nodes if</span>
<span class="sd">            mode==&quot;input&quot; or Probes if mode==&quot;target&quot;)</span>
<span class="sd">        mode : &quot;input&quot; or &quot;target&quot;, optional</span>
<span class="sd">            Whether this data corresponds to an input or target value</span>
<span class="sd">        n_batch : int, optional</span>
<span class="sd">            Number of elements in batch (if None, will just verify that all</span>
<span class="sd">            data items have same batch size)</span>
<span class="sd">        n_steps : int, optional</span>
<span class="sd">            Number of simulation steps (if None, will just verify that all</span>
<span class="sd">            data items have same number of steps)</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="n">data</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">mode</span> <span class="o">==</span> <span class="s2">&quot;input&quot;</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">d</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">tensor_graph</span><span class="o">.</span><span class="n">invariant_inputs</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="n">ValidationError</span><span class="p">(</span>
                        <span class="s2">&quot;</span><span class="si">%s</span><span class="s2"> is not an input Node (a nengo.Node with &quot;</span>
                        <span class="s2">&quot;size_in==0), or is from a different network.&quot;</span> <span class="o">%</span> <span class="n">d</span><span class="p">,</span>
                        <span class="s2">&quot;</span><span class="si">%s</span><span class="s2"> data&quot;</span> <span class="o">%</span> <span class="n">mode</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">d</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">probes</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="n">ValidationError</span><span class="p">(</span>
                        <span class="s2">&quot;</span><span class="si">%s</span><span class="s2"> is not a Probe, or is from a different &quot;</span>
                        <span class="s2">&quot;network&quot;</span> <span class="o">%</span> <span class="n">d</span><span class="p">,</span> <span class="s2">&quot;</span><span class="si">%s</span><span class="s2"> data&quot;</span> <span class="o">%</span> <span class="n">mode</span><span class="p">)</span>

        <span class="n">args</span> <span class="o">=</span> <span class="p">[</span><span class="n">n_batch</span><span class="p">,</span> <span class="n">n_steps</span><span class="p">]</span>
        <span class="n">labels</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;batch size&quot;</span><span class="p">,</span> <span class="s2">&quot;number of timesteps&quot;</span><span class="p">]</span>

        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">args</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">val</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">values</span><span class="p">()))</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
                <span class="k">for</span> <span class="n">n</span><span class="p">,</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">data</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                    <span class="k">if</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">!=</span> <span class="n">val</span><span class="p">:</span>
                        <span class="k">raise</span> <span class="n">ValidationError</span><span class="p">(</span>
                            <span class="s2">&quot;Elements have different </span><span class="si">%s</span><span class="s2">: </span><span class="si">%s</span><span class="s2"> vs </span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span>
                            <span class="p">(</span><span class="n">labels</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">val</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="s2">&quot;</span><span class="si">%s</span><span class="s2"> data&quot;</span> <span class="o">%</span> <span class="n">mode</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">for</span> <span class="n">n</span><span class="p">,</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">data</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                    <span class="k">if</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">!=</span> <span class="n">args</span><span class="p">[</span><span class="n">i</span><span class="p">]:</span>
                        <span class="k">raise</span> <span class="n">ValidationError</span><span class="p">(</span>
                            <span class="s2">&quot;Data for </span><span class="si">%s</span><span class="s2"> has </span><span class="si">%s</span><span class="s2">=</span><span class="si">%s</span><span class="s2">, which does not match &quot;</span>
                            <span class="s2">&quot;expected size </span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">labels</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="n">i</span><span class="p">],</span>
                                                  <span class="n">args</span><span class="p">[</span><span class="n">i</span><span class="p">]),</span>
                            <span class="s2">&quot;</span><span class="si">%s</span><span class="s2"> data&quot;</span> <span class="o">%</span> <span class="n">mode</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">n</span><span class="p">,</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">data</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="k">if</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">minibatch_size</span><span class="p">:</span>
                <span class="k">raise</span> <span class="n">ValidationError</span><span class="p">(</span>
                    <span class="s2">&quot;Size of minibatch (</span><span class="si">%d</span><span class="s2">) for </span><span class="si">%s</span><span class="s2"> data less than Simulation &quot;</span>
                    <span class="s2">&quot;`minibatch_size` (</span><span class="si">%d</span><span class="s2">)&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">n</span><span class="p">,</span>
                                               <span class="bp">self</span><span class="o">.</span><span class="n">minibatch_size</span><span class="p">),</span>
                    <span class="s2">&quot;</span><span class="si">%s</span><span class="s2"> data&quot;</span> <span class="o">%</span> <span class="n">mode</span><span class="p">)</span>

            <span class="n">d</span> <span class="o">=</span> <span class="n">n</span><span class="o">.</span><span class="n">size_out</span> <span class="k">if</span> <span class="n">mode</span> <span class="o">==</span> <span class="s2">&quot;input&quot;</span> <span class="k">else</span> <span class="n">n</span><span class="o">.</span><span class="n">size_in</span>
            <span class="k">if</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">!=</span> <span class="n">d</span><span class="p">:</span>
                <span class="k">raise</span> <span class="n">ValidationError</span><span class="p">(</span>
                    <span class="s2">&quot;Dimensionality of data (</span><span class="si">%s</span><span class="s2">) does not match &quot;</span>
                    <span class="s2">&quot;dimensionality of </span><span class="si">%s</span><span class="s2"> (</span><span class="si">%s</span><span class="s2">)&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">n</span><span class="p">,</span> <span class="n">d</span><span class="p">),</span>
                    <span class="s2">&quot;</span><span class="si">%s</span><span class="s2"> data&quot;</span> <span class="o">%</span> <span class="n">mode</span><span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">dt</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;(float) The time step of the simulator.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">dt</span>

    <span class="nd">@dt</span><span class="o">.</span><span class="n">setter</span>
    <span class="k">def</span> <span class="nf">dt</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dummy</span><span class="p">):</span>
        <span class="k">raise</span> <span class="n">ReadonlyError</span><span class="p">(</span><span class="n">attr</span><span class="o">=</span><span class="s1">&#39;dt&#39;</span><span class="p">,</span> <span class="n">obj</span><span class="o">=</span><span class="bp">self</span><span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">training_step</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">tensor_graph</span><span class="o">.</span><span class="n">training_step</span>

    <span class="k">def</span> <span class="nf">__enter__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_graph_context</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tensor_graph</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">as_default</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_graph_context</span><span class="o">.</span><span class="fm">__enter__</span><span class="p">()</span>
        <span class="k">return</span> <span class="bp">self</span>

    <span class="k">def</span> <span class="nf">__exit__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_graph_context</span><span class="o">.</span><span class="fm">__exit__</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">__del__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Raise a RuntimeWarning if the Simulator is deallocated while open.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">closed</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">closed</span><span class="p">:</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                <span class="s2">&quot;Simulator with model=</span><span class="si">%s</span><span class="s2"> was deallocated while open. &quot;</span>
                <span class="s2">&quot;Simulators should be closed manually to ensure resources &quot;</span>
                <span class="s2">&quot;are properly freed.&quot;</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="ne">RuntimeWarning</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">close</span><span class="p">()</span></div>


<div class="viewcode-block" id="SimulationData"><a class="viewcode-back" href="../../simulator.html#nengo_dl.simulator.SimulationData">[docs]</a><span class="k">class</span> <span class="nc">SimulationData</span><span class="p">(</span><span class="n">collections</span><span class="o">.</span><span class="n">Mapping</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Data structure used to access simulation data from the model.</span>

<span class="sd">    The main use case for this is to access Probe data; for example,</span>
<span class="sd">    ``probe_data = sim.data[my_probe]``.  However, it is also</span>
<span class="sd">    used to access the parameters of objects in the model; for example, after</span>
<span class="sd">    the model has been optimized via :meth:`.Simulator.train`, the updated</span>
<span class="sd">    encoder values for an ensemble can be accessed via</span>
<span class="sd">    ``trained_encoders = sim.data[my_ens].encoders``.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    sim : :class:`.Simulator`</span>
<span class="sd">        The simulator from which data will be drawn</span>
<span class="sd">    minibatched : bool</span>
<span class="sd">        If False, discard the minibatch dimension on probe data</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    SimulationData shouldn&#39;t be created/accessed directly by the user, but</span>
<span class="sd">    rather via ``sim.data`` (which is an instance of SimulationData).</span>
<span class="sd">    &quot;&quot;&quot;</span>

<div class="viewcode-block" id="SimulationData.__init__"><a class="viewcode-back" href="../../simulator.html#nengo_dl.simulator.SimulationData.__init__">[docs]</a>    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sim</span><span class="p">,</span> <span class="n">minibatched</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sim</span> <span class="o">=</span> <span class="n">sim</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">minibatched</span> <span class="o">=</span> <span class="n">minibatched</span></div>

<div class="viewcode-block" id="SimulationData.__getitem__"><a class="viewcode-back" href="../../simulator.html#nengo_dl.simulator.SimulationData.__getitem__">[docs]</a>    <span class="k">def</span> <span class="nf">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">obj</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Return the data associated with ``obj``.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        obj : :class:`~nengo:nengo.Probe` or :class:`~nengo:nengo.Ensemble` \</span>
<span class="sd">              or :class:`~nengo:nengo.Connection`</span>
<span class="sd">            Object whose simulation data is being accessed</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        :class:`~numpy:numpy.ndarray` or \</span>
<span class="sd">                :class:`~nengo:nengo.builder.ensemble.BuiltEnsemble` or \</span>
<span class="sd">                :class:`~nengo:nengo.builder.connection.BuiltConnection`</span>
<span class="sd">            Array containing probed data if ``obj`` is a</span>
<span class="sd">            :class:`~nengo:nengo.Probe`, otherwise the corresponding</span>
<span class="sd">            parameter object</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="n">obj</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">sim</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">params</span><span class="p">:</span>
            <span class="k">raise</span> <span class="n">ValidationError</span><span class="p">(</span><span class="s2">&quot;Object is not in parameters of model </span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span>
                                  <span class="bp">self</span><span class="o">.</span><span class="n">sim</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="nb">str</span><span class="p">(</span><span class="n">obj</span><span class="p">))</span>

        <span class="n">data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sim</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="n">obj</span><span class="p">]</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="n">Probe</span><span class="p">):</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="k">return</span> <span class="p">[]</span>

            <span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">sim</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">sig</span><span class="p">[</span><span class="n">obj</span><span class="p">][</span><span class="s2">&quot;in&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">minibatched</span><span class="p">:</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">minibatched</span><span class="p">:</span>
                    <span class="c1"># move batch dimension to front</span>
                    <span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">moveaxis</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="c1"># get rid of batch dimension</span>
                    <span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>

            <span class="n">data</span><span class="o">.</span><span class="n">setflags</span><span class="p">(</span><span class="n">write</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="n">Ensemble</span><span class="p">):</span>
            <span class="c1"># get the live simulation values</span>
            <span class="n">scaled_encoders</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_param</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="s2">&quot;scaled_encoders&quot;</span><span class="p">)</span>
            <span class="n">bias</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_param</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="s2">&quot;bias&quot;</span><span class="p">)</span>

            <span class="c1"># infer the related values (rolled into scaled_encoders)</span>
            <span class="n">gain</span> <span class="o">=</span> <span class="p">(</span><span class="n">obj</span><span class="o">.</span><span class="n">radius</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">scaled_encoders</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="o">/</span>
                    <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">encoders</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
            <span class="n">encoders</span> <span class="o">=</span> <span class="n">obj</span><span class="o">.</span><span class="n">radius</span> <span class="o">*</span> <span class="n">scaled_encoders</span> <span class="o">/</span> <span class="n">gain</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">]</span>

            <span class="c1"># figure out max_rates/intercepts from neuron model</span>
            <span class="n">max_rates</span><span class="p">,</span> <span class="n">intercepts</span> <span class="o">=</span> <span class="p">(</span>
                <span class="n">obj</span><span class="o">.</span><span class="n">neuron_type</span><span class="o">.</span><span class="n">max_rates_intercepts</span><span class="p">(</span><span class="n">gain</span><span class="p">,</span> <span class="n">bias</span><span class="p">))</span>

            <span class="n">data</span> <span class="o">=</span> <span class="n">BuiltEnsemble</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">eval_points</span><span class="p">,</span> <span class="n">encoders</span><span class="p">,</span> <span class="n">intercepts</span><span class="p">,</span>
                                 <span class="n">max_rates</span><span class="p">,</span> <span class="n">scaled_encoders</span><span class="p">,</span> <span class="n">gain</span><span class="p">,</span> <span class="n">bias</span><span class="p">)</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="n">Connection</span><span class="p">):</span>
            <span class="c1"># get the live simulation values</span>
            <span class="n">weights</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_param</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="s2">&quot;weights&quot;</span><span class="p">)</span>

            <span class="c1"># impossible to recover transform</span>
            <span class="n">transform</span> <span class="o">=</span> <span class="kc">None</span>

            <span class="n">data</span> <span class="o">=</span> <span class="n">BuiltConnection</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">eval_points</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">solver_info</span><span class="p">,</span> <span class="n">weights</span><span class="p">,</span>
                                   <span class="n">transform</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">data</span></div>

<div class="viewcode-block" id="SimulationData.get_param"><a class="viewcode-back" href="../../simulator.html#nengo_dl.simulator.SimulationData.get_param">[docs]</a>    <span class="k">def</span> <span class="nf">get_param</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">obj</span><span class="p">,</span> <span class="n">attr</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Returns the current parameter value for the given object.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        obj : ``NengoObject``</span>
<span class="sd">            The nengo object for which we want to know the parameters</span>
<span class="sd">        attr : str</span>
<span class="sd">            The parameter of ``obj`` to be returned</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        :class:`~numpy:numpy.ndarray`</span>
<span class="sd">            Current value of the parameters associated with the given object</span>

<span class="sd">        Notes</span>
<span class="sd">        -----</span>
<span class="sd">        Parameter values should be accessed through ``sim.data``</span>
<span class="sd">        (which will call this function if necessary), rather than directly</span>
<span class="sd">        through this function.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">sim</span><span class="o">.</span><span class="n">closed</span><span class="p">:</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="s2">&quot;Checking </span><span class="si">%s</span><span class="s2">.</span><span class="si">%s</span><span class="s2"> after simulator is closed; cannot &quot;</span>
                          <span class="s2">&quot;fetch live value, so the initial value will be &quot;</span>
                          <span class="s2">&quot;returned.&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="n">attr</span><span class="p">))</span>

            <span class="k">return</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">sim</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="n">obj</span><span class="p">],</span> <span class="n">attr</span><span class="p">)</span>

        <span class="n">sig_obj</span><span class="p">,</span> <span class="n">sig_attr</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_attr_map</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="n">attr</span><span class="p">)</span>

        <span class="k">try</span><span class="p">:</span>
            <span class="n">sig</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sim</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">sig</span><span class="p">[</span><span class="n">sig_obj</span><span class="p">][</span><span class="n">sig_attr</span><span class="p">]</span>
        <span class="k">except</span> <span class="ne">KeyError</span><span class="p">:</span>
            <span class="c1"># sig_attr doesn&#39;t exist for this attribute</span>
            <span class="k">return</span> <span class="kc">None</span>

        <span class="k">if</span> <span class="n">sig</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">sim</span><span class="o">.</span><span class="n">tensor_graph</span><span class="o">.</span><span class="n">sig_map</span><span class="p">:</span>
            <span class="c1"># if sig isn&#39;t in sig_map then that means it isn&#39;t used anywhere</span>
            <span class="c1"># in the simulation (and therefore never changes), so we can</span>
            <span class="c1"># safely return the static build value</span>
            <span class="k">return</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">sim</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="n">obj</span><span class="p">],</span> <span class="n">attr</span><span class="p">)</span>

        <span class="n">param</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sim</span><span class="o">.</span><span class="n">tensor_graph</span><span class="o">.</span><span class="n">get_tensor</span><span class="p">(</span><span class="n">sig</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">sim</span><span class="o">.</span><span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">param</span><span class="p">)</span></div>

    <span class="k">def</span> <span class="nf">_attr_map</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">obj</span><span class="p">,</span> <span class="n">attr</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Maps from ``sim.data[obj].attr`` to the equivalent</span>
<span class="sd">        ``model.sig[obj][attr]``.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        obj : ``NengoObject``</span>
<span class="sd">            The nengo object for which we want to know the parameters</span>
<span class="sd">        attr : str</span>
<span class="sd">            The parameter of ``obj`` to be returned</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        obj : ``NengoObject``</span>
<span class="sd">            The nengo object to key into ``model.sig``</span>
<span class="sd">        attr : str</span>
<span class="sd">            The name of the signal corresponding to input attr</span>

<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="n">Ensemble</span><span class="p">)</span> <span class="ow">and</span> <span class="n">attr</span> <span class="o">==</span> <span class="s2">&quot;bias&quot;</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">obj</span><span class="o">.</span><span class="n">neurons</span><span class="p">,</span> <span class="n">attr</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="n">Ensemble</span><span class="p">)</span> <span class="ow">and</span> <span class="n">attr</span> <span class="o">==</span> <span class="s2">&quot;scaled_encoders&quot;</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">obj</span><span class="p">,</span> <span class="s2">&quot;encoders&quot;</span>

        <span class="k">return</span> <span class="n">obj</span><span class="p">,</span> <span class="n">attr</span>

    <span class="k">def</span> <span class="nf">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">sim</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">params</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">__iter__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">iter</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">sim</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">params</span><span class="p">)</span></div>
</pre></div>

           </div>
           
          </div>
          <footer>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2015, Applied Brain Research.
      Last updated on Jun 14, 2018.

    </p>
  </div> 

</footer>

        </div>
      </div>

    </section>

  </div>
  <!-- adapted from sphinx_rtd_theme versions.html -->

<div class="rst-versions" data-toggle="rst-versions" role="note" aria-label="versions">
    <span class="rst-current-version" data-toggle="rst-current-version">
        <span class="fa fa-book"> Versions</span>
        v0.6.0
        <span class="fa fa-caret-down"></span>
    </span>
    <div class="rst-other-versions">
        <dl>
            
            
                <dd><a href="../../../_modules/nengo_dl/simulator.html">latest</a></dd>
            

            
                
                    <dd><a href="../../../v1.0.0/_modules/nengo_dl/simulator.html">v1.0.0</a></dd>
                
            
                
                    <dd><a href="../../../v0.6.2/_modules/nengo_dl/simulator.html">v0.6.2</a></dd>
                
            
                
                    <dd><a href="../../../v0.6.1/_modules/nengo_dl/simulator.html">v0.6.1</a></dd>
                
            
                
                    <dd>v0.6.0</dd>
                
            
                
                    <dd><a href="../../../v0.5.2/_modules/nengo_dl/simulator.html">v0.5.2</a></dd>
                
            
                
                    <dd><a href="../../../v0.5.1/_modules/nengo_dl/simulator.html">v0.5.1</a></dd>
                
            
                
                    <dd><a href="../../../v0.5.0/_modules/nengo_dl/simulator.html">v0.5.0</a></dd>
                
            
                
                    <dd><a href="../../../v0.4.0/_modules/nengo_dl/simulator.html">v0.4.0</a></dd>
                
            
                
                    <dd><a href="../../../v0.3.1/_modules/nengo_dl/simulator.html">v0.3.1</a></dd>
                
            
                
                    <dd><a href="../../../v0.3.0/_modules/nengo_dl/simulator.html">v0.3.0</a></dd>
                
            
                
                    <dd><a href="../../../v0.2.0/_modules/nengo_dl/simulator.html">v0.2.0</a></dd>
                
            
                
                    <dd><a href="../../..//_modules/nengo_dl/simulator.html"></a></dd>
                
            
        </dl>
    </div>
</div>

  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'../../',
            VERSION:'0.6.0',
            LANGUAGE:'None',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true,
            SOURCELINK_SUFFIX: '.txt'
        };
    </script>
      <script type="text/javascript" src="../../_static/jquery.js"></script>
      <script type="text/javascript" src="../../_static/underscore.js"></script>
      <script type="text/javascript" src="../../_static/doctools.js"></script>
      <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

  

  
  
    <script type="text/javascript" src="../../_static/js/theme.js"></script>
  

  <script type="text/javascript">
      jQuery(function () {
          
          SphinxRtdTheme.Navigation.enableSticky();
          
      });
  </script> 

</body>
</html>