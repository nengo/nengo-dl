
<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta charset="utf-8" />
    <title>nengo_dl.tensor_graph &#8212; NengoDL 3.2.0 docs</title>
    <link rel="stylesheet" href="../../_static/basic.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
<link href="https://fonts.googleapis.com/css?family=IBM+Plex+Sans:400,400i,600|Rajdhani:700&display=swap" rel="stylesheet">
<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.8.2/css/all.css" integrity="sha384-oS3vJWv+0UjzBfQzYUhtDYW+Pj2yciDJxpsK1OYPAYjqT085Qq/1cq5FLXAZQ7Ay" crossorigin="anonymous">
<link rel="stylesheet" href="https://www.nengo.ai/css/bootstrap.css" type="text/css">
<style>
  body .title-bar,
  body .documentation-source h1:after {
    background-color: #ff6600;
  }
</style>

<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-GT8XEDLTMJ"></script>
<script>
 window.dataLayer = window.dataLayer || [];
 function gtag(){dataLayer.push(arguments);}
 gtag('js', new Date());
 gtag('config', 'G-GT8XEDLTMJ');
</script>
<!-- End Google tag (gtag.js) -->

<!-- Matomo -->
<script>
 var _paq = window._paq = window._paq || [];
 _paq.push(["setDocumentTitle", document.domain + "/" + document.title]);
 _paq.push(["setCookieDomain", "*.appliedbrainresearch.com"]);
 _paq.push(["setDomains", ["*.appliedbrainresearch.com","*.edge.nengo.ai","*.forum.nengo.ai","*.labs.nengo.ai","*.nengo.ai"]]);
 _paq.push(["enableCrossDomainLinking"]);
 _paq.push(["setDoNotTrack", true]);
 _paq.push(['trackPageView']);
 _paq.push(['enableLinkTracking']);
 (function() {
   var u="https://appliedbrainresearch.matomo.cloud/";
   _paq.push(['setTrackerUrl', u+'matomo.php']);
   _paq.push(['setSiteId', '3']);
   var d=document, g=d.createElement('script'), s=d.getElementsByTagName('script')[0];
   g.async=true; g.src='//cdn.matomo.cloud/appliedbrainresearch.matomo.cloud/matomo.js'; s.parentNode.insertBefore(g,s);
 })();
</script>
<!-- End Matomo Code -->
<script src="https://code.jquery.com/jquery-3.3.1.min.js" integrity="sha256-FgpCb/KJQlLNfOu91ta32o/NMZxltwRo8QtmkMRdAu8=" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.3/umd/popper.min.js" integrity="sha384-ZMP7rVo3mIykV+2+9J3UJ46jBk0WLaUAdn689aCwoqbBJiSnjAK/l8WvCWPIPm49" crossorigin="anonymous"></script>
<script src="https://unpkg.com/scrollreveal"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/stickyfill/2.1.0/stickyfill.min.js"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.1.1/js/bootstrap.min.js" integrity="sha384-smHYKdLADwkXOn1EmN1qk/HfnUcbVRZyYmZ4qpPea6sjB/pTJ0euyQp0Mk8ck+5T" crossorigin="anonymous"></script>
<!-- From basic/layout.html -->
<script type="text/javascript" id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
  
  
<script src="../../_static/underscore.js"></script>
  
  
<script src="../../_static/doctools.js"></script>
  
  
<script src="../../_static/language_data.js"></script>
  
  
<script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
  
  
<script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
  
  
<script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true, "ignoreClass": "document", "processClass": "math|output_area"}})</script>
  
    <link rel="shortcut icon" href="../../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
<meta name="viewport" content="width=device-width, initial-scale=1, viewport-fit=cover">

  </head><body class="bg-dark">

<header class="fixed-top header-top shadow-sm">
  <nav class="navbar navbar-expand-md navbar-light bg-white">
    <a class="navbar-brand" href="https://www.nengo.ai/">
      <img
        src="https://www.nengo.ai/design/_images/general-full-light.svg"
        alt="Nengo"
        class="logo"
      />
    </a>
    <button
      class="navbar-toggler"
      type="button"
      data-toggle="collapse"
      data-target="#navbar-collapse"
      aria-controls="navbar-collapse"
      aria-expanded="false"
      aria-label="Toggle navigation"
    >
      <span class="navbar-toggler-icon"></span>
    </button>
    <div class="collapse navbar-collapse" id="navbar-collapse">
      <ul class="navbar-nav ml-auto">
        <li class="nav-item">
          <a class="nav-link" href="https://www.nengo.ai/">What is Nengo?</a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="https://www.nengo.ai/examples/">Examples</a>
        </li>
        <li class="nav-item dropdown active">
          <a
            class="nav-link dropdown-toggle"
            id="navbar-dropdown-docs"
            data-toggle="dropdown"
            aria-haspopup="true"
            aria-expanded="false"
            href="#"
            >Documentation</a
          >
          <div
            class="dropdown-menu shadow-lg border-0"
            aria-labelledby="navbar-dropdown-docs"
          >
            
            <a class="dropdown-item" href="https://www.nengo.ai/nengo/">Nengo Core</a>
            <a class="dropdown-item" href="https://github.com/nengo/nengo-gui/">Nengo GUI</a>
            <a class="dropdown-item" href="https://www.nengo.ai/nengo-dl/">Nengo DL</a>
            <div class="dropdown-divider"></div>
            <a class="dropdown-item" href="https://www.nengo.ai/nengo-spa/">Nengo SPA</a>
            <a class="dropdown-item" href="https://www.nengo.ai/nengo-extras/">Nengo Extras</a>
            <a class="dropdown-item" href="https://arvoelke.github.io/nengolib-docs/">Nengolib</a>
            <div class="dropdown-divider"></div>
            <a class="dropdown-item" href="https://www.nengo.ai/nengo-fpga/">Nengo FPGA</a>
            <a class="dropdown-item" href="https://www.nengo.ai/nengo-loihi/">Nengo Loihi</a>
            <a class="dropdown-item" href="https://github.com/nengo/nengo-ocl">Nengo OpenCL</a>
            <a class="dropdown-item" href="https://github.com/project-rig/nengo_spinnaker">Nengo SpiNNaker</a>
            <a class="dropdown-item" href="https://github.com/nengo/nengo-mpi">Nengo MPI</a>
            <div class="dropdown-divider"></div>
            <a class="dropdown-item" href="https://www.nengo.ai/documentation/"
              >All documentation</a
            >
          </div>
        </li>
        <li class="nav-item dropdown">
          <a
            class="nav-link dropdown-toggle"
            id="navbar-dropdown-community"
            data-toggle="dropdown"
            aria-haspopup="true"
            aria-expanded="false"
            href="#"
            >Community</a
          >
          <div
            class="dropdown-menu shadow-lg border-0"
            aria-labelledby="navbar-dropdown-community"
          >
            <a class="dropdown-item" href="https://forum.nengo.ai">Forum</a>
            <div class="dropdown-divider"></div>
            <a class="dropdown-item" href="https://www.nengo.ai/people/"
              >People</a
            >
            <a class="dropdown-item" href="https://www.nengo.ai/summer-school/"
              >Summer school</a
            >
            <a class="dropdown-item" href="https://www.nengo.ai/contributing/"
              >Contributing</a
            >
            <a class="dropdown-item" href="https://www.nengo.ai/publications/"
              >Publications</a
            >
            <a class="dropdown-item" href="https://www.nengo.ai/videos/"
              >Videos</a
            >
            <a class="dropdown-item" href="https://www.nengo.ai/conduct/"
              >Code of conduct</a
            >
            <a class="dropdown-item" href="https://www.nengo.ai/caa/">CAA</a>
          </div>
        </li>
        <li class="nav-item">
          <a
            class="nav-link btn btn-success btn-sm text-white"
            href="https://www.nengo.ai/getting-started/"
            >Getting started</a
          >
        </li>
      </ul>
    </div>
  </nav>
</header>
<div class="main-content gradient-top">
  <div class="container-fluid">
    <div class="row"><a class="toggle-sidenav d-block d-md-none" href="#"
  ><i class="icon-close fa fa-fw fa-arrow-left"></i
  ><i class="icon-open fa fa-fw fa-arrow-right"></i
></a>
<div role="complementary" class="sidenav col-4 col-xl-3 p-0 border-right">
  <h3 class="pt-5 px-5">
    <a href="../../index.html">
      <img
        class="img-fluid documentation-image"
        src="https://www.nengo.ai/design/_images/nengo-dl-full-light.svg"
        alt="NengoDL"
      />
    </a>
  </h3>
  
  <form class="px-5 pb-5 mb-0 mt-3 border-bottom">
    <div class="form-group">
      <label class="text-gray">Version:</label>
      <select class="custom-select" onchange="switchVersion(this);">
        
        
        <option value="../../../_modules/nengo_dl/tensor_graph.html">latest</option>
        
        
          
        <option selected>v3.2.0</option>
          
        
          
        <option value="../../../v3.1.0/_modules/nengo_dl/tensor_graph.html">
          v3.1.0
        </option>
          
        
          
        <option value="../../../v3.0.0/_modules/nengo_dl/tensor_graph.html">
          v3.0.0
        </option>
          
        
          
        <option value="../../../v2.2.2/_modules/nengo_dl/tensor_graph.html">
          v2.2.2
        </option>
          
        
          
        <option value="../../../v2.2.1/_modules/nengo_dl/tensor_graph.html">
          v2.2.1
        </option>
          
        
          
        <option value="../../../v2.2.0/_modules/nengo_dl/tensor_graph.html">
          v2.2.0
        </option>
          
        
          
        <option value="../../../v2.1.1/_modules/nengo_dl/tensor_graph.html">
          v2.1.1
        </option>
          
        
          
        <option value="../../../v2.1.0/_modules/nengo_dl/tensor_graph.html">
          v2.1.0
        </option>
          
        
          
        <option value="../../../v2.0.0/_modules/nengo_dl/tensor_graph.html">
          v2.0.0
        </option>
          
        
          
        <option value="../../../v1.2.1/_modules/nengo_dl/tensor_graph.html">
          v1.2.1
        </option>
          
        
          
        <option value="../../../v1.2.0/_modules/nengo_dl/tensor_graph.html">
          v1.2.0
        </option>
          
        
          
        <option value="../../../v1.1.0/_modules/nengo_dl/tensor_graph.html">
          v1.1.0
        </option>
          
        
          
        <option value="../../../v1.0.0/_modules/nengo_dl/tensor_graph.html">
          v1.0.0
        </option>
          
        
          
        <option value="../../../v0.6.2/_modules/nengo_dl/tensor_graph.html">
          v0.6.2
        </option>
          
        
          
        <option value="../../../v0.6.1/_modules/nengo_dl/tensor_graph.html">
          v0.6.1
        </option>
          
        
          
        <option value="../../../v0.6.0/_modules/nengo_dl/tensor_graph.html">
          v0.6.0
        </option>
          
        
          
        <option value="../../../v0.5.2/_modules/nengo_dl/tensor_graph.html">
          v0.5.2
        </option>
          
        
          
        <option value="../../../v0.5.1/_modules/nengo_dl/tensor_graph.html">
          v0.5.1
        </option>
          
        
          
        <option value="../../../v0.5.0/_modules/nengo_dl/tensor_graph.html">
          v0.5.0
        </option>
          
        
          
        <option value="../../../v0.4.0/_modules/nengo_dl/tensor_graph.html">
          v0.4.0
        </option>
          
        
          
        <option value="../../../v0.3.1/_modules/nengo_dl/tensor_graph.html">
          v0.3.1
        </option>
          
        
          
        <option value="../../../v0.3.0/_modules/nengo_dl/tensor_graph.html">
          v0.3.0
        </option>
          
        
          
        <option value="../../../v0.2.0/_modules/nengo_dl/tensor_graph.html">
          v0.2.0
        </option>
          
        
      </select>
    </div>
  </form>
  
  <div class="p-5 toctree">
    <ul>
<li class="toctree-l1"><a class="reference internal" href="../../introduction.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../user-guide.html">User guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../reference.html">API reference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../examples.html">Examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../resources.html">Additional resources</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../project.html">Project information</a></li>
</ul>

  </div>
<form class="p-5 my-0 border-top" action="../../search.html" method="get">
  <div class="form-group form-group-single">
    <input type="text" name="q" class="form-control" placeholder="Search" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
    <button type="submit" class="btn btn-link">
      <img src="https://www.nengo.ai/img/icon-search.svg" alt="Go" />
    </button>
  </div>
</form></div>
      

      <div class="col-12 col-md-8 col-xl-9">
        <div class="container">
          <div class="row">
            <div class="col-10 offset-1 pb-5 documentation-source" role="main">
              
  <h1>Source code for nengo_dl.tensor_graph</h1><div class="highlight"><pre>
<span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">Manages the data and build processes associated with implementing a Nengo simulation</span>
<span class="sd">in TensorFlow.</span>
<span class="sd">&quot;&quot;&quot;</span>

<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">OrderedDict</span><span class="p">,</span> <span class="n">defaultdict</span>
<span class="kn">import</span> <span class="nn">logging</span>
<span class="kn">import</span> <span class="nn">warnings</span>

<span class="kn">from</span> <span class="nn">nengo</span> <span class="kn">import</span> <span class="n">Connection</span><span class="p">,</span> <span class="n">Process</span>
<span class="kn">from</span> <span class="nn">nengo.builder.neurons</span> <span class="kn">import</span> <span class="n">SimNeurons</span>
<span class="kn">from</span> <span class="nn">nengo.builder.operator</span> <span class="kn">import</span> <span class="n">Reset</span><span class="p">,</span> <span class="n">SimPyFunc</span><span class="p">,</span> <span class="n">TimeUpdate</span>
<span class="kn">from</span> <span class="nn">nengo.builder.processes</span> <span class="kn">import</span> <span class="n">SimProcess</span>
<span class="kn">from</span> <span class="nn">nengo.config</span> <span class="kn">import</span> <span class="n">ConfigError</span>
<span class="kn">from</span> <span class="nn">nengo.exceptions</span> <span class="kn">import</span> <span class="n">BuildError</span>
<span class="kn">from</span> <span class="nn">nengo.neurons</span> <span class="kn">import</span> <span class="n">Direct</span>
<span class="kn">from</span> <span class="nn">nengo.synapses</span> <span class="kn">import</span> <span class="n">Lowpass</span>
<span class="kn">from</span> <span class="nn">nengo.transforms</span> <span class="kn">import</span> <span class="n">SparseMatrix</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.eager</span> <span class="kn">import</span> <span class="n">context</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.training.tracking</span> <span class="kn">import</span> <span class="n">base</span> <span class="k">as</span> <span class="n">trackable</span>

<span class="kn">from</span> <span class="nn">nengo_dl</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">builder</span><span class="p">,</span>
    <span class="n">config</span><span class="p">,</span>
    <span class="n">compat</span><span class="p">,</span>
    <span class="n">graph_optimizer</span><span class="p">,</span>
    <span class="n">tensor_node</span><span class="p">,</span>
    <span class="n">signals</span><span class="p">,</span>
    <span class="n">utils</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">logger</span> <span class="o">=</span> <span class="n">logging</span><span class="o">.</span><span class="n">getLogger</span><span class="p">(</span><span class="vm">__name__</span><span class="p">)</span>


<div class="viewcode-block" id="TensorGraph"><a class="viewcode-back" href="../../reference.html#nengo_dl.tensor_graph.TensorGraph">[docs]</a><span class="k">class</span> <span class="nc">TensorGraph</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Layer</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Implement the Nengo simulation as a Keras Layer.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    model : `~nengo.builder.Model`</span>
<span class="sd">        Pre-built Nengo model describing the network to be simulated.</span>
<span class="sd">    dt : float</span>
<span class="sd">        Length of a simulator timestep, in seconds.</span>
<span class="sd">    unroll_simulation : int</span>
<span class="sd">        Unroll simulation loop by explicitly building ``unroll_simulation``</span>
<span class="sd">        iterations into the computation graph.</span>
<span class="sd">    minibatch_size : int</span>
<span class="sd">        The number of simultaneous inputs that will be passed through the</span>
<span class="sd">        network.</span>
<span class="sd">    device : None or ``&quot;/cpu:0&quot;`` or ``&quot;/gpu:[0-n]&quot;``</span>
<span class="sd">        Device on which to execute computations (if None then uses the</span>
<span class="sd">        default device as determined by TensorFlow).</span>
<span class="sd">    progress : `.utils.ProgressBar`</span>
<span class="sd">        Progress bar for optimization stage.</span>
<span class="sd">    seed : int</span>
<span class="sd">        Seed for random number generation.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@trackable</span><span class="o">.</span><span class="n">no_automatic_dependency_tracking</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">dt</span><span class="p">,</span> <span class="n">unroll_simulation</span><span class="p">,</span> <span class="n">minibatch_size</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">progress</span><span class="p">,</span> <span class="n">seed</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">name</span><span class="o">=</span><span class="s2">&quot;TensorGraph&quot;</span><span class="p">,</span>
            <span class="n">dynamic</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="n">trainable</span><span class="o">=</span><span class="ow">not</span> <span class="n">config</span><span class="o">.</span><span class="n">get_setting</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="s2">&quot;inference_only&quot;</span><span class="p">,</span> <span class="kc">False</span><span class="p">),</span>
            <span class="n">dtype</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">get_setting</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="s2">&quot;dtype&quot;</span><span class="p">,</span> <span class="s2">&quot;float32&quot;</span><span class="p">),</span>
            <span class="n">batch_size</span><span class="o">=</span><span class="n">minibatch_size</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dt</span> <span class="o">=</span> <span class="n">dt</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">unroll</span> <span class="o">=</span> <span class="n">unroll_simulation</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">use_loop</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">get_setting</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="s2">&quot;use_loop&quot;</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">minibatch_size</span> <span class="o">=</span> <span class="n">minibatch_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="n">device</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">seed</span> <span class="o">=</span> <span class="n">seed</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">inference_only</span> <span class="o">=</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">trainable</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">signals</span> <span class="o">=</span> <span class="n">signals</span><span class="o">.</span><span class="n">SignalDict</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">minibatch_size</span><span class="p">)</span>

        <span class="c1"># find invariant inputs (nodes that don&#39;t receive any input other</span>
        <span class="c1"># than the simulation time). we&#39;ll compute these outside the simulation</span>
        <span class="c1"># and feed in the result.</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">toplevel</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">invariant_inputs</span> <span class="o">=</span> <span class="n">OrderedDict</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">invariant_inputs</span> <span class="o">=</span> <span class="n">OrderedDict</span><span class="p">(</span>
                <span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">n</span><span class="o">.</span><span class="n">output</span><span class="p">)</span>
                <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">toplevel</span><span class="o">.</span><span class="n">all_nodes</span>
                <span class="k">if</span> <span class="n">n</span><span class="o">.</span><span class="n">size_in</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">and</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">tensor_node</span><span class="o">.</span><span class="n">TensorNode</span><span class="p">)</span>
            <span class="p">)</span>

        <span class="c1"># remove input nodes because they are executed outside the simulation</span>
        <span class="n">node_processes</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">n</span><span class="o">.</span><span class="n">output</span> <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">invariant_inputs</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">n</span><span class="o">.</span><span class="n">output</span><span class="p">,</span> <span class="n">Process</span><span class="p">)</span>
        <span class="p">]</span>
        <span class="n">operators</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">op</span>
            <span class="k">for</span> <span class="n">op</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">operators</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span>
                <span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">op</span><span class="p">,</span> <span class="n">SimPyFunc</span><span class="p">)</span> <span class="ow">and</span> <span class="n">op</span><span class="o">.</span><span class="n">x</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">)</span>
                <span class="ow">or</span> <span class="p">(</span>
                    <span class="nb">isinstance</span><span class="p">(</span><span class="n">op</span><span class="p">,</span> <span class="n">SimProcess</span><span class="p">)</span>
                    <span class="ow">and</span> <span class="n">op</span><span class="o">.</span><span class="n">input</span> <span class="ow">is</span> <span class="kc">None</span>
                    <span class="ow">and</span> <span class="n">op</span><span class="o">.</span><span class="n">process</span> <span class="ow">in</span> <span class="n">node_processes</span>
                <span class="p">)</span>
            <span class="p">)</span>
        <span class="p">]</span>

        <span class="c1"># mark trainable signals</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mark_signals</span><span class="p">()</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Initial plan length: </span><span class="si">%d</span><span class="s2">&quot;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">operators</span><span class="p">))</span>

        <span class="c1"># apply graph simplification functions</span>
        <span class="n">simplifications</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">get_setting</span><span class="p">(</span>
            <span class="n">model</span><span class="p">,</span> <span class="s2">&quot;simplifications&quot;</span><span class="p">,</span> <span class="n">graph_optimizer</span><span class="o">.</span><span class="n">default_simplifications</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="k">with</span> <span class="n">progress</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="s2">&quot;operator simplificaton&quot;</span><span class="p">,</span> <span class="n">max_value</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
            <span class="n">old_operators</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">while</span> <span class="nb">len</span><span class="p">(</span><span class="n">old_operators</span><span class="p">)</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="n">operators</span><span class="p">)</span> <span class="ow">or</span> <span class="nb">any</span><span class="p">(</span>
                <span class="n">x</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">y</span> <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">operators</span><span class="p">,</span> <span class="n">old_operators</span><span class="p">)</span>
            <span class="p">):</span>
                <span class="n">old_operators</span> <span class="o">=</span> <span class="n">operators</span>
                <span class="k">for</span> <span class="n">simp</span> <span class="ow">in</span> <span class="n">simplifications</span><span class="p">:</span>
                    <span class="n">operators</span> <span class="o">=</span> <span class="n">simp</span><span class="p">(</span><span class="n">operators</span><span class="p">)</span>

        <span class="c1"># group mergeable operators</span>
        <span class="n">planner</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">get_setting</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="s2">&quot;planner&quot;</span><span class="p">,</span> <span class="n">graph_optimizer</span><span class="o">.</span><span class="n">tree_planner</span><span class="p">)</span>

        <span class="k">with</span> <span class="n">progress</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="s2">&quot;merging operators&quot;</span><span class="p">,</span> <span class="n">max_value</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
            <span class="n">plan</span> <span class="o">=</span> <span class="n">planner</span><span class="p">(</span><span class="n">operators</span><span class="p">)</span>

        <span class="c1"># TODO: we could also merge operators sequentially (e.g., combine</span>
        <span class="c1"># a copy and dotinc into one op), as long as the intermediate signal</span>
        <span class="c1"># is only written to by one op and read by one op</span>

        <span class="c1"># order signals/operators to promote contiguous reads</span>
        <span class="n">sorter</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">get_setting</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="s2">&quot;sorter&quot;</span><span class="p">,</span> <span class="n">graph_optimizer</span><span class="o">.</span><span class="n">order_signals</span><span class="p">)</span>

        <span class="k">with</span> <span class="n">progress</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="s2">&quot;ordering signals&quot;</span><span class="p">,</span> <span class="n">max_value</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
            <span class="n">sigs</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">plan</span> <span class="o">=</span> <span class="n">sorter</span><span class="p">(</span><span class="n">plan</span><span class="p">,</span> <span class="n">n_passes</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>

        <span class="c1"># create base arrays and map Signals to TensorSignals (views on those</span>
        <span class="c1"># base arrays)</span>
        <span class="k">with</span> <span class="n">progress</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="s2">&quot;creating signals&quot;</span><span class="p">,</span> <span class="n">max_value</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">create_signals</span><span class="p">(</span><span class="n">sigs</span><span class="p">)</span>

        <span class="c1"># generate unique names for layer inputs/outputs</span>
        <span class="c1"># this follows the TensorFlow unique naming scheme, so if multiple objects are</span>
        <span class="c1"># created with the same name, they will be named like name, NAME_1, name_2</span>
        <span class="c1"># (note: case insensitive)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">io_names</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="n">name_count</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">obj</span> <span class="ow">in</span> <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">invariant_inputs</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">probes</span><span class="p">:</span>
            <span class="n">name</span> <span class="o">=</span> <span class="p">(</span>
                <span class="nb">type</span><span class="p">(</span><span class="n">obj</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>
                <span class="k">if</span> <span class="n">obj</span><span class="o">.</span><span class="n">label</span> <span class="ow">is</span> <span class="kc">None</span>
                <span class="k">else</span> <span class="n">utils</span><span class="o">.</span><span class="n">sanitize_name</span><span class="p">(</span><span class="n">obj</span><span class="o">.</span><span class="n">label</span><span class="p">)</span>
            <span class="p">)</span>

            <span class="n">key</span> <span class="o">=</span> <span class="n">name</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>

            <span class="k">if</span> <span class="n">name_count</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">name</span> <span class="o">+=</span> <span class="s2">&quot;_</span><span class="si">%d</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">name_count</span><span class="p">[</span><span class="n">key</span><span class="p">]</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">io_names</span><span class="p">[</span><span class="n">obj</span><span class="p">]</span> <span class="o">=</span> <span class="n">name</span>
            <span class="n">name_count</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Optimized plan length: </span><span class="si">%d</span><span class="s2">&quot;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">plan</span><span class="p">))</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
            <span class="s2">&quot;Number of base arrays: (</span><span class="si">%s</span><span class="s2">, </span><span class="si">%d</span><span class="s2">), (</span><span class="si">%s</span><span class="s2">, </span><span class="si">%d</span><span class="s2">), (</span><span class="si">%s</span><span class="s2">, </span><span class="si">%d</span><span class="s2">)&quot;</span><span class="p">,</span>
            <span class="o">*</span><span class="nb">tuple</span><span class="p">((</span><span class="n">k</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">))</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">x</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">base_arrays_init</span><span class="o">.</span><span class="n">items</span><span class="p">()),</span>
        <span class="p">)</span>

<div class="viewcode-block" id="TensorGraph.build_inputs"><a class="viewcode-back" href="../../reference.html#nengo_dl.tensor_graph.TensorGraph.build_inputs">[docs]</a>    <span class="k">def</span> <span class="nf">build_inputs</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Generates a set of Input layers that can be used as inputs to a</span>
<span class="sd">        TensorGraph layer.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        n_steps : ``tf.keras.layers.Input``</span>
<span class="sd">            Input layer for specifying the number of simulation timesteps.</span>
<span class="sd">        inputs : dict of {`nengo.Node`: ``tf.keras.layers.Input``}</span>
<span class="sd">            Input layers for each of the Nodes in the network.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c1"># input placeholders</span>
        <span class="n">inputs</span> <span class="o">=</span> <span class="n">OrderedDict</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">invariant_inputs</span><span class="p">:</span>
            <span class="n">inputs</span><span class="p">[</span><span class="n">n</span><span class="p">]</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Input</span><span class="p">(</span>
                <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">n</span><span class="o">.</span><span class="n">size_out</span><span class="p">),</span>
                <span class="n">batch_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">minibatch_size</span><span class="p">,</span>
                <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
                <span class="n">name</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">io_names</span><span class="p">[</span><span class="n">n</span><span class="p">],</span>
            <span class="p">)</span>

        <span class="c1"># number of steps to run</span>
        <span class="n">n_steps</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Input</span><span class="p">(</span>
            <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,),</span> <span class="n">batch_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">minibatch_size</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="s2">&quot;int32&quot;</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;n_steps&quot;</span>
        <span class="p">)</span>

        <span class="k">return</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">n_steps</span></div>

<div class="viewcode-block" id="TensorGraph.build"><a class="viewcode-back" href="../../reference.html#nengo_dl.tensor_graph.TensorGraph.build">[docs]</a>    <span class="k">def</span> <span class="nf">build</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Create any Variables used in the model.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        input_shape : list of tuple of int</span>
<span class="sd">            Shapes of all the inputs to this layer.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">build</span><span class="p">(</span><span class="n">input_shape</span><span class="p">)</span>

        <span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">set_seed</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">seed</span><span class="p">)</span>

        <span class="k">def</span> <span class="nf">get_initializer</span><span class="p">(</span><span class="n">init_vals</span><span class="p">):</span>
            <span class="sd">&quot;&quot;&quot;Use more efficient initializers if possible to save memory.&quot;&quot;&quot;</span>

            <span class="n">values</span><span class="p">,</span> <span class="n">shapes</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">minibatched</span> <span class="o">=</span> <span class="n">init_vals</span>

            <span class="c1"># initial value of None means that the initial value isn&#39;t used, so we</span>
            <span class="c1"># can use anything for the initial value</span>
            <span class="k">if</span> <span class="nb">all</span><span class="p">(</span><span class="n">v</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">values</span><span class="p">):</span>
                <span class="n">initializer</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="k">elif</span> <span class="nb">all</span><span class="p">(</span><span class="n">v</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">np</span><span class="o">.</span><span class="n">all</span><span class="p">(</span><span class="n">v</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">values</span><span class="p">):</span>
                <span class="n">initializer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">initializers</span><span class="o">.</span><span class="n">zeros</span><span class="p">()</span>
            <span class="k">elif</span> <span class="nb">all</span><span class="p">(</span><span class="n">v</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">np</span><span class="o">.</span><span class="n">all</span><span class="p">(</span><span class="n">v</span> <span class="o">==</span> <span class="mi">1</span><span class="p">)</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">values</span><span class="p">):</span>
                <span class="n">initializer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">initializers</span><span class="o">.</span><span class="n">ones</span><span class="p">()</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">val</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">(</span>
                    <span class="p">[</span>
                        <span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">s</span><span class="p">,</span> <span class="n">dtype</span><span class="p">)</span>
                        <span class="k">if</span> <span class="n">v</span> <span class="ow">is</span> <span class="kc">None</span>
                        <span class="k">else</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">broadcast_to</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">s</span><span class="p">),</span> <span class="n">dtype</span><span class="p">)</span>
                        <span class="k">for</span> <span class="n">v</span><span class="p">,</span> <span class="n">s</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">values</span><span class="p">,</span> <span class="n">shapes</span><span class="p">)</span>
                    <span class="p">],</span>
                    <span class="n">axis</span><span class="o">=</span><span class="mi">1</span> <span class="k">if</span> <span class="n">minibatched</span> <span class="k">else</span> <span class="mi">0</span><span class="p">,</span>
                <span class="p">)</span>
                <span class="n">initializer</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">shape</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="n">val</span>

            <span class="c1"># figure out shape of full concatenated initial value</span>
            <span class="n">shape</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">shapes</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
            <span class="n">shape</span><span class="p">[</span><span class="n">minibatched</span><span class="p">]</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="n">minibatched</span><span class="p">]</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">shapes</span><span class="p">)</span>

            <span class="k">return</span> <span class="n">initializer</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">shape</span><span class="p">),</span> <span class="n">dtype</span>

        <span class="c1"># variables for model parameters</span>
        <span class="k">with</span> <span class="n">trackable</span><span class="o">.</span><span class="n">no_automatic_dependency_tracking_scope</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">base_params</span> <span class="o">=</span> <span class="n">OrderedDict</span><span class="p">()</span>
        <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">base_params</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">sig_type</span> <span class="ow">in</span> <span class="p">(</span><span class="s2">&quot;trainable&quot;</span><span class="p">,</span> <span class="s2">&quot;non_trainable&quot;</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">base_arrays_init</span><span class="p">[</span><span class="n">sig_type</span><span class="p">]</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                <span class="n">initializer</span><span class="p">,</span> <span class="n">shape</span><span class="p">,</span> <span class="n">dtype</span> <span class="o">=</span> <span class="n">get_initializer</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>
                <span class="k">assert</span> <span class="n">initializer</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>  <span class="c1"># params should never be set</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">base_params</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">add_weight</span><span class="p">(</span>
                    <span class="n">initializer</span><span class="o">=</span><span class="n">initializer</span><span class="p">,</span>
                    <span class="n">shape</span><span class="o">=</span><span class="n">shape</span><span class="p">,</span>
                    <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span>
                    <span class="n">trainable</span><span class="o">=</span><span class="n">sig_type</span> <span class="o">==</span> <span class="s2">&quot;trainable&quot;</span><span class="p">,</span>
                    <span class="n">name</span><span class="o">=</span><span class="s2">&quot;base_params/</span><span class="si">%s</span><span class="s2">_</span><span class="si">%s</span><span class="s2">_</span><span class="si">%s</span><span class="s2">&quot;</span>
                    <span class="o">%</span> <span class="p">(</span><span class="n">sig_type</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="s2">&quot;_&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">shape</span><span class="p">)),</span>
                <span class="p">)</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot;created base param variables&quot;</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">([</span><span class="nb">str</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">base_params</span><span class="o">.</span><span class="n">values</span><span class="p">()])</span>

        <span class="c1"># variables to save the internal state of simulation between runs</span>
        <span class="k">with</span> <span class="n">trackable</span><span class="o">.</span><span class="n">no_automatic_dependency_tracking_scope</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">saved_state</span> <span class="o">=</span> <span class="n">OrderedDict</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">base_arrays_init</span><span class="p">[</span><span class="s2">&quot;state&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="n">initializer</span><span class="p">,</span> <span class="n">shape</span><span class="p">,</span> <span class="n">dtype</span> <span class="o">=</span> <span class="n">get_initializer</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">initializer</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="c1"># don&#39;t need to save the state for signals where the initial value</span>
                <span class="c1"># doesn&#39;t matter</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">saved_state</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span>
                    <span class="n">initial_value</span><span class="o">=</span><span class="k">lambda</span><span class="p">:</span> <span class="n">initializer</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="n">shape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">),</span>
                    <span class="n">shape</span><span class="o">=</span><span class="n">shape</span><span class="p">,</span>
                    <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span>
                    <span class="n">trainable</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                    <span class="n">name</span><span class="o">=</span><span class="s2">&quot;saved_state/</span><span class="si">%s</span><span class="s2">_</span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">dtype</span><span class="p">,</span> <span class="s2">&quot;_&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">shape</span><span class="p">)),</span>
                <span class="p">)</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot;created saved state variables&quot;</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">([</span><span class="nb">str</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">saved_state</span><span class="o">.</span><span class="n">values</span><span class="p">()])</span>

        <span class="c1"># call build on any TensorNode Layers</span>

        <span class="k">def</span> <span class="nf">unbuild</span><span class="p">(</span><span class="n">layer</span><span class="p">):</span>
            <span class="k">assert</span> <span class="n">layer</span><span class="o">.</span><span class="n">built</span>

            <span class="c1"># clear any losses attached to layer (they will be recreated in the</span>
            <span class="c1"># build step, so we don&#39;t want to keep around any losses</span>
            <span class="c1"># associated with the previous build)</span>
            <span class="c1"># note: not clearing layer._losses, because those are manually added</span>
            <span class="c1"># by the user (not created during the build process)</span>
            <span class="n">layer</span><span class="o">.</span><span class="n">_eager_losses</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="n">layer</span><span class="o">.</span><span class="n">_callable_losses</span> <span class="o">=</span> <span class="p">[]</span>

            <span class="n">layer</span><span class="o">.</span><span class="n">built</span> <span class="o">=</span> <span class="kc">False</span>

            <span class="k">for</span> <span class="n">sub</span> <span class="ow">in</span> <span class="n">layer</span><span class="o">.</span><span class="n">_layers</span><span class="p">:</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">sub</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Layer</span><span class="p">):</span>
                    <span class="n">unbuild</span><span class="p">(</span><span class="n">sub</span><span class="p">)</span>

        <span class="n">layer_ops</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">op</span>
            <span class="k">for</span> <span class="n">ops</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">plan</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">ops</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">tensor_node</span><span class="o">.</span><span class="n">SimTensorNode</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">op</span> <span class="ow">in</span> <span class="n">ops</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">op</span><span class="o">.</span><span class="n">func</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Layer</span><span class="p">)</span>
        <span class="p">]</span>
        <span class="n">weight_gets</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">weight_sets</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">op</span> <span class="ow">in</span> <span class="n">layer_ops</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">op</span><span class="o">.</span><span class="n">func</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_layers</span><span class="p">:</span>
                <span class="c1"># already built this layer</span>
                <span class="k">continue</span>

            <span class="k">if</span> <span class="n">op</span><span class="o">.</span><span class="n">time</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">shape_in</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">shape_in</span> <span class="o">=</span> <span class="p">[()]</span>
            <span class="k">if</span> <span class="n">op</span><span class="o">.</span><span class="n">input</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">shape_in</span> <span class="o">+=</span> <span class="p">[(</span><span class="bp">self</span><span class="o">.</span><span class="n">minibatch_size</span><span class="p">,)</span> <span class="o">+</span> <span class="n">op</span><span class="o">.</span><span class="n">shape_in</span><span class="p">]</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">shape_in</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                <span class="n">shape_in</span> <span class="o">=</span> <span class="n">shape_in</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

            <span class="k">if</span> <span class="n">op</span><span class="o">.</span><span class="n">func</span><span class="o">.</span><span class="n">built</span><span class="p">:</span>
                <span class="c1"># we rebuild the layer (even if it is already built),</span>
                <span class="c1"># because we need to build the weights within the TensorGraph</span>
                <span class="c1"># context</span>

                <span class="c1"># save the weight values so they can be restored</span>
                <span class="c1"># exactly inside the tensornode</span>
                <span class="n">weights</span> <span class="o">=</span> <span class="n">op</span><span class="o">.</span><span class="n">func</span><span class="o">.</span><span class="n">weights</span>
                <span class="n">weight_gets</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">weights</span><span class="p">)</span>

                <span class="c1"># clear the results of previous build</span>
                <span class="n">unbuild</span><span class="p">(</span><span class="n">op</span><span class="o">.</span><span class="n">func</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">weights</span> <span class="o">=</span> <span class="kc">None</span>

            <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="n">op</span><span class="o">.</span><span class="n">func</span><span class="o">.</span><span class="n">name</span><span class="p">):</span>
                <span class="n">op</span><span class="o">.</span><span class="n">func</span><span class="o">.</span><span class="n">build</span><span class="p">(</span><span class="n">shape_in</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">weights</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">weight_sets</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">op</span><span class="o">.</span><span class="n">func</span><span class="o">.</span><span class="n">weights</span><span class="p">)</span>

            <span class="c1"># add op func to _layers so that any weights are collected</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">op</span><span class="o">.</span><span class="n">func</span><span class="p">)</span>

        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">weight_gets</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="c1"># do all the weight getting/setting in one go, for efficiency reasons</span>
            <span class="n">ctx</span> <span class="o">=</span> <span class="p">(</span>
                <span class="n">weight_gets</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">as_default</span><span class="p">()</span>
                <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">weight_gets</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="s2">&quot;graph&quot;</span><span class="p">)</span>
                <span class="k">else</span> <span class="n">context</span><span class="o">.</span><span class="n">eager_mode</span><span class="p">()</span>
            <span class="p">)</span>
            <span class="k">with</span> <span class="n">ctx</span><span class="p">:</span>
                <span class="n">weight_vals</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">backend</span><span class="o">.</span><span class="n">batch_get_value</span><span class="p">(</span><span class="n">weight_gets</span><span class="p">)</span>

            <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">backend</span><span class="o">.</span><span class="n">batch_set_value</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">weight_sets</span><span class="p">,</span> <span class="n">weight_vals</span><span class="p">))</span>

        <span class="c1"># initialize state variables (need to do this manually because we&#39;re not</span>
        <span class="c1"># adding them to self.weights)</span>
        <span class="c1"># note: don&#39;t need to do this in eager mode, since variables are</span>
        <span class="c1"># initialized on creation</span>
        <span class="c1"># TODO: why does this cause problems if it is done before the tensornode</span>
        <span class="c1">#  weight get/sets above?</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">context</span><span class="o">.</span><span class="n">executing_eagerly</span><span class="p">():</span>
            <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">backend</span><span class="o">.</span><span class="n">batch_get_value</span><span class="p">(</span>
                <span class="p">[</span><span class="n">var</span><span class="o">.</span><span class="n">initializer</span> <span class="k">for</span> <span class="n">var</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">saved_state</span><span class="o">.</span><span class="n">values</span><span class="p">()]</span>
            <span class="p">)</span></div>

    <span class="c1"># @tf.function  # TODO: get this working? does this help?</span>
<div class="viewcode-block" id="TensorGraph.call"><a class="viewcode-back" href="../../reference.html#nengo_dl.tensor_graph.TensorGraph.call">[docs]</a>    <span class="nd">@tf</span><span class="o">.</span><span class="n">autograph</span><span class="o">.</span><span class="n">experimental</span><span class="o">.</span><span class="n">do_not_convert</span>
    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">progress</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">stateful</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Constructs the graph elements to simulate the model.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        inputs : list of ``tf.Tensor``</span>
<span class="sd">            Input layers/tensors for the network (must match the structure defined in</span>
<span class="sd">            `.build_inputs`).</span>
<span class="sd">        training : bool</span>
<span class="sd">            Whether the network is being run in training or inference mode.  If None,</span>
<span class="sd">            uses the symbolic Keras learning phase variable.</span>
<span class="sd">        progress : `.utils.ProgressBar`</span>
<span class="sd">            Progress bar for construction stage.</span>
<span class="sd">        stateful : bool</span>
<span class="sd">            Whether or not to build the model to support preserving the internal state</span>
<span class="sd">            between executions.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        probe_arrays : list of ``tf.Tensor``</span>
<span class="sd">            Tensors representing the output of all the Probes in the network (order</span>
<span class="sd">            corresponding to ``self.model.probes``, which is the order the Probes were</span>
<span class="sd">            instantiated).</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">call</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="n">training</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">training</span> <span class="o">==</span> <span class="mi">1</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">inference_only</span><span class="p">:</span>
            <span class="k">raise</span> <span class="n">BuildError</span><span class="p">(</span>
                <span class="s2">&quot;TensorGraph was created with inference_only=True; cannot be built &quot;</span>
                <span class="s2">&quot;with training=</span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">training</span>
            <span class="p">)</span>

        <span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">set_seed</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">seed</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">progress</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">progress</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">NullProgressBar</span><span class="p">()</span>

        <span class="c1"># reset signaldict</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">signals</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>

        <span class="c1"># create these constants once here for reuse in different operators</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">signals</span><span class="o">.</span><span class="n">dt</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dt</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">signals</span><span class="o">.</span><span class="n">dt_val</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dt</span>  <span class="c1"># store the actual value as well</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">signals</span><span class="o">.</span><span class="n">zero</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">signals</span><span class="o">.</span><span class="n">one</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>

        <span class="c1"># set up invariant inputs</span>
        <span class="k">with</span> <span class="n">trackable</span><span class="o">.</span><span class="n">no_automatic_dependency_tracking_scope</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">node_inputs</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="n">n</span><span class="p">,</span> <span class="n">inp</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">invariant_inputs</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
            <span class="c1"># specify shape of inputs (keras sometimes loses this shape information)</span>
            <span class="n">inp</span><span class="o">.</span><span class="n">set_shape</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">minibatch_size</span><span class="p">,</span> <span class="n">inp</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">n</span><span class="o">.</span><span class="n">size_out</span><span class="p">])</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">node_inputs</span><span class="p">[</span><span class="n">n</span><span class="p">]</span> <span class="o">=</span> <span class="n">inp</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">steps_to_run</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">][</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>

        <span class="c1"># initialize op builder</span>
        <span class="n">build_config</span> <span class="o">=</span> <span class="n">builder</span><span class="o">.</span><span class="n">BuildConfig</span><span class="p">(</span>
            <span class="n">inference_only</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">inference_only</span><span class="p">,</span>
            <span class="n">lif_smoothing</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">get_setting</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s2">&quot;lif_smoothing&quot;</span><span class="p">),</span>
            <span class="n">cpu_only</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span> <span class="o">==</span> <span class="s2">&quot;/cpu:0&quot;</span> <span class="ow">or</span> <span class="ow">not</span> <span class="n">utils</span><span class="o">.</span><span class="n">tf_gpu_installed</span><span class="p">,</span>
            <span class="n">rng</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">RandomState</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">seed</span><span class="p">),</span>
            <span class="n">training</span><span class="o">=</span><span class="p">(</span>
                <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">backend</span><span class="o">.</span><span class="n">learning_phase</span><span class="p">()</span> <span class="k">if</span> <span class="n">training</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">training</span>
            <span class="p">),</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">op_builder</span> <span class="o">=</span> <span class="n">builder</span><span class="o">.</span><span class="n">Builder</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">plan</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">signals</span><span class="p">,</span> <span class="n">build_config</span><span class="p">)</span>

        <span class="c1"># pre-build stage</span>
        <span class="k">with</span> <span class="n">progress</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="s2">&quot;pre-build stage&quot;</span><span class="p">,</span> <span class="n">max_value</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">plan</span><span class="p">))</span> <span class="k">as</span> <span class="n">sub</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">op_builder</span><span class="o">.</span><span class="n">build_pre</span><span class="p">(</span><span class="n">sub</span><span class="p">)</span>

        <span class="c1"># build stage</span>
        <span class="k">with</span> <span class="n">progress</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="s2">&quot;build stage&quot;</span><span class="p">,</span> <span class="n">max_value</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">plan</span><span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">unroll</span><span class="p">)</span> <span class="k">as</span> <span class="n">sub</span><span class="p">:</span>
            <span class="n">steps_run</span><span class="p">,</span> <span class="n">probe_arrays</span><span class="p">,</span> <span class="n">final_internal_state</span><span class="p">,</span> <span class="n">final_base_params</span> <span class="o">=</span> <span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_build_loop</span><span class="p">(</span><span class="n">sub</span><span class="p">)</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_loop</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">_build_no_loop</span><span class="p">(</span><span class="n">sub</span><span class="p">)</span>
            <span class="p">)</span>

        <span class="c1"># store these so that they can be accessed after the initial build</span>
        <span class="k">with</span> <span class="n">trackable</span><span class="o">.</span><span class="n">no_automatic_dependency_tracking_scope</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">steps_run</span> <span class="o">=</span> <span class="n">steps_run</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">probe_arrays</span> <span class="o">=</span> <span class="n">probe_arrays</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">final_internal_state</span> <span class="o">=</span> <span class="n">final_internal_state</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">final_base_params</span> <span class="o">=</span> <span class="n">final_base_params</span>

        <span class="c1"># logging</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
            <span class="s2">&quot;Number of reads: </span><span class="si">%d</span><span class="s2">&quot;</span><span class="p">,</span> <span class="nb">sum</span><span class="p">(</span><span class="n">x</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">signals</span><span class="o">.</span><span class="n">read_types</span><span class="o">.</span><span class="n">values</span><span class="p">())</span>
        <span class="p">)</span>
        <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">signals</span><span class="o">.</span><span class="n">read_types</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;    </span><span class="si">%s</span><span class="s2">: </span><span class="si">%d</span><span class="s2">&quot;</span><span class="p">,</span> <span class="o">*</span><span class="n">x</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
            <span class="s2">&quot;Number of writes: </span><span class="si">%d</span><span class="s2">&quot;</span><span class="p">,</span> <span class="nb">sum</span><span class="p">(</span><span class="n">x</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">signals</span><span class="o">.</span><span class="n">write_types</span><span class="o">.</span><span class="n">values</span><span class="p">())</span>
        <span class="p">)</span>
        <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">signals</span><span class="o">.</span><span class="n">write_types</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;    </span><span class="si">%s</span><span class="s2">: </span><span class="si">%d</span><span class="s2">&quot;</span><span class="p">,</span> <span class="o">*</span><span class="n">x</span><span class="p">)</span>

        <span class="c1"># note: always return steps_run so that the simulation will run for the given</span>
        <span class="c1"># number of steps, even if there are no output probes</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">probe_arrays</span><span class="o">.</span><span class="n">values</span><span class="p">())</span> <span class="o">+</span> <span class="p">[</span><span class="n">steps_run</span><span class="p">]</span>

        <span class="n">updates</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">if</span> <span class="n">stateful</span><span class="p">:</span>
            <span class="c1"># update saved state</span>
            <span class="n">updates</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span>
                <span class="n">var</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span><span class="n">val</span><span class="p">)</span>
                <span class="k">for</span> <span class="n">var</span><span class="p">,</span> <span class="n">val</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">saved_state</span><span class="o">.</span><span class="n">values</span><span class="p">(),</span> <span class="n">final_internal_state</span><span class="p">)</span>
            <span class="p">)</span>

        <span class="c1"># if any of the base params have changed (due to online learning rules) then we</span>
        <span class="c1"># also need to assign those back to the original variable (so that their</span>
        <span class="c1"># values will persist). any parameters targeted by online learning rules</span>
        <span class="c1"># will be minibatched, so we only need to update the minibatched params.</span>
        <span class="k">for</span> <span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">var</span><span class="p">),</span> <span class="n">val</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">base_params</span><span class="o">.</span><span class="n">items</span><span class="p">(),</span> <span class="n">final_base_params</span><span class="p">):</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">minibatched</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">base_arrays_init</span><span class="p">[</span><span class="s2">&quot;non_trainable&quot;</span><span class="p">][</span><span class="n">key</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
            <span class="k">except</span> <span class="ne">KeyError</span><span class="p">:</span>
                <span class="n">minibatched</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">base_arrays_init</span><span class="p">[</span><span class="s2">&quot;trainable&quot;</span><span class="p">][</span><span class="n">key</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

            <span class="k">if</span> <span class="n">minibatched</span><span class="p">:</span>
                <span class="n">updates</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">var</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span><span class="n">val</span><span class="p">))</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Number of variable updates: </span><span class="si">%d</span><span class="s2">&quot;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">updates</span><span class="p">))</span>

        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">updates</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">control_dependencies</span><span class="p">(</span><span class="n">updates</span><span class="p">):</span>
                <span class="n">outputs</span> <span class="o">=</span> <span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">identity</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">outputs</span><span class="p">]</span>

        <span class="k">return</span> <span class="n">outputs</span></div>

    <span class="k">def</span> <span class="nf">_fill_bases</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">saved_state</span><span class="p">,</span> <span class="n">base_params</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Initialize signals.bases from TensorGraph params.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        saved_state : dict</span>
<span class="sd">            Mapping from base keys to initial values</span>
<span class="sd">        base_params : dict</span>
<span class="sd">            Mapping from base keys to initial values</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">val</span> <span class="ow">in</span> <span class="n">saved_state</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="c1"># we add the tf.identity so that when we write we&#39;re not updating</span>
            <span class="c1"># the base variable</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">signals</span><span class="o">.</span><span class="n">bases</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">identity</span><span class="p">(</span><span class="n">val</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">val</span> <span class="ow">in</span> <span class="n">base_params</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">signals</span><span class="o">.</span><span class="n">bases</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">identity</span><span class="p">(</span><span class="n">val</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="p">(</span><span class="n">_</span><span class="p">,</span> <span class="n">shapes</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">minibatched</span><span class="p">)</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">base_arrays_init</span><span class="p">[</span><span class="s2">&quot;state&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="k">if</span> <span class="n">key</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">signals</span><span class="o">.</span><span class="n">bases</span><span class="p">:</span>
                <span class="c1"># no saved state for this base, so we just temporarily insert</span>
                <span class="c1"># the shape information so that future scatters will know</span>
                <span class="c1"># what the base shape is</span>
                <span class="n">shape</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">shapes</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
                <span class="n">shape</span><span class="p">[</span><span class="n">minibatched</span><span class="p">]</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="n">minibatched</span><span class="p">]</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">shapes</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">signals</span><span class="o">.</span><span class="n">bases</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_build_loop</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">progress</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Build simulation loop using symbolic while loop.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        progress : `.utils.ProgressBar`</span>
<span class="sd">            Progress bar for loop construction</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        steps_run : ``tf.Tensor``</span>
<span class="sd">            The number of simulation steps that were executed.</span>
<span class="sd">        probe_arrays : dict of {`nengo.Probe`: ``tf.Tensor``}</span>
<span class="sd">            Arrays containing the output values for each Probe.</span>
<span class="sd">        final_internal_state: list of ``tf.Tensor``</span>
<span class="sd">            Tensors representing the value of all internal state at the end of the run.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">def</span> <span class="nf">loop_condition</span><span class="p">(</span><span class="n">loop_i</span><span class="p">,</span> <span class="n">n_steps</span><span class="p">,</span> <span class="o">*</span><span class="n">_</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">loop_i</span> <span class="o">&lt;</span> <span class="n">n_steps</span>

        <span class="k">def</span> <span class="nf">loop_body</span><span class="p">(</span><span class="n">loop_i</span><span class="p">,</span> <span class="n">n_steps</span><span class="p">,</span> <span class="n">probe_arrays</span><span class="p">,</span> <span class="n">saved_state</span><span class="p">,</span> <span class="n">base_params</span><span class="p">):</span>
            <span class="c1"># fill in signals.bases</span>
            <span class="c1"># note: we need to do this here because we</span>
            <span class="c1"># need to use the tensors from inside the loop, not the source variables)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_fill_bases</span><span class="p">(</span>
                <span class="nb">dict</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">saved_state</span><span class="p">,</span> <span class="n">saved_state</span><span class="p">)),</span>
                <span class="nb">dict</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">base_params</span><span class="p">,</span> <span class="n">base_params</span><span class="p">)),</span>
            <span class="p">)</span>

            <span class="k">def</span> <span class="nf">update_probes</span><span class="p">(</span><span class="n">probe_tensors</span><span class="p">,</span> <span class="n">loop_i</span><span class="p">):</span>
                <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">p</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">probe_tensors</span><span class="p">):</span>
                    <span class="k">if</span> <span class="n">config</span><span class="o">.</span><span class="n">get_setting</span><span class="p">(</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span>
                        <span class="s2">&quot;keep_history&quot;</span><span class="p">,</span>
                        <span class="n">default</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                        <span class="n">obj</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">probes</span><span class="p">[</span><span class="n">i</span><span class="p">],</span>
                    <span class="p">):</span>
                        <span class="n">probe_arrays</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">probe_arrays</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">loop_i</span><span class="p">,</span> <span class="n">p</span><span class="p">)</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">probe_arrays</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">cond</span><span class="p">(</span>
                            <span class="n">pred</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">equal</span><span class="p">(</span><span class="n">loop_i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">n_steps</span><span class="p">),</span>
                            <span class="n">true_fn</span><span class="o">=</span><span class="k">lambda</span> <span class="n">p</span><span class="o">=</span><span class="n">p</span><span class="p">,</span> <span class="n">i</span><span class="o">=</span><span class="n">i</span><span class="p">:</span> <span class="n">probe_arrays</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">p</span><span class="p">),</span>
                            <span class="n">false_fn</span><span class="o">=</span><span class="k">lambda</span> <span class="n">i</span><span class="o">=</span><span class="n">i</span><span class="p">:</span> <span class="n">probe_arrays</span><span class="p">[</span><span class="n">i</span><span class="p">],</span>
                        <span class="p">)</span>

            <span class="n">loop_i</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_build_inner_loop</span><span class="p">(</span><span class="n">loop_i</span><span class="p">,</span> <span class="n">update_probes</span><span class="p">,</span> <span class="n">progress</span><span class="p">)</span>

            <span class="n">state_arrays</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">signals</span><span class="o">.</span><span class="n">bases</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">saved_state</span><span class="p">)</span>
            <span class="n">base_arrays</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">signals</span><span class="o">.</span><span class="n">bases</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">base_params</span><span class="p">)</span>

            <span class="k">return</span> <span class="n">loop_i</span><span class="p">,</span> <span class="n">n_steps</span><span class="p">,</span> <span class="n">probe_arrays</span><span class="p">,</span> <span class="n">state_arrays</span><span class="p">,</span> <span class="n">base_arrays</span>

        <span class="n">loop_i</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

        <span class="n">probe_arrays</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">tf</span><span class="o">.</span><span class="n">TensorArray</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">clear_after_read</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">dynamic_size</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">probes</span>
        <span class="p">]</span>

        <span class="c1"># build simulation loop</span>
        <span class="n">loop_vars</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">loop_i</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">steps_to_run</span><span class="p">,</span>
            <span class="n">probe_arrays</span><span class="p">,</span>
            <span class="nb">tuple</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">saved_state</span><span class="o">.</span><span class="n">values</span><span class="p">()),</span>
            <span class="nb">tuple</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">base_params</span><span class="o">.</span><span class="n">values</span><span class="p">()),</span>
        <span class="p">)</span>

        <span class="n">loop_vars</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">while_loop</span><span class="p">(</span>
            <span class="n">cond</span><span class="o">=</span><span class="n">loop_condition</span><span class="p">,</span>
            <span class="n">body</span><span class="o">=</span><span class="n">loop_body</span><span class="p">,</span>
            <span class="n">loop_vars</span><span class="o">=</span><span class="n">loop_vars</span><span class="p">,</span>
            <span class="n">parallel_iterations</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>  <span class="c1"># TODO: parallel iterations work in eager mode</span>
        <span class="p">)</span>

        <span class="c1"># change to shape (minibatch_size,) (required by keras) instead of a scalar</span>
        <span class="n">steps_run</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">tile</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">loop_vars</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">0</span><span class="p">),</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">minibatch_size</span><span class="p">,))</span>

        <span class="n">probe_arrays</span> <span class="o">=</span> <span class="n">OrderedDict</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">p</span><span class="p">,</span> <span class="n">a</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">probes</span><span class="p">,</span> <span class="n">loop_vars</span><span class="p">[</span><span class="mi">2</span><span class="p">]):</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">stack</span><span class="p">()</span>

            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">sig</span><span class="p">[</span><span class="n">p</span><span class="p">][</span><span class="s2">&quot;in&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">minibatched</span><span class="p">:</span>
                <span class="c1"># change from tensorarray&#39;s (steps, batch, d) to (batch, steps, d)</span>
                <span class="n">perm</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="o">.</span><span class="n">ndims</span><span class="p">)</span>
                <span class="n">perm</span><span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]]</span> <span class="o">=</span> <span class="n">perm</span><span class="p">[[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]]</span>
                <span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">perm</span><span class="o">=</span><span class="n">perm</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># add minibatch dimension for consistency</span>
                <span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>

            <span class="n">probe_arrays</span><span class="p">[</span><span class="n">p</span><span class="p">]</span> <span class="o">=</span> <span class="n">x</span>

        <span class="n">final_internal_state</span> <span class="o">=</span> <span class="n">loop_vars</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span>
        <span class="n">final_base_params</span> <span class="o">=</span> <span class="n">loop_vars</span><span class="p">[</span><span class="mi">4</span><span class="p">]</span>

        <span class="k">return</span> <span class="n">steps_run</span><span class="p">,</span> <span class="n">probe_arrays</span><span class="p">,</span> <span class="n">final_internal_state</span><span class="p">,</span> <span class="n">final_base_params</span>

    <span class="k">def</span> <span class="nf">_build_no_loop</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">progress</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Build simulation loop through explicit unrolling.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        progress : `.utils.ProgressBar`</span>
<span class="sd">            Progress bar for loop construction</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        steps_run : ``tf.Tensor``</span>
<span class="sd">            The number of simulation steps that were executed.</span>
<span class="sd">        probe_arrays : dict of {`nengo.Probe`: ``tf.Tensor``}</span>
<span class="sd">            Arrays containing the output values for each Probe.</span>
<span class="sd">        final_internal_state: list of ``tf.Tensor``</span>
<span class="sd">            Tensors representing the value of all internal state at the end of the run.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_fill_bases</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">saved_state</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">base_params</span><span class="p">)</span>

        <span class="n">loop_i</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>  <span class="c1"># symbolic loop variable</span>
        <span class="n">loop_iter</span> <span class="o">=</span> <span class="mi">0</span>  <span class="c1"># non-symbolic loop variable</span>
        <span class="n">probe_data</span> <span class="o">=</span> <span class="p">[[]</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">probes</span><span class="p">]</span>

        <span class="k">def</span> <span class="nf">update_probes</span><span class="p">(</span><span class="n">probe_tensors</span><span class="p">,</span> <span class="n">_</span><span class="p">):</span>
            <span class="k">nonlocal</span> <span class="n">loop_iter</span>

            <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">p</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">probe_tensors</span><span class="p">):</span>
                <span class="k">if</span> <span class="n">config</span><span class="o">.</span><span class="n">get_setting</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s2">&quot;keep_history&quot;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">obj</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">probes</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
                <span class="p">):</span>
                    <span class="n">probe_data</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>
                <span class="k">elif</span> <span class="n">loop_iter</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">unroll</span> <span class="o">-</span> <span class="mi">1</span><span class="p">:</span>
                    <span class="n">probe_data</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>

            <span class="n">loop_iter</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="n">loop_i</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_build_inner_loop</span><span class="p">(</span><span class="n">loop_i</span><span class="p">,</span> <span class="n">update_probes</span><span class="p">,</span> <span class="n">progress</span><span class="p">)</span>

        <span class="c1"># change to shape (minibatch_size,) (required by keras) instead of a scalar</span>
        <span class="n">steps_run</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">tile</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">loop_i</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">minibatch_size</span><span class="p">,))</span>

        <span class="n">probe_arrays</span> <span class="o">=</span> <span class="n">OrderedDict</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">p</span><span class="p">,</span> <span class="n">a</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">probes</span><span class="p">,</span> <span class="n">probe_data</span><span class="p">):</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">sig</span><span class="p">[</span><span class="n">p</span><span class="p">][</span><span class="s2">&quot;in&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">minibatched</span><span class="p">:</span>
                <span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

                <span class="c1"># add minibatch dimension for consistency</span>
                <span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>

            <span class="n">probe_arrays</span><span class="p">[</span><span class="n">p</span><span class="p">]</span> <span class="o">=</span> <span class="n">x</span>

        <span class="n">final_internal_state</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">signals</span><span class="o">.</span><span class="n">bases</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">saved_state</span>
        <span class="p">)</span>
        <span class="n">final_base_params</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">signals</span><span class="o">.</span><span class="n">bases</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">base_params</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">steps_run</span><span class="p">,</span> <span class="n">probe_arrays</span><span class="p">,</span> <span class="n">final_internal_state</span><span class="p">,</span> <span class="n">final_base_params</span>

    <span class="k">def</span> <span class="nf">_build_inner_loop</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">loop_i</span><span class="p">,</span> <span class="n">update_probes</span><span class="p">,</span> <span class="n">progress</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        loop_i : ``tf.Tensor``</span>
<span class="sd">            Loop iteration variable.</span>
<span class="sd">        update_probes : callable</span>
<span class="sd">            Function that will update some stored probe data in each iteration.</span>
<span class="sd">        progress</span>
<span class="sd">            Progress bar for loop construction.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        loop_i : ``tf.Tensor``</span>
<span class="sd">            Updated loop iteration variable.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">constant_probes</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">probes</span><span class="p">:</span>
            <span class="n">probe_sig</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">sig</span><span class="p">[</span><span class="n">p</span><span class="p">][</span><span class="s2">&quot;in&quot;</span><span class="p">]</span>
            <span class="k">if</span> <span class="n">probe_sig</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">signals</span><span class="p">:</span>
                <span class="c1"># if a probe signal isn&#39;t in sig_map, that means that it</span>
                <span class="c1"># isn&#39;t involved in any simulator ops.  so we know its value</span>
                <span class="c1"># never changes, and we&#39;ll just return a constant containing</span>
                <span class="c1"># the initial value.</span>
                <span class="n">init_val</span> <span class="o">=</span> <span class="n">probe_sig</span><span class="o">.</span><span class="n">initial_value</span>
                <span class="k">if</span> <span class="n">probe_sig</span><span class="o">.</span><span class="n">minibatched</span><span class="p">:</span>
                    <span class="n">init_val</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">tile</span><span class="p">(</span><span class="n">init_val</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="p">:],</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">minibatch_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>

                <span class="n">constant_probes</span><span class="p">[</span><span class="n">p</span><span class="p">]</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="n">init_val</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">unroll_iter</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">unroll</span><span class="p">):</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot;BUILDING ITERATION </span><span class="si">%d</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">unroll_iter</span><span class="p">)</span>
            <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="s2">&quot;iteration_</span><span class="si">%d</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">unroll_iter</span><span class="p">):</span>
                <span class="c1"># fill in invariant input data</span>
                <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">node_inputs</span><span class="p">:</span>
                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">sig</span><span class="p">[</span><span class="n">n</span><span class="p">][</span><span class="s2">&quot;out&quot;</span><span class="p">]</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">signals</span><span class="p">:</span>
                        <span class="c1"># if the out signal doesn&#39;t exist then that means that</span>
                        <span class="c1"># the node output isn&#39;t actually used anywhere, so we can</span>
                        <span class="c1"># ignore it</span>

                        <span class="bp">self</span><span class="o">.</span><span class="n">signals</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span>
                            <span class="bp">self</span><span class="o">.</span><span class="n">signals</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">sig</span><span class="p">[</span><span class="n">n</span><span class="p">][</span><span class="s2">&quot;out&quot;</span><span class="p">]],</span>
                            <span class="bp">self</span><span class="o">.</span><span class="n">node_inputs</span><span class="p">[</span><span class="n">n</span><span class="p">][:,</span> <span class="n">loop_i</span><span class="p">],</span>
                        <span class="p">)</span>

                <span class="c1"># build the operators for a single step</span>
                <span class="c1"># note: we tie things to the `loop_i` variable so that we</span>
                <span class="c1"># can be sure the other things we&#39;re tying to the</span>
                <span class="c1"># simulation step (side effects and probes) from the</span>
                <span class="c1"># previous timestep are executed before the next step</span>
                <span class="c1"># starts</span>
                <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">control_dependencies</span><span class="p">([</span><span class="n">loop_i</span><span class="p">]):</span>
                    <span class="c1"># build operators</span>
                    <span class="n">side_effects</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">op_builder</span><span class="o">.</span><span class="n">build</span><span class="p">(</span><span class="n">progress</span><span class="p">)</span>

                    <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot;collecting probe tensors&quot;</span><span class="p">)</span>
                    <span class="n">probe_tensors</span> <span class="o">=</span> <span class="p">[]</span>
                    <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">probes</span><span class="p">:</span>
                        <span class="k">if</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">constant_probes</span><span class="p">:</span>
                            <span class="n">probe_tensors</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">constant_probes</span><span class="p">[</span><span class="n">p</span><span class="p">])</span>
                        <span class="k">else</span><span class="p">:</span>
                            <span class="n">probe_tensors</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                                <span class="bp">self</span><span class="o">.</span><span class="n">signals</span><span class="o">.</span><span class="n">gather</span><span class="p">(</span>
                                    <span class="bp">self</span><span class="o">.</span><span class="n">signals</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">sig</span><span class="p">[</span><span class="n">p</span><span class="p">][</span><span class="s2">&quot;in&quot;</span><span class="p">]]</span>
                                <span class="p">)</span>
                            <span class="p">)</span>

                    <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">30</span><span class="p">)</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot;build_step complete&quot;</span><span class="p">)</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot;probe_tensors </span><span class="si">%s</span><span class="s2">&quot;</span><span class="p">,</span> <span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">probe_tensors</span><span class="p">])</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot;side_effects </span><span class="si">%s</span><span class="s2">&quot;</span><span class="p">,</span> <span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">side_effects</span><span class="p">])</span>

                <span class="c1"># update probe data</span>
                <span class="n">update_probes</span><span class="p">(</span><span class="n">probe_tensors</span><span class="p">,</span> <span class="n">loop_i</span><span class="p">)</span>

                <span class="c1"># need to make sure that any operators that could have side</span>
                <span class="c1"># effects run each timestep, so we tie them to the loop</span>
                <span class="c1"># increment. we also need to make sure that all the probe</span>
                <span class="c1"># reads happen before those values get overwritten on the</span>
                <span class="c1"># next timestep</span>
                <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">control_dependencies</span><span class="p">(</span><span class="n">side_effects</span> <span class="o">+</span> <span class="n">probe_tensors</span><span class="p">):</span>
                    <span class="n">loop_i</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="k">return</span> <span class="n">loop_i</span>

<div class="viewcode-block" id="TensorGraph.build_post"><a class="viewcode-back" href="../../reference.html#nengo_dl.tensor_graph.TensorGraph.build_post">[docs]</a>    <span class="nd">@trackable</span><span class="o">.</span><span class="n">no_automatic_dependency_tracking</span>
    <span class="k">def</span> <span class="nf">build_post</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Executes post-build processes for operators (after the graph has</span>
<span class="sd">        been constructed and whenever Simulator is reset).</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">RandomState</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">seed</span><span class="p">)</span>

        <span class="c1"># build input functions (we need to do this here, because in the case</span>
        <span class="c1"># of processes these functions need to be be rebuilt on reset)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">input_funcs</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="n">n</span><span class="p">,</span> <span class="n">output</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">invariant_inputs</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">input_funcs</span><span class="p">[</span><span class="n">n</span><span class="p">]</span> <span class="o">=</span> <span class="n">output</span>
            <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">Process</span><span class="p">):</span>
                <span class="n">state</span> <span class="o">=</span> <span class="n">output</span><span class="o">.</span><span class="n">make_state</span><span class="p">((</span><span class="n">n</span><span class="o">.</span><span class="n">size_in</span><span class="p">,),</span> <span class="p">(</span><span class="n">n</span><span class="o">.</span><span class="n">size_out</span><span class="p">,),</span> <span class="bp">self</span><span class="o">.</span><span class="n">dt</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">input_funcs</span><span class="p">[</span><span class="n">n</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span>
                    <span class="n">output</span><span class="o">.</span><span class="n">make_step</span><span class="p">(</span>
                        <span class="p">(</span><span class="n">n</span><span class="o">.</span><span class="n">size_in</span><span class="p">,),</span>
                        <span class="p">(</span><span class="n">n</span><span class="o">.</span><span class="n">size_out</span><span class="p">,),</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">dt</span><span class="p">,</span>
                        <span class="n">output</span><span class="o">.</span><span class="n">get_rng</span><span class="p">(</span><span class="n">rng</span><span class="p">),</span>
                        <span class="n">state</span><span class="p">,</span>
                    <span class="p">)</span>
                    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">minibatch_size</span><span class="p">)</span>
                <span class="p">]</span>
            <span class="k">elif</span> <span class="n">n</span><span class="o">.</span><span class="n">size_out</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">input_funcs</span><span class="p">[</span><span class="n">n</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span>
                    <span class="n">utils</span><span class="o">.</span><span class="n">align_func</span><span class="p">((</span><span class="n">n</span><span class="o">.</span><span class="n">size_out</span><span class="p">,),</span> <span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">)(</span><span class="n">output</span><span class="p">)</span>
                <span class="p">]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># a node with no inputs and no outputs, but it can still</span>
                <span class="c1"># have side effects</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">input_funcs</span><span class="p">[</span><span class="n">n</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">output</span><span class="p">]</span>

        <span class="c1"># execute build_post on all the op builders</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">op_builder</span><span class="o">.</span><span class="n">build_post</span><span class="p">()</span></div>

<div class="viewcode-block" id="TensorGraph.get_tensor"><a class="viewcode-back" href="../../reference.html#nengo_dl.tensor_graph.TensorGraph.get_tensor">[docs]</a>    <span class="k">def</span> <span class="nf">get_tensor</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sig</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Returns a Tensor corresponding to the given Signal.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        sig : `~nengo.builder.Signal`</span>
<span class="sd">            A signal in the Nengo model.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        tensor : ``tf.Tensor``</span>
<span class="sd">            Tensor containing the value of the given Signal.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">tensor_sig</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">signals</span><span class="p">[</span><span class="n">sig</span><span class="p">]</span>

        <span class="k">try</span><span class="p">:</span>
            <span class="n">base</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">base_params</span><span class="p">[</span><span class="n">tensor_sig</span><span class="o">.</span><span class="n">key</span><span class="p">]</span>
        <span class="k">except</span> <span class="ne">KeyError</span><span class="p">:</span>
            <span class="n">base</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">saved_state</span><span class="p">[</span><span class="n">tensor_sig</span><span class="o">.</span><span class="n">key</span><span class="p">]</span>

        <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">gather</span><span class="p">(</span>
            <span class="n">base</span><span class="p">,</span> <span class="n">tensor_sig</span><span class="o">.</span><span class="n">tf_indices</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span> <span class="k">if</span> <span class="n">tensor_sig</span><span class="o">.</span><span class="n">minibatched</span> <span class="k">else</span> <span class="mi">0</span><span class="p">,</span>
        <span class="p">)</span></div>

<div class="viewcode-block" id="TensorGraph.mark_signals"><a class="viewcode-back" href="../../reference.html#nengo_dl.tensor_graph.TensorGraph.mark_signals">[docs]</a>    <span class="k">def</span> <span class="nf">mark_signals</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Mark all the signals in ``self.model`` according to whether they</span>
<span class="sd">        represent trainable parameters of the model (parameters that can be</span>
<span class="sd">        optimized by deep learning methods).</span>

<span class="sd">        Trainable parameters include connection weights, ensemble encoders, and</span>
<span class="sd">        neuron biases.  Unless one of those signals is targeted by a Nengo</span>
<span class="sd">        learning rule (otherwise the learning rule update conflicts with the</span>
<span class="sd">        deep learning optimization).</span>

<span class="sd">        Users can manually specify whether signals are trainable or not using</span>
<span class="sd">        the config system (e.g.,</span>
<span class="sd">        ``net.config[nengo.Ensemble].trainable = False``).</span>

<span class="sd">        The trainable attribute will be set to one of three values:</span>

<span class="sd">        - ``True``: Signal is trainable</span>
<span class="sd">        - ``False``: Signal could be trainable, but has been set to non-trainable</span>
<span class="sd">          (e.g., because the user manually configured that object not to be trainable).</span>
<span class="sd">        - ``None``: Signal is never trainable (e.g., simulator state)</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">def</span> <span class="nf">get_trainable</span><span class="p">(</span><span class="n">parent_configs</span><span class="p">,</span> <span class="n">obj</span><span class="p">):</span>
            <span class="sd">&quot;&quot;&quot;Looks up the current value of ``obj.trainable``.&quot;&quot;&quot;</span>

            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">inference_only</span><span class="p">:</span>
                <span class="k">return</span> <span class="kc">False</span>

            <span class="c1"># default to 1 (so that we can distinguish between an object being</span>
            <span class="c1"># set to trainable vs defaulting to trainable)</span>
            <span class="n">trainable</span> <span class="o">=</span> <span class="mi">1</span>

            <span class="c1"># we go from top down (so lower level settings will override)</span>
            <span class="k">for</span> <span class="n">cfg</span> <span class="ow">in</span> <span class="n">parent_configs</span><span class="p">:</span>
                <span class="k">try</span><span class="p">:</span>
                    <span class="n">cfg_trainable</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">cfg</span><span class="p">[</span><span class="n">obj</span><span class="p">],</span> <span class="s2">&quot;trainable&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
                <span class="k">except</span> <span class="n">ConfigError</span><span class="p">:</span>
                    <span class="c1"># object not configured in this network config</span>
                    <span class="n">cfg_trainable</span> <span class="o">=</span> <span class="kc">None</span>

                <span class="k">if</span> <span class="n">cfg_trainable</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">trainable</span> <span class="o">=</span> <span class="n">cfg_trainable</span>

            <span class="k">return</span> <span class="n">trainable</span>

        <span class="k">def</span> <span class="nf">mark_network</span><span class="p">(</span><span class="n">parent_configs</span><span class="p">,</span> <span class="n">net</span><span class="p">):</span>
            <span class="sd">&quot;&quot;&quot;Recursively marks the signals for objects within each subnetwork.&quot;&quot;&quot;</span>

            <span class="n">parent_configs</span> <span class="o">=</span> <span class="n">parent_configs</span> <span class="o">+</span> <span class="p">[</span><span class="n">net</span><span class="o">.</span><span class="n">config</span><span class="p">]</span>

            <span class="k">for</span> <span class="n">subnet</span> <span class="ow">in</span> <span class="n">net</span><span class="o">.</span><span class="n">networks</span><span class="p">:</span>
                <span class="n">mark_network</span><span class="p">(</span><span class="n">parent_configs</span><span class="p">,</span> <span class="n">subnet</span><span class="p">)</span>

            <span class="c1"># encoders and biases are trainable</span>
            <span class="k">for</span> <span class="n">ens</span> <span class="ow">in</span> <span class="n">net</span><span class="o">.</span><span class="n">ensembles</span><span class="p">:</span>
                <span class="n">ens_trainable</span> <span class="o">=</span> <span class="n">get_trainable</span><span class="p">(</span><span class="n">parent_configs</span><span class="p">,</span> <span class="n">ens</span><span class="p">)</span>

                <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">sig</span><span class="p">[</span><span class="n">ens</span><span class="p">][</span><span class="s2">&quot;encoders&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">trainable</span> <span class="o">=</span> <span class="n">ens_trainable</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">sig</span><span class="p">[</span><span class="n">ens</span><span class="p">][</span><span class="s2">&quot;encoders&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">minibatched</span> <span class="o">=</span> <span class="kc">False</span>

                <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">ens</span><span class="o">.</span><span class="n">neuron_type</span><span class="p">,</span> <span class="n">Direct</span><span class="p">):</span>
                    <span class="n">neurons_trainable</span> <span class="o">=</span> <span class="n">get_trainable</span><span class="p">(</span><span class="n">parent_configs</span><span class="p">,</span> <span class="n">ens</span><span class="o">.</span><span class="n">neurons</span><span class="p">)</span>
                    <span class="k">if</span> <span class="n">neurons_trainable</span> <span class="ow">is</span> <span class="mi">1</span><span class="p">:</span>  <span class="c1"># noqa: F632</span>
                        <span class="n">neurons_trainable</span> <span class="o">=</span> <span class="n">ens_trainable</span>

                    <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">sig</span><span class="p">[</span><span class="n">ens</span><span class="o">.</span><span class="n">neurons</span><span class="p">][</span><span class="s2">&quot;bias&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">trainable</span> <span class="o">=</span> <span class="n">neurons_trainable</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">sig</span><span class="p">[</span><span class="n">ens</span><span class="o">.</span><span class="n">neurons</span><span class="p">][</span><span class="s2">&quot;bias&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">minibatched</span> <span class="o">=</span> <span class="kc">False</span>

            <span class="c1"># connection weights are trainable</span>
            <span class="k">for</span> <span class="n">conn</span> <span class="ow">in</span> <span class="n">net</span><span class="o">.</span><span class="n">connections</span><span class="p">:</span>
                <span class="c1"># note: this doesn&#39;t include probe connections, since they</span>
                <span class="c1"># aren&#39;t added to the network</span>
                <span class="k">if</span> <span class="n">compat</span><span class="o">.</span><span class="n">conn_has_weights</span><span class="p">(</span><span class="n">conn</span><span class="p">):</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">sig</span><span class="p">[</span><span class="n">conn</span><span class="p">][</span><span class="s2">&quot;weights&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">trainable</span> <span class="o">=</span> <span class="n">get_trainable</span><span class="p">(</span>
                        <span class="n">parent_configs</span><span class="p">,</span> <span class="n">conn</span>
                    <span class="p">)</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">sig</span><span class="p">[</span><span class="n">conn</span><span class="p">][</span><span class="s2">&quot;weights&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">minibatched</span> <span class="o">=</span> <span class="kc">False</span>

            <span class="c1"># parameters can&#39;t be modified by an online Nengo learning rule</span>
            <span class="c1"># and offline training at the same time. (it is possible in</span>
            <span class="c1"># theory, but it complicates things a lot and is probably not a</span>
            <span class="c1"># common use case). we also make those signals minibatched</span>
            <span class="c1"># (they wouldn&#39;t be normally), because we want to be able to</span>
            <span class="c1"># learn independently in each minibatch</span>
            <span class="k">for</span> <span class="n">conn</span> <span class="ow">in</span> <span class="n">net</span><span class="o">.</span><span class="n">connections</span><span class="p">:</span>
                <span class="n">rule</span> <span class="o">=</span> <span class="n">conn</span><span class="o">.</span><span class="n">learning_rule</span>
                <span class="k">if</span> <span class="n">rule</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">rule</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
                        <span class="n">rule</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">rule</span><span class="o">.</span><span class="n">values</span><span class="p">())</span>
                    <span class="k">elif</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">rule</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
                        <span class="n">rule</span> <span class="o">=</span> <span class="p">[</span><span class="n">rule</span><span class="p">]</span>

                    <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="n">rule</span><span class="p">:</span>
                        <span class="k">if</span> <span class="n">r</span><span class="o">.</span><span class="n">modifies</span> <span class="ow">in</span> <span class="p">(</span><span class="s2">&quot;weights&quot;</span><span class="p">,</span> <span class="s2">&quot;decoders&quot;</span><span class="p">):</span>
                            <span class="n">obj</span> <span class="o">=</span> <span class="n">conn</span>
                            <span class="n">attr</span> <span class="o">=</span> <span class="s2">&quot;weights&quot;</span>
                        <span class="k">elif</span> <span class="n">r</span><span class="o">.</span><span class="n">modifies</span> <span class="o">==</span> <span class="s2">&quot;encoders&quot;</span><span class="p">:</span>
                            <span class="n">obj</span> <span class="o">=</span> <span class="n">conn</span><span class="o">.</span><span class="n">post_obj</span>
                            <span class="n">attr</span> <span class="o">=</span> <span class="s2">&quot;encoders&quot;</span>
                        <span class="k">else</span><span class="p">:</span>
                            <span class="k">raise</span> <span class="ne">NotImplementedError</span>

                        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">sig</span><span class="p">[</span><span class="n">obj</span><span class="p">][</span><span class="n">attr</span><span class="p">]</span><span class="o">.</span><span class="n">trainable</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
                            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                                <span class="s2">&quot;</span><span class="si">%s</span><span class="s2"> has a learning rule and is also set &quot;</span>
                                <span class="s2">&quot;to be trainable; this is likely to &quot;</span>
                                <span class="s2">&quot;produce strange training behaviour.&quot;</span> <span class="o">%</span> <span class="n">obj</span>
                            <span class="p">)</span>
                        <span class="k">else</span><span class="p">:</span>
                            <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">sig</span><span class="p">[</span><span class="n">obj</span><span class="p">][</span><span class="n">attr</span><span class="p">]</span><span class="o">.</span><span class="n">trainable</span> <span class="o">=</span> <span class="kc">False</span>

                        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">sig</span><span class="p">[</span><span class="n">obj</span><span class="p">][</span><span class="n">attr</span><span class="p">]</span><span class="o">.</span><span class="n">minibatched</span> <span class="o">=</span> <span class="kc">True</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">toplevel</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                <span class="s2">&quot;No top-level network in model; assuming no trainable parameters&quot;</span><span class="p">,</span>
                <span class="ne">UserWarning</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">mark_network</span><span class="p">([],</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">toplevel</span><span class="p">)</span>

            <span class="c1"># the connections to connection probes are not trainable, but</span>
            <span class="c1"># also not minibatched</span>
            <span class="n">probe_seeds</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">seeds</span><span class="p">[</span><span class="n">p</span><span class="p">]</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">probes</span><span class="p">]</span>
            <span class="k">for</span> <span class="n">obj</span><span class="p">,</span> <span class="n">seed</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">seeds</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="n">Connection</span><span class="p">)</span> <span class="ow">and</span> <span class="n">seed</span> <span class="ow">in</span> <span class="n">probe_seeds</span><span class="p">:</span>
                    <span class="k">if</span> <span class="n">compat</span><span class="o">.</span><span class="n">conn_has_weights</span><span class="p">(</span><span class="n">obj</span><span class="p">):</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">sig</span><span class="p">[</span><span class="n">obj</span><span class="p">][</span><span class="s2">&quot;weights&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">trainable</span> <span class="o">=</span> <span class="kc">None</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">sig</span><span class="p">[</span><span class="n">obj</span><span class="p">][</span><span class="s2">&quot;weights&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">minibatched</span> <span class="o">=</span> <span class="kc">False</span>

        <span class="c1"># time/step are not minibatched and not trainable</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">step</span><span class="o">.</span><span class="n">trainable</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">step</span><span class="o">.</span><span class="n">minibatched</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">time</span><span class="o">.</span><span class="n">trainable</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">time</span><span class="o">.</span><span class="n">minibatched</span> <span class="o">=</span> <span class="kc">False</span>

        <span class="c1"># fill in defaults for all other signals</span>
        <span class="c1"># signals are not trainable by default, and views take on the</span>
        <span class="c1"># properties of their bases</span>
        <span class="k">for</span> <span class="n">op</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">operators</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">sig</span> <span class="ow">in</span> <span class="n">op</span><span class="o">.</span><span class="n">all_signals</span><span class="p">:</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">sig</span><span class="o">.</span><span class="n">base</span><span class="p">,</span> <span class="s2">&quot;trainable&quot;</span><span class="p">):</span>
                    <span class="n">sig</span><span class="o">.</span><span class="n">base</span><span class="o">.</span><span class="n">trainable</span> <span class="o">=</span> <span class="kc">None</span>

                <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">sig</span><span class="o">.</span><span class="n">base</span><span class="p">,</span> <span class="s2">&quot;minibatched&quot;</span><span class="p">):</span>
                    <span class="n">sig</span><span class="o">.</span><span class="n">base</span><span class="o">.</span><span class="n">minibatched</span> <span class="o">=</span> <span class="ow">not</span> <span class="n">sig</span><span class="o">.</span><span class="n">base</span><span class="o">.</span><span class="n">trainable</span>

                <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">sig</span><span class="p">,</span> <span class="s2">&quot;trainable&quot;</span><span class="p">):</span>
                    <span class="n">sig</span><span class="o">.</span><span class="n">trainable</span> <span class="o">=</span> <span class="n">sig</span><span class="o">.</span><span class="n">base</span><span class="o">.</span><span class="n">trainable</span>

                <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">sig</span><span class="p">,</span> <span class="s2">&quot;minibatched&quot;</span><span class="p">):</span>
                    <span class="n">sig</span><span class="o">.</span><span class="n">minibatched</span> <span class="o">=</span> <span class="n">sig</span><span class="o">.</span><span class="n">base</span><span class="o">.</span><span class="n">minibatched</span></div>

<div class="viewcode-block" id="TensorGraph.create_signals"><a class="viewcode-back" href="../../reference.html#nengo_dl.tensor_graph.TensorGraph.create_signals">[docs]</a>    <span class="nd">@trackable</span><span class="o">.</span><span class="n">no_automatic_dependency_tracking</span>
    <span class="k">def</span> <span class="nf">create_signals</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sigs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Groups signal data together into larger arrays, and represent each</span>
<span class="sd">        individual signal as a slice into that array.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        sigs : list of `~nengo.builder.Signal`</span>
<span class="sd">            Base signals arranged into the order in which they should reside in</span>
<span class="sd">            memory (e.g., output from `.graph_optimizer.order_signals`)</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">base_arrays</span> <span class="o">=</span> <span class="n">OrderedDict</span><span class="p">(</span>
            <span class="p">[</span>
                <span class="p">(</span><span class="s2">&quot;trainable&quot;</span><span class="p">,</span> <span class="n">OrderedDict</span><span class="p">()),</span>
                <span class="p">(</span><span class="s2">&quot;non_trainable&quot;</span><span class="p">,</span> <span class="n">OrderedDict</span><span class="p">()),</span>
                <span class="p">(</span><span class="s2">&quot;state&quot;</span><span class="p">,</span> <span class="n">OrderedDict</span><span class="p">()),</span>
            <span class="p">]</span>
        <span class="p">)</span>
        <span class="n">curr_keys</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="n">sig_idxs</span> <span class="o">=</span> <span class="p">{</span><span class="n">s</span><span class="p">:</span> <span class="n">i</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">s</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">sigs</span><span class="p">)}</span>

        <span class="c1"># find the non-overlapping partitions of the signals</span>
        <span class="n">breaks</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">diff</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">ops</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">plan</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">ops</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">Reset</span><span class="p">):</span>
                <span class="c1"># don&#39;t include Resets, otherwise the big reset block</span>
                <span class="c1"># overrides most of the partitioning</span>
                <span class="n">partition_sigs</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">partition_sigs</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">ops</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">all_signals</span><span class="p">))</span>

            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">partition_sigs</span><span class="p">:</span>
                <span class="n">op_sigs</span> <span class="o">=</span> <span class="p">[</span><span class="n">op</span><span class="o">.</span><span class="n">all_signals</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">base</span> <span class="k">for</span> <span class="n">op</span> <span class="ow">in</span> <span class="n">ops</span><span class="p">]</span>
                <span class="n">idxs</span> <span class="o">=</span> <span class="p">[</span><span class="n">sig_idxs</span><span class="p">[</span><span class="n">s</span><span class="p">]</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">op_sigs</span><span class="p">]</span>
                <span class="n">diff</span><span class="p">[</span><span class="n">op_sigs</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">argmin</span><span class="p">(</span><span class="n">idxs</span><span class="p">)]]</span> <span class="o">+=</span> <span class="mi">1</span>
                <span class="n">diff</span><span class="p">[</span><span class="n">op_sigs</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">idxs</span><span class="p">)]]</span> <span class="o">-=</span> <span class="mi">1</span>

        <span class="c1"># find the partition points in signal list</span>
        <span class="nb">open</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">s</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">sigs</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">diff</span><span class="p">:</span>
                <span class="nb">open</span> <span class="o">+=</span> <span class="n">diff</span><span class="p">[</span><span class="n">s</span><span class="p">]</span>

            <span class="k">if</span> <span class="nb">open</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">breaks</span> <span class="o">+=</span> <span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span>

        <span class="n">logging</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot;partitions&quot;</span><span class="p">)</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span>
            <span class="s2">&quot;</span><span class="se">\n</span><span class="si">%s</span><span class="s2">&quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="s2">&quot;|&quot;</span> <span class="k">if</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">breaks</span> <span class="k">else</span> <span class="s2">&quot; &quot;</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">sigs</span><span class="p">)))</span>
        <span class="p">)</span>

        <span class="c1"># find all the signals that have a set operation associated with them</span>

        <span class="k">def</span> <span class="nf">special_set</span><span class="p">(</span><span class="n">s</span><span class="p">,</span> <span class="n">op</span><span class="p">):</span>
            <span class="k">return</span> <span class="p">(</span>
                <span class="c1"># we don&#39;t include Lowpass ops, because for efficiency reasons in the</span>
                <span class="c1"># nengo-dl Lowpass implementation we reuse the output signal (which is</span>
                <span class="c1"># set) as the state signal (so we need to include that signal in the</span>
                <span class="c1"># state)</span>
                <span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">op</span><span class="p">,</span> <span class="n">SimProcess</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">op</span><span class="o">.</span><span class="n">process</span><span class="p">,</span> <span class="n">Lowpass</span><span class="p">))</span>
                <span class="c1"># nengo marks the time step as a set, but really it&#39;s an inc (since</span>
                <span class="c1"># it&#39;s incrementing the simulation step)</span>
                <span class="ow">or</span> <span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">op</span><span class="p">,</span> <span class="n">TimeUpdate</span><span class="p">)</span> <span class="ow">and</span> <span class="n">s</span> <span class="ow">is</span> <span class="n">op</span><span class="o">.</span><span class="n">step</span><span class="p">)</span>
                <span class="c1"># nengo marks neuron state as a set, but really it&#39;s more like an</span>
                <span class="c1"># inc/update (since the neuron calculation may depend on the state)</span>
                <span class="ow">or</span> <span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">op</span><span class="p">,</span> <span class="n">SimNeurons</span><span class="p">)</span> <span class="ow">and</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">op</span><span class="o">.</span><span class="n">states</span><span class="p">)</span>
            <span class="p">)</span>

        <span class="n">set_sigs</span> <span class="o">=</span> <span class="p">{</span>
            <span class="n">s</span><span class="o">.</span><span class="n">base</span>
            <span class="k">for</span> <span class="n">ops</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">plan</span>
            <span class="k">for</span> <span class="n">op</span> <span class="ow">in</span> <span class="n">ops</span>
            <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">op</span><span class="o">.</span><span class="n">sets</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">special_set</span><span class="p">(</span><span class="n">s</span><span class="p">,</span> <span class="n">op</span><span class="p">)</span>
        <span class="p">}</span>

        <span class="c1"># create all the base signals</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">sig</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">sigs</span><span class="p">):</span>
            <span class="k">assert</span> <span class="n">sig</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">signals</span>
            <span class="k">assert</span> <span class="ow">not</span> <span class="n">sig</span><span class="o">.</span><span class="n">is_view</span>

            <span class="k">if</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">breaks</span><span class="p">:</span>
                <span class="c1"># start a new array for all current bases</span>
                <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">curr_keys</span><span class="p">:</span>
                    <span class="n">curr_keys</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="nb">object</span><span class="p">()</span>

            <span class="c1"># convert to appropriate dtype</span>
            <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">issubdtype</span><span class="p">(</span><span class="n">sig</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">floating</span><span class="p">):</span>
                <span class="n">dtype</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dtype</span>
            <span class="k">elif</span> <span class="n">np</span><span class="o">.</span><span class="n">issubdtype</span><span class="p">(</span><span class="n">sig</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">integer</span><span class="p">):</span>
                <span class="n">dtype</span> <span class="o">=</span> <span class="s2">&quot;int32&quot;</span>
            <span class="k">elif</span> <span class="n">np</span><span class="o">.</span><span class="n">issubdtype</span><span class="p">(</span><span class="n">sig</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">bool_</span><span class="p">):</span>
                <span class="n">dtype</span> <span class="o">=</span> <span class="s2">&quot;bool&quot;</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">&quot;Unsupported signal dtype&quot;</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">sig</span><span class="o">.</span><span class="n">sparse</span><span class="p">:</span>
                <span class="c1"># for sparse tensors, what we care about is the shape of the</span>
                <span class="c1"># underlying data, not the full matrix</span>
                <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="n">sig</span><span class="o">.</span><span class="n">initial_value</span><span class="o">.</span><span class="n">size</span><span class="p">,)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># resize scalars to length 1 vectors</span>
                <span class="n">shape</span> <span class="o">=</span> <span class="n">sig</span><span class="o">.</span><span class="n">shape</span> <span class="k">if</span> <span class="n">sig</span><span class="o">.</span><span class="n">shape</span> <span class="o">!=</span> <span class="p">()</span> <span class="k">else</span> <span class="p">(</span><span class="mi">1</span><span class="p">,)</span>

            <span class="c1"># parameters of signal that affect the base array</span>
            <span class="n">array_params</span> <span class="o">=</span> <span class="p">(</span><span class="n">dtype</span><span class="p">,</span> <span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:],</span> <span class="n">sig</span><span class="o">.</span><span class="n">trainable</span><span class="p">,</span> <span class="n">sig</span><span class="o">.</span><span class="n">minibatched</span><span class="p">)</span>

            <span class="c1"># key used to map signals to base arrays</span>
            <span class="k">if</span> <span class="n">array_params</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">curr_keys</span><span class="p">:</span>
                <span class="n">curr_keys</span><span class="p">[</span><span class="n">array_params</span><span class="p">]</span> <span class="o">=</span> <span class="nb">object</span><span class="p">()</span>
            <span class="n">key</span> <span class="o">=</span> <span class="n">curr_keys</span><span class="p">[</span><span class="n">array_params</span><span class="p">]</span>

            <span class="k">if</span> <span class="n">sig</span> <span class="ow">in</span> <span class="n">set_sigs</span><span class="p">:</span>
                <span class="c1"># signals with a set operation associated with them don&#39;t need an</span>
                <span class="c1"># initial value (since the value will just be immediately overridden</span>
                <span class="c1"># by the set operation)</span>
                <span class="n">initial_value</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">initial_value</span> <span class="o">=</span> <span class="n">sig</span><span class="o">.</span><span class="n">initial_value</span>
                <span class="k">if</span> <span class="n">sig</span><span class="o">.</span><span class="n">sparse</span><span class="p">:</span>
                    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">initial_value</span><span class="p">,</span> <span class="n">SparseMatrix</span><span class="p">):</span>
                        <span class="n">initial_value</span> <span class="o">=</span> <span class="n">initial_value</span><span class="o">.</span><span class="n">data</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">initial_value</span> <span class="o">=</span> <span class="n">initial_value</span><span class="o">.</span><span class="n">tocoo</span><span class="p">()</span><span class="o">.</span><span class="n">data</span>

            <span class="k">if</span> <span class="n">sig</span><span class="o">.</span><span class="n">minibatched</span><span class="p">:</span>
                <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">minibatch_size</span><span class="p">,)</span> <span class="o">+</span> <span class="n">shape</span>

            <span class="k">if</span> <span class="n">sig</span><span class="o">.</span><span class="n">trainable</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">sig_type</span> <span class="o">=</span> <span class="s2">&quot;state&quot;</span>
            <span class="k">elif</span> <span class="n">sig</span><span class="o">.</span><span class="n">trainable</span><span class="p">:</span>
                <span class="n">sig_type</span> <span class="o">=</span> <span class="s2">&quot;trainable&quot;</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">sig_type</span> <span class="o">=</span> <span class="s2">&quot;non_trainable&quot;</span>

            <span class="k">if</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">base_arrays</span><span class="p">[</span><span class="n">sig_type</span><span class="p">]:</span>
                <span class="n">base_arrays</span><span class="p">[</span><span class="n">sig_type</span><span class="p">][</span><span class="n">key</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">initial_value</span><span class="p">)</span>
                <span class="n">base_arrays</span><span class="p">[</span><span class="n">sig_type</span><span class="p">][</span><span class="n">key</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">base_arrays</span><span class="p">[</span><span class="n">sig_type</span><span class="p">][</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span>
                    <span class="p">[</span><span class="n">initial_value</span><span class="p">],</span>
                    <span class="p">[</span><span class="n">shape</span><span class="p">],</span>
                    <span class="n">dtype</span><span class="p">,</span>
                    <span class="n">sig</span><span class="o">.</span><span class="n">minibatched</span><span class="p">,</span>
                <span class="p">]</span>

            <span class="n">n</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="n">sig</span><span class="o">.</span><span class="n">minibatched</span><span class="p">]</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">base_arrays</span><span class="p">[</span><span class="n">sig_type</span><span class="p">][</span><span class="n">key</span><span class="p">][</span><span class="mi">1</span><span class="p">])</span>
            <span class="n">slices</span> <span class="o">=</span> <span class="p">[(</span><span class="n">n</span> <span class="o">-</span> <span class="n">shape</span><span class="p">[</span><span class="n">sig</span><span class="o">.</span><span class="n">minibatched</span><span class="p">],</span> <span class="n">n</span><span class="p">)]</span>

            <span class="n">tensor_sig</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">signals</span><span class="o">.</span><span class="n">get_tensor_signal</span><span class="p">(</span>
                <span class="n">slices</span><span class="p">,</span>
                <span class="n">key</span><span class="p">,</span>
                <span class="n">dtype</span><span class="p">,</span>
                <span class="n">shape</span><span class="p">[</span><span class="n">sig</span><span class="o">.</span><span class="n">minibatched</span> <span class="p">:],</span>
                <span class="n">sig</span><span class="o">.</span><span class="n">minibatched</span><span class="p">,</span>
                <span class="n">label</span><span class="o">=</span><span class="n">sig</span><span class="o">.</span><span class="n">name</span><span class="p">,</span>
                <span class="n">signal</span><span class="o">=</span><span class="n">sig</span><span class="p">,</span>
            <span class="p">)</span>

            <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot;created base signal&quot;</span><span class="p">)</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="n">sig</span><span class="p">)</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="n">tensor_sig</span><span class="p">)</span>

        <span class="c1"># add any signal views to the sig_map</span>
        <span class="n">all_views</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">sig</span>
            <span class="k">for</span> <span class="n">ops</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">plan</span>
            <span class="k">for</span> <span class="n">op</span> <span class="ow">in</span> <span class="n">ops</span>
            <span class="k">for</span> <span class="n">sig</span> <span class="ow">in</span> <span class="n">op</span><span class="o">.</span><span class="n">all_signals</span>
            <span class="k">if</span> <span class="n">sig</span><span class="o">.</span><span class="n">is_view</span>
        <span class="p">]</span>
        <span class="k">for</span> <span class="n">sig</span> <span class="ow">in</span> <span class="n">all_views</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">sig</span><span class="o">.</span><span class="n">size</span> <span class="o">==</span> <span class="n">sig</span><span class="o">.</span><span class="n">base</span><span class="o">.</span><span class="n">size</span><span class="p">:</span>
                <span class="c1"># reshape view</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">signals</span><span class="p">[</span><span class="n">sig</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">signals</span><span class="p">[</span><span class="n">sig</span><span class="o">.</span><span class="n">base</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">sig</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">sig</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span> <span class="o">!=</span> <span class="n">sig</span><span class="o">.</span><span class="n">base</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:]:</span>
                    <span class="c1"># TODO: support this?</span>
                    <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">&quot;Slicing on axes &gt; 0 is not supported&quot;</span><span class="p">)</span>

                <span class="c1"># slice view</span>
                <span class="k">assert</span> <span class="n">np</span><span class="o">.</span><span class="n">all</span><span class="p">([</span><span class="n">x</span> <span class="o">==</span> <span class="mi">1</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">sig</span><span class="o">.</span><span class="n">elemstrides</span><span class="p">[</span><span class="mi">1</span><span class="p">:]])</span>

                <span class="n">start</span> <span class="o">=</span> <span class="n">sig</span><span class="o">.</span><span class="n">elemoffset</span>
                <span class="n">stride</span> <span class="o">=</span> <span class="n">sig</span><span class="o">.</span><span class="n">elemstrides</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
                <span class="n">stop</span> <span class="o">=</span> <span class="n">start</span> <span class="o">+</span> <span class="n">sig</span><span class="o">.</span><span class="n">size</span> <span class="o">*</span> <span class="n">stride</span>
                <span class="k">if</span> <span class="n">stop</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="n">stop</span> <span class="o">=</span> <span class="kc">None</span>

                <span class="bp">self</span><span class="o">.</span><span class="n">signals</span><span class="p">[</span><span class="n">sig</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">signals</span><span class="p">[</span><span class="n">sig</span><span class="o">.</span><span class="n">base</span><span class="p">][</span><span class="nb">slice</span><span class="p">(</span><span class="n">start</span><span class="p">,</span> <span class="n">stop</span><span class="p">,</span> <span class="n">stride</span><span class="p">)]</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">base_arrays_init</span> <span class="o">=</span> <span class="n">base_arrays</span></div></div>
</pre></div>

            </div>
          </div>
        </div>
      </div>

    </div>
  </div>
</div><footer class="text-light footer-main gradient-bottom">
  <p class="small text-center mb-0">
    <a class="no-hover-line" href="https://appliedbrainresearch.com">
      <img
        src="https://appliedbrainresearch.com/img/logo-blue-notext.svg"
        height="48"
      />
    </a>
    <a href="https://www.nengo.ai/">What is Nengo?</a>
    <a href="https://www.nengo.ai/examples/">Examples</a>
    <a href="https://www.nengo.ai/documentation/">Documentation</a>
    <a href="https://www.nengo.ai/getting-started/">Getting started</a>
    <a href="https://www.nengo.ai/privacy/">Privacy</a>
  </p>
  <p class="small text-center mb-0">&copy; Applied Brain Research</p>
</footer>
<script>
  function switchVersion(select) {
    var option = select.selectedOptions[0];
    if (option.hasAttribute("value")) {
      window.location = option.value;
    }
  }
</script>

<script>
  var elements = document.querySelectorAll('.sidenav');
  Stickyfill.add(elements);
</script>
<script>
  ScrollReveal().reveal(".fade-in", {
      scale: 0.85,
      duration: 1000,
      delay: 250,
      interval: 50
  });
</script>
<script>
  $('a.toggle-sidenav').on('click', function(e) {
    e.preventDefault();
    if ( $(this).hasClass('active') ) {
      $(this).removeClass('active');
      $('.sidenav').removeClass('open');
    } else {
      $(this).addClass('active');
      $('.sidenav').addClass('open');
    }
  });
</script>
<script>
  var lists = document.querySelectorAll('.toctree ul');
  lists.forEach((ul) => {
      ul.classList.add("nav");
  });
  var links = document.querySelectorAll('.toctree a');
  links.forEach((link) => {
      link.classList.add("nav-link");
  });
  $("body").scrollspy({target: ".sidenav"});
</script>
  </body>
</html>