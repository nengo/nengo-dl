
<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta charset="utf-8" />
    <title>Inserting a TensorFlow/Keras network into a Nengo model &#8212; NengoDL 2.2.2 docs</title>
    <link rel="stylesheet" href="../_static/basic.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
<link href="https://fonts.googleapis.com/css?family=IBM+Plex+Sans:400,400i,600|Rajdhani:700&display=swap" rel="stylesheet">
<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.8.2/css/all.css" integrity="sha384-oS3vJWv+0UjzBfQzYUhtDYW+Pj2yciDJxpsK1OYPAYjqT085Qq/1cq5FLXAZQ7Ay" crossorigin="anonymous">
<link rel="stylesheet" href="https://www.nengo.ai/css/bootstrap.css" type="text/css">
<style>
  body .title-bar,
  body .documentation-source h1:after {
    background-color: #ff6600;
  }
</style>

<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-GT8XEDLTMJ"></script>
<script>
 window.dataLayer = window.dataLayer || [];
 function gtag(){dataLayer.push(arguments);}
 gtag('js', new Date());
 gtag('config', 'G-GT8XEDLTMJ');
</script>
<!-- End Google tag (gtag.js) -->

<!-- Matomo -->
<script>
 var _paq = window._paq = window._paq || [];
 _paq.push(["setDocumentTitle", document.domain + "/" + document.title]);
 _paq.push(["setCookieDomain", "*.appliedbrainresearch.com"]);
 _paq.push(["setDomains", ["*.appliedbrainresearch.com","*.edge.nengo.ai","*.forum.nengo.ai","*.labs.nengo.ai","*.nengo.ai"]]);
 _paq.push(["enableCrossDomainLinking"]);
 _paq.push(["setDoNotTrack", true]);
 _paq.push(['trackPageView']);
 _paq.push(['enableLinkTracking']);
 (function() {
   var u="https://appliedbrainresearch.matomo.cloud/";
   _paq.push(['setTrackerUrl', u+'matomo.php']);
   _paq.push(['setSiteId', '3']);
   var d=document, g=d.createElement('script'), s=d.getElementsByTagName('script')[0];
   g.async=true; g.src='//cdn.matomo.cloud/appliedbrainresearch.matomo.cloud/matomo.js'; s.parentNode.insertBefore(g,s);
 })();
</script>
<!-- End Matomo Code -->
<script src="https://code.jquery.com/jquery-3.3.1.min.js" integrity="sha256-FgpCb/KJQlLNfOu91ta32o/NMZxltwRo8QtmkMRdAu8=" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.3/umd/popper.min.js" integrity="sha384-ZMP7rVo3mIykV+2+9J3UJ46jBk0WLaUAdn689aCwoqbBJiSnjAK/l8WvCWPIPm49" crossorigin="anonymous"></script>
<script src="https://unpkg.com/scrollreveal"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/stickyfill/2.1.0/stickyfill.min.js"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.1.1/js/bootstrap.min.js" integrity="sha384-smHYKdLADwkXOn1EmN1qk/HfnUcbVRZyYmZ4qpPea6sjB/pTJ0euyQp0Mk8ck+5T" crossorigin="anonymous"></script>
<!-- From basic/layout.html -->
<script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
  
  
<script type="text/javascript" src="../_static/underscore.js"></script>
  
  
<script type="text/javascript" src="../_static/doctools.js"></script>
  
  
<script type="text/javascript" src="../_static/language_data.js"></script>
  
  
<script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
  
  
<script async="async" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
  
  
<script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true, "ignoreClass": "document", "processClass": "math|output_area"}})</script>
  
    <link rel="shortcut icon" href="../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Optimizing spiking neural networks" href="spiking-mnist.html" />
    <link rel="prev" title="Coming from TensorFlow to NengoDL" href="from-tensorflow.html" />
<meta name="viewport" content="width=device-width, initial-scale=1, viewport-fit=cover">

  </head><body class="bg-dark">

<header class="fixed-top header-top shadow-sm">
  <nav class="navbar navbar-expand-md navbar-light bg-white">
    <a class="navbar-brand" href="https://www.nengo.ai/">
      <img
        src="https://www.nengo.ai/design/_images/general-full-light.svg"
        alt="Nengo"
        class="logo"
      />
    </a>
    <button
      class="navbar-toggler"
      type="button"
      data-toggle="collapse"
      data-target="#navbar-collapse"
      aria-controls="navbar-collapse"
      aria-expanded="false"
      aria-label="Toggle navigation"
    >
      <span class="navbar-toggler-icon"></span>
    </button>
    <div class="collapse navbar-collapse" id="navbar-collapse">
      <ul class="navbar-nav ml-auto">
        <li class="nav-item">
          <a class="nav-link" href="https://www.nengo.ai/">What is Nengo?</a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="https://www.nengo.ai/examples/">Examples</a>
        </li>
        <li class="nav-item dropdown active">
          <a
            class="nav-link dropdown-toggle"
            id="navbar-dropdown-docs"
            data-toggle="dropdown"
            aria-haspopup="true"
            aria-expanded="false"
            href="#"
            >Documentation</a
          >
          <div
            class="dropdown-menu shadow-lg border-0"
            aria-labelledby="navbar-dropdown-docs"
          >
            
            <a class="dropdown-item" href="https://www.nengo.ai/nengo/">Nengo Core</a>
            <a class="dropdown-item" href="https://github.com/nengo/nengo-gui/">Nengo GUI</a>
            <a class="dropdown-item" href="https://www.nengo.ai/nengo-dl/">Nengo DL</a>
            <div class="dropdown-divider"></div>
            <a class="dropdown-item" href="https://www.nengo.ai/nengo-spa/">Nengo SPA</a>
            <a class="dropdown-item" href="https://www.nengo.ai/nengo-extras/">Nengo Extras</a>
            <a class="dropdown-item" href="https://arvoelke.github.io/nengolib-docs/">Nengolib</a>
            <div class="dropdown-divider"></div>
            <a class="dropdown-item" href="https://www.nengo.ai/nengo-fpga/">Nengo FPGA</a>
            <a class="dropdown-item" href="https://www.nengo.ai/nengo-loihi/">Nengo Loihi</a>
            <a class="dropdown-item" href="https://github.com/nengo/nengo-ocl">Nengo OpenCL</a>
            <a class="dropdown-item" href="https://github.com/project-rig/nengo_spinnaker">Nengo SpiNNaker</a>
            <a class="dropdown-item" href="https://github.com/nengo/nengo-mpi">Nengo MPI</a>
            <div class="dropdown-divider"></div>
            <a class="dropdown-item" href="https://www.nengo.ai/documentation/"
              >All documentation</a
            >
          </div>
        </li>
        <li class="nav-item dropdown">
          <a
            class="nav-link dropdown-toggle"
            id="navbar-dropdown-community"
            data-toggle="dropdown"
            aria-haspopup="true"
            aria-expanded="false"
            href="#"
            >Community</a
          >
          <div
            class="dropdown-menu shadow-lg border-0"
            aria-labelledby="navbar-dropdown-community"
          >
            <a class="dropdown-item" href="https://forum.nengo.ai">Forum</a>
            <div class="dropdown-divider"></div>
            <a class="dropdown-item" href="https://www.nengo.ai/people/"
              >People</a
            >
            <a class="dropdown-item" href="https://www.nengo.ai/summer-school/"
              >Summer school</a
            >
            <a class="dropdown-item" href="https://www.nengo.ai/contributing/"
              >Contributing</a
            >
            <a class="dropdown-item" href="https://www.nengo.ai/publications/"
              >Publications</a
            >
            <a class="dropdown-item" href="https://www.nengo.ai/videos/"
              >Videos</a
            >
            <a class="dropdown-item" href="https://www.nengo.ai/conduct/"
              >Code of conduct</a
            >
            <a class="dropdown-item" href="https://www.nengo.ai/caa/">CAA</a>
          </div>
        </li>
        <li class="nav-item">
          <a
            class="nav-link btn btn-success btn-sm text-white"
            href="https://www.nengo.ai/getting-started/"
            >Getting started</a
          >
        </li>
      </ul>
    </div>
  </nav>
</header>
<div class="main-content gradient-top">
  <div class="container-fluid">
    <div class="row"><a class="toggle-sidenav d-block d-md-none" href="#"
  ><i class="icon-close fa fa-fw fa-arrow-left"></i
  ><i class="icon-open fa fa-fw fa-arrow-right"></i
></a>
<div role="complementary" class="sidenav col-4 col-xl-3 p-0 border-right">
  <h3 class="pt-5 px-5">
    <a href="../index.html">
      <img
        class="img-fluid documentation-image"
        src="https://www.nengo.ai/design/_images/nengo-dl-full-light.svg"
        alt="NengoDL"
      />
    </a>
  </h3>
  
  <form class="px-5 pb-5 mb-0 mt-3 border-bottom">
    <div class="form-group">
      <label class="text-gray">Version:</label>
      <select class="custom-select" onchange="switchVersion(this);">
        
        
        <option value="../../examples/tensorflow-models.html">latest</option>
        
        
          
        <option selected>v2.2.2</option>
          
        
          
        <option value="../../v2.2.1/examples/tensorflow-models.html">
          v2.2.1
        </option>
          
        
          
        <option value="../../v2.2.0/examples/tensorflow-models.html">
          v2.2.0
        </option>
          
        
          
        <option value="../../v2.1.1/examples/tensorflow-models.html">
          v2.1.1
        </option>
          
        
          
        <option value="../../v2.1.0/examples/tensorflow-models.html">
          v2.1.0
        </option>
          
        
          
        <option value="../../v2.0.0/examples/tensorflow-models.html">
          v2.0.0
        </option>
          
        
          
        <option value="../../v1.2.1/examples/tensorflow-models.html">
          v1.2.1
        </option>
          
        
          
        <option value="../../v1.2.0/examples/tensorflow-models.html">
          v1.2.0
        </option>
          
        
          
        <option value="../../v1.1.0/examples/tensorflow-models.html">
          v1.1.0
        </option>
          
        
          
        <option value="../../v1.0.0/examples/tensorflow-models.html">
          v1.0.0
        </option>
          
        
          
        <option value="../../v0.6.2/examples/tensorflow-models.html">
          v0.6.2
        </option>
          
        
          
        <option value="../../v0.6.1/examples/tensorflow-models.html">
          v0.6.1
        </option>
          
        
          
        <option value="../../v0.6.0/examples/tensorflow-models.html">
          v0.6.0
        </option>
          
        
          
        <option value="../../v0.5.2/examples/tensorflow-models.html">
          v0.5.2
        </option>
          
        
          
        <option value="../../v0.5.1/examples/tensorflow-models.html">
          v0.5.1
        </option>
          
        
          
        <option value="../../v0.5.0/examples/tensorflow-models.html">
          v0.5.0
        </option>
          
        
          
        <option value="../../v0.4.0/examples/tensorflow-models.html">
          v0.4.0
        </option>
          
        
          
        <option value="../../v0.3.1/examples/tensorflow-models.html">
          v0.3.1
        </option>
          
        
          
        <option value="../../v0.3.0/examples/tensorflow-models.html">
          v0.3.0
        </option>
          
        
          
        <option value="../../v0.2.0/examples/tensorflow-models.html">
          v0.2.0
        </option>
          
        
      </select>
    </div>
  </form>
  
  <div class="p-5 toctree">
    <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../introduction.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../user-guide.html">User guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../reference.html">API reference</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../examples.html">Examples</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="from-nengo.html">Coming from Nengo to NengoDL</a></li>
<li class="toctree-l2"><a class="reference internal" href="from-tensorflow.html">Coming from TensorFlow to NengoDL</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">Inserting a TensorFlow/Keras network into a Nengo model</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#Inserting-a-Keras-network">Inserting a Keras network</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Inserting-a-TensorFlow-Slim-network">Inserting a TensorFlow-Slim network</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="spiking-mnist.html">Optimizing spiking neural networks</a></li>
<li class="toctree-l2"><a class="reference internal" href="spa-retrieval.html">Optimizing a cognitive model</a></li>
<li class="toctree-l2"><a class="reference internal" href="spa-memory.html">Optimizing a cognitive model with temporal dynamics</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../resources.html">Additional resources</a></li>
<li class="toctree-l1"><a class="reference internal" href="../project.html">Project information</a></li>
</ul>

  </div>
<form class="p-5 my-0 border-top" action="../search.html" method="get">
  <div class="form-group form-group-single">
    <input type="text" name="q" class="form-control" placeholder="Search" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
    <button type="submit" class="btn btn-link">
      <img src="https://www.nengo.ai/img/icon-search.svg" alt="Go" />
    </button>
  </div>
</form></div>
      

      <div class="col-12 col-md-8 col-xl-9">
        <div class="container">
          <div class="row">
            <div class="col-10 offset-1 pb-5 documentation-source" role="main">
              
  
<style>
/* CSS for nbsphinx extension */

/* remove conflicting styling from Sphinx themes */
div.nbinput.container,
div.nbinput.container div.prompt,
div.nbinput.container div.input_area,
div.nbinput.container div[class*=highlight],
div.nbinput.container div[class*=highlight] pre,
div.nboutput.container,
div.nboutput.container div.prompt,
div.nboutput.container div.output_area,
div.nboutput.container div[class*=highlight],
div.nboutput.container div[class*=highlight] pre {
    background: none;
    border: none;
    padding: 0 0;
    margin: 0;
    box-shadow: none;
}

/* avoid gaps between output lines */
div.nboutput.container div[class*=highlight] pre {
    line-height: normal;
}

/* input/output containers */
div.nbinput.container,
div.nboutput.container {
    display: -webkit-flex;
    display: flex;
    align-items: flex-start;
    margin: 0;
    width: 100%;
}
@media (max-width: 540px) {
    div.nbinput.container,
    div.nboutput.container {
        flex-direction: column;
    }
}

/* input container */
div.nbinput.container {
    padding-top: 5px;
}

/* last container */
div.nblast.container {
    padding-bottom: 5px;
}

/* input prompt */
div.nbinput.container div.prompt pre {
    color: #307FC1;
}

/* output prompt */
div.nboutput.container div.prompt pre {
    color: #BF5B3D;
}

/* all prompts */
div.nbinput.container div.prompt,
div.nboutput.container div.prompt {
    min-width: 7ex;
    padding-top: 0.4em;
    padding-right: 0.4em;
    text-align: right;
    flex: 0;
}
@media (max-width: 540px) {
    div.nbinput.container div.prompt,
    div.nboutput.container div.prompt {
        text-align: left;
        padding: 0.4em;
    }
    div.nboutput.container div.prompt.empty {
        padding: 0;
    }
}

/* disable scrollbars on prompts */
div.nbinput.container div.prompt pre,
div.nboutput.container div.prompt pre {
    overflow: hidden;
}

/* input/output area */
div.nbinput.container div.input_area,
div.nboutput.container div.output_area {
    padding: 0.4em;
    -webkit-flex: 1;
    flex: 1;
    overflow: auto;
}
@media (max-width: 540px) {
    div.nbinput.container div.input_area,
    div.nboutput.container div.output_area {
        width: 100%;
    }
}

/* input area */
div.nbinput.container div.input_area {
    border: 1px solid #e0e0e0;
    border-radius: 2px;
    background: #f5f5f5;
}

/* override MathJax center alignment in output cells */
div.nboutput.container div[class*=MathJax] {
    text-align: left !important;
}

/* override sphinx.ext.imgmath center alignment in output cells */
div.nboutput.container div.math p {
    text-align: left;
}

/* standard error */
div.nboutput.container div.output_area.stderr {
    background: #fdd;
}

/* ANSI colors */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-default-inverse-fg { color: #FFFFFF; }
.ansi-default-inverse-bg { background-color: #000000; }

.ansi-bold { font-weight: bold; }
.ansi-underline { text-decoration: underline; }

/* Some additional styling taken form the Jupyter notebook CSS */
div.rendered_html table {
  border: none;
  border-collapse: collapse;
  border-spacing: 0;
  color: black;
  font-size: 12px;
  table-layout: fixed;
}
div.rendered_html thead {
  border-bottom: 1px solid black;
  vertical-align: bottom;
}
div.rendered_html tr,
div.rendered_html th,
div.rendered_html td {
  text-align: right;
  vertical-align: middle;
  padding: 0.5em 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}
div.rendered_html th {
  font-weight: bold;
}
div.rendered_html tbody tr:nth-child(odd) {
  background: #f5f5f5;
}
div.rendered_html tbody tr:hover {
  background: rgba(66, 165, 245, 0.2);
}
</style>
<div class="section" id="Inserting-a-TensorFlow/Keras-network-into-a-Nengo-model">
<h1>Inserting a TensorFlow/Keras network into a Nengo model<a class="headerlink" href="#Inserting-a-TensorFlow/Keras-network-into-a-Nengo-model" title="Permalink to this headline">¶</a></h1>
<p>Often we may want to define one part of our model in Nengo, and another part in TensorFlow. For example, suppose we are building a biological reinforcement learning model, but we’d like the inputs to our model to be natural images rather than artificial vectors. We could load a vision network from TensorFlow, insert it into our model using NengoDL, and then build the rest of our model using normal Nengo syntax.</p>
<p>NengoDL supports this through the <a class="reference external" href="https://www.nengo.ai/nengo-dl/tensor_node.html">TensorNode</a> class. This allows us to write code directly in TensorFlow, and then insert it easily into Nengo. In this example we will demonstrate this in two different ways: first using a network defined using <a class="reference external" href="https://keras.io/">Keras</a>, and second using a prebuilt vision network from the <a class="reference external" href="https://github.com/tensorflow/models">tensorflow/models</a> repository.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[1]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="o">%</span><span class="k">matplotlib</span> inline

<span class="kn">import</span> <span class="nn">sys</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">from</span> <span class="nn">urllib.request</span> <span class="k">import</span> <span class="n">urlopen</span>
<span class="kn">import</span> <span class="nn">io</span>
<span class="kn">import</span> <span class="nn">shutil</span>
<span class="kn">import</span> <span class="nn">stat</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">PIL</span> <span class="k">import</span> <span class="n">Image</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">from</span> <span class="nn">tensorflow</span> <span class="k">import</span> <span class="n">keras</span>
<span class="kn">import</span> <span class="nn">tensorflow.contrib.slim</span> <span class="k">as</span> <span class="nn">slim</span><span class="p">;</span>

<span class="kn">import</span> <span class="nn">nengo</span>
<span class="kn">import</span> <span class="nn">nengo_dl</span>

<span class="c1"># keras uses the global random seeds, so we set those here to</span>
<span class="c1"># ensure the example is reproducible</span>
<span class="n">seed</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
<span class="n">tf</span><span class="o">.</span><span class="n">set_random_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p><strong>Introduction to TensorNodes</strong></p>
<p><code class="docutils literal notranslate"><span class="pre">nengo_dl.TensorNode</span></code> works very similarly to <code class="docutils literal notranslate"><span class="pre">nengo.Node</span></code>, except instead of using the node to insert Python code into our model we will use it to insert TensorFlow code.</p>
<p>The first thing we need to do is define our TensorNode output. This is a function that accepts the current simulation time (and, optionally, a batch of vectors) as input, and produces a batch of vectors as output. All of these variables will be represented as <code class="docutils literal notranslate"><span class="pre">tf.Tensor</span></code> objects, and the internal operations of the TensorNode will be implemented with TensorFlow operations. For example, we could use a TensorNode to output a <code class="docutils literal notranslate"><span class="pre">sin</span></code> function:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="k">with</span> <span class="n">nengo</span><span class="o">.</span><span class="n">Network</span><span class="p">()</span> <span class="k">as</span> <span class="n">net</span><span class="p">:</span>
    <span class="k">def</span> <span class="nf">sin_func</span><span class="p">(</span><span class="n">t</span><span class="p">):</span>
        <span class="c1"># compute sin wave (based on simulation time)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">t</span><span class="p">)</span>

        <span class="c1"># convert output to the expected batched vector shape</span>
        <span class="c1"># (with batch size of 1 and vector dimensionality 1)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>

        <span class="k">return</span> <span class="n">out</span>

    <span class="n">node</span> <span class="o">=</span> <span class="n">nengo_dl</span><span class="o">.</span><span class="n">TensorNode</span><span class="p">(</span><span class="n">sin_func</span><span class="p">)</span>
    <span class="n">p</span> <span class="o">=</span> <span class="n">nengo</span><span class="o">.</span><span class="n">Probe</span><span class="p">(</span><span class="n">node</span><span class="p">)</span>

<span class="k">with</span> <span class="n">nengo_dl</span><span class="o">.</span><span class="n">Simulator</span><span class="p">(</span><span class="n">net</span><span class="p">)</span> <span class="k">as</span> <span class="n">sim</span><span class="p">:</span>
    <span class="n">sim</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="mf">5.0</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">sim</span><span class="o">.</span><span class="n">trange</span><span class="p">(),</span> <span class="n">sim</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">p</span><span class="p">]);</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Build finished in 0:00:00
Optimization finished in 0:00:00
Construction finished in 0:00:00
|#                            Simulating                              | 0:00:00
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
/home/travis/build/nengo/nengo-dl/nengo_dl/simulator.py:102: UserWarning: No GPU support detected. It is recommended that you install tensorflow-gpu (`pip install tensorflow-gpu`).
  &#34;No GPU support detected. It is recommended that you &#34;
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Simulation finished in 0:00:00
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/examples_tensorflow-models_3_3.png" src="../_images/examples_tensorflow-models_3_3.png" />
</div>
</div>
<p>However, outputting a <code class="docutils literal notranslate"><span class="pre">sin</span></code> function is something we could do more easily with a regular <code class="docutils literal notranslate"><span class="pre">nengo.Node</span></code>. The main use case for <code class="docutils literal notranslate"><span class="pre">nengo_dl.TensorNode</span></code> is to allow us to write more complex TensorFlow code and insert it into a NengoDL model. We will see two different examples of this below.</p>
<div class="section" id="Inserting-a-Keras-network">
<h2>Inserting a Keras network<a class="headerlink" href="#Inserting-a-Keras-network" title="Permalink to this headline">¶</a></h2>
<p><a class="reference external" href="https://keras.io/">Keras</a> is a popular software package for building and training deep learning style networks. It provides a higher-level syntactical wrapper around TensorFlow (or other packages, such as Theano). And because it is defining a TensorFlow network under the hood, we can define a network using Keras and then insert it into NengoDL using a TensorNode.</p>
<p>This example assumes familiarity with the Keras API. Specifically it is based on the <a class="reference external" href="https://www.tensorflow.org/tutorials/keras/basic_classification">introduction in the Tensorflow documentation</a>, so if you are not yet familiar with Keras, you may find it helpful to read those tutorials first.</p>
<p>For this example we’ll train a neural network to classify the fashion MNIST dataset. This dataset contains images of clothing, and the goal of the network is to identify what type of clothing it is (e.g. t-shirt, trouser, coat, etc.).</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[3]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">fashion_mnist</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">fashion_mnist</span>

<span class="p">(</span><span class="n">train_images</span><span class="p">,</span> <span class="n">train_labels</span><span class="p">),</span> <span class="p">(</span><span class="n">test_images</span><span class="p">,</span> <span class="n">test_labels</span><span class="p">)</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">fashion_mnist</span><span class="o">.</span><span class="n">load_data</span><span class="p">())</span>
<span class="n">num_classes</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">test_labels</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

<span class="c1"># normalize images so values are between 0 and 1</span>
<span class="n">train_images</span> <span class="o">=</span> <span class="n">train_images</span> <span class="o">/</span> <span class="mf">255.0</span>
<span class="n">test_images</span> <span class="o">=</span> <span class="n">test_images</span> <span class="o">/</span> <span class="mf">255.0</span>

<span class="n">class_names</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;T-shirt/top&#39;</span><span class="p">,</span> <span class="s1">&#39;Trouser&#39;</span><span class="p">,</span> <span class="s1">&#39;Pullover&#39;</span><span class="p">,</span> <span class="s1">&#39;Dress&#39;</span><span class="p">,</span> <span class="s1">&#39;Coat&#39;</span><span class="p">,</span>
               <span class="s1">&#39;Sandal&#39;</span><span class="p">,</span> <span class="s1">&#39;Shirt&#39;</span><span class="p">,</span> <span class="s1">&#39;Sneaker&#39;</span><span class="p">,</span> <span class="s1">&#39;Bag&#39;</span><span class="p">,</span> <span class="s1">&#39;Ankle boot&#39;</span><span class="p">]</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">3</span><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">test_images</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;gray&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s2">&quot;off&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="n">class_names</span><span class="p">[</span><span class="n">test_labels</span><span class="p">[</span><span class="n">i</span><span class="p">]]);</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz
32768/29515 [=================================] - 0s 0us/step
Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz
26427392/26421880 [==============================] - 0s 0us/step
Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz
8192/5148 [===============================================] - 0s 0us/step
Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz
4423680/4422102 [==============================] - 0s 0us/step
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/examples_tensorflow-models_6_1.png" src="../_images/examples_tensorflow-models_6_1.png" />
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/examples_tensorflow-models_6_2.png" src="../_images/examples_tensorflow-models_6_2.png" />
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/examples_tensorflow-models_6_3.png" src="../_images/examples_tensorflow-models_6_3.png" />
</div>
</div>
<p>Next we build and train a simple neural network, using Keras. In this case we’re building a simple two layer, densely connected network.</p>
<p>Note that alternatively we could define the network in Keras and then train it in NengoDL (using the <code class="docutils literal notranslate"><span class="pre">Simulator.train</span></code> function). But for this example we’ll show how to do everything in Keras.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">image_shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">Sequential</span><span class="p">([</span>
    <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Flatten</span><span class="p">(</span><span class="n">input_shape</span><span class="o">=</span><span class="n">image_shape</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;flatten&#39;</span><span class="p">),</span>
    <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">relu</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;hidden&#39;</span><span class="p">),</span>
    <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">softmax</span><span class="p">,</span>
                       <span class="n">name</span><span class="o">=</span><span class="s1">&#39;softmax&#39;</span><span class="p">)</span>
<span class="p">])</span>

<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">AdamOptimizer</span><span class="p">(),</span>
              <span class="n">loss</span><span class="o">=</span><span class="s1">&#39;sparse_categorical_crossentropy&#39;</span><span class="p">,</span>
              <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_images</span><span class="p">,</span> <span class="n">train_labels</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">5</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Epoch 1/5
60000/60000 [==============================] - 4s 71us/step - loss: 0.5042 - acc: 0.8221
Epoch 2/5
60000/60000 [==============================] - 4s 69us/step - loss: 0.3774 - acc: 0.8626
Epoch 3/5
60000/60000 [==============================] - 4s 70us/step - loss: 0.3377 - acc: 0.8766
Epoch 4/5
60000/60000 [==============================] - 4s 73us/step - loss: 0.3131 - acc: 0.8855
Epoch 5/5
60000/60000 [==============================] - 4s 74us/step - loss: 0.2969 - acc: 0.8900
</pre></div></div>
</div>
<p>We’ll save the trained weights, so that we can load them later within our TensorNode.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">model_weights</span> <span class="o">=</span> <span class="s2">&quot;keras_weights.h5&quot;</span>
<span class="n">model</span><span class="o">.</span><span class="n">save_weights</span><span class="p">(</span><span class="n">model_weights</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>Now we’re ready to create our TensorNode. Instead of using a function for our TensorNode output, in this case we’ll use a callable class so that we can include <code class="docutils literal notranslate"><span class="pre">pre_build</span></code> and <code class="docutils literal notranslate"><span class="pre">post_build</span></code> functions. These allow us to execute code at different stages during the build process, which can be necessary for more complicated TensorNodes.</p>
<p>NengoDL will call the <code class="docutils literal notranslate"><span class="pre">pre_build</span></code> function once when the model is first constructed, so we can use this function to perform any initial setup required for our node. In this case we’ll use the <code class="docutils literal notranslate"><span class="pre">pre_build</span></code> function to call the Keras <code class="docutils literal notranslate"><span class="pre">clone_model</span></code> function. This effectively reruns the Keras model definition from above, but because we’re calling it in the <code class="docutils literal notranslate"><span class="pre">pre_build</span></code> stage it will be naturally integrated into the NengoDL model that is being built.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">__call__</span></code> function is where we do the main job of constructing the TensorFlow elements that will implement our node. It will take TensorFlow Tensors as input and produce a <code class="docutils literal notranslate"><span class="pre">tf.Tensor</span></code> as output, as with the <code class="docutils literal notranslate"><span class="pre">tf.sin</span></code> example above. In this case we apply the Keras model to the TensorNode inputs (stored in the <code class="docutils literal notranslate"><span class="pre">x</span></code> variable). This adds the TensorFlow elements that implement that Keras model into the simulation graph.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">post_build</span></code> function is called after the rest of the graph has been constructed (and whenever the simulation is reset). We’ll use this to load the pretrained weights into the model. We have to do this at the <code class="docutils literal notranslate"><span class="pre">post_build</span></code> stage because we need access to the initialized simulation session, which has the variables we want to load.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="k">class</span> <span class="nc">KerasNode</span><span class="p">:</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">keras_model</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">keras_model</span>

    <span class="k">def</span> <span class="nf">pre_build</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">clone_model</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="c1"># reshape the flattened images into their 2D shape</span>
        <span class="c1"># (plus the batch dimension)</span>
        <span class="n">images</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,)</span> <span class="o">+</span> <span class="n">image_shape</span><span class="p">)</span>
        <span class="c1"># build the rest of the model into the graph</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">call</span><span class="p">(</span><span class="n">images</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">post_build</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sess</span><span class="p">,</span> <span class="n">rng</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">load_weights</span><span class="p">(</span><span class="n">model_weights</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>Notice that in the <code class="docutils literal notranslate"><span class="pre">__call__</span></code> method we pass our input tensor to the <code class="docutils literal notranslate"><span class="pre">Model.call</span></code> method, not <code class="docutils literal notranslate"><span class="pre">Model.predict</span></code> (which you might be more familiar with if you frequently work with Keras). We do this because we want the model to return a <code class="docutils literal notranslate"><span class="pre">Tensor</span></code> object (i.e., an abstract representation of the computations that will be performed in the network), rather than actually simulating the network and computing predictions (as the <code class="docutils literal notranslate"><span class="pre">predict</span></code> function does). This way the returned <code class="docutils literal notranslate"><span class="pre">Tensor</span></code> can
become part of the TensorFlow graph that NengoDL is constructing.</p>
<p>To better understand the difference between <code class="docutils literal notranslate"><span class="pre">model.call(images)</span></code> and <code class="docutils literal notranslate"><span class="pre">model.predict(images)</span></code>, we can look at the code below:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[7]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">():</span>
    <span class="n">model</span><span class="o">.</span><span class="n">load_weights</span><span class="p">(</span><span class="n">model_weights</span><span class="p">)</span>

    <span class="c1"># model.call takes a Tensor as input and returns a Tensor</span>
    <span class="n">out1</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">call</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">test_images</span><span class="p">[:</span><span class="mi">10</span><span class="p">],</span>
                                           <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Type of &#39;out1&#39;:&quot;</span><span class="p">,</span> <span class="nb">type</span><span class="p">(</span><span class="n">out1</span><span class="p">))</span>

    <span class="c1"># model.predict takes a numpy array as input and returns</span>
    <span class="c1"># a numpy array</span>
    <span class="n">out2</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test_images</span><span class="p">[:</span><span class="mi">10</span><span class="p">])</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Type of &#39;out2&#39;:&quot;</span><span class="p">,</span> <span class="nb">type</span><span class="p">(</span><span class="n">out2</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Type of &#39;out1&#39;: &lt;class &#39;tensorflow.python.framework.ops.Tensor&#39;&gt;
Type of &#39;out2&#39;: &lt;class &#39;numpy.ndarray&#39;&gt;
</pre></div></div>
</div>
<p>Now that we have our <code class="docutils literal notranslate"><span class="pre">KerasNode</span></code> class, we can use it to insert our Keras model into a Nengo network via a <code class="docutils literal notranslate"><span class="pre">TensorNode</span></code>.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[8]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">net_input_shape</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">image_shape</span><span class="p">)</span>  <span class="c1"># because input will be a vector</span>

<span class="k">with</span> <span class="n">nengo</span><span class="o">.</span><span class="n">Network</span><span class="p">()</span> <span class="k">as</span> <span class="n">net</span><span class="p">:</span>
    <span class="c1"># create a normal input node to feed in our test image.</span>
    <span class="c1"># the `np.ones` array is a placeholder, these</span>
    <span class="c1"># values will be replaced with the Fashion MNIST images</span>
    <span class="c1"># when we run the Simulator.</span>
    <span class="n">input_node</span> <span class="o">=</span> <span class="n">nengo</span><span class="o">.</span><span class="n">Node</span><span class="p">(</span><span class="n">output</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">net_input_shape</span><span class="p">,)))</span>

    <span class="c1"># create a TensorNode containing the KerasNode we defined</span>
    <span class="c1"># above, passing it the Keras model we created.</span>
    <span class="c1"># we also need to specify size_in (the dimensionality of</span>
    <span class="c1"># our input vectors, the flattened images) and size_out (the number</span>
    <span class="c1"># of classification classes output by the keras network)</span>
    <span class="n">keras_node</span> <span class="o">=</span> <span class="n">nengo_dl</span><span class="o">.</span><span class="n">TensorNode</span><span class="p">(</span>
        <span class="n">KerasNode</span><span class="p">(</span><span class="n">model</span><span class="p">),</span>
        <span class="n">size_in</span><span class="o">=</span><span class="n">net_input_shape</span><span class="p">,</span>
        <span class="n">size_out</span><span class="o">=</span><span class="n">num_classes</span><span class="p">)</span>

    <span class="c1"># connect up our input to our keras node</span>
    <span class="n">nengo</span><span class="o">.</span><span class="n">Connection</span><span class="p">(</span><span class="n">input_node</span><span class="p">,</span> <span class="n">keras_node</span><span class="p">,</span> <span class="n">synapse</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>

    <span class="c1"># add a probes to collect output of keras node</span>
    <span class="n">keras_p</span> <span class="o">=</span> <span class="n">nengo</span><span class="o">.</span><span class="n">Probe</span><span class="p">(</span><span class="n">keras_node</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>At this point we could add any other Nengo components we like to the network, and connect them up to the Keras node (for example, if we wanted to take the classified image labels and use them as input to a spiking neural model). But to keep things simple, we’ll stop here.</p>
<p>We’ll grab some random images from our test set, in order to demonstrate that we have successfully loaded the trained Keras network.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[9]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">minibatch_size</span> <span class="o">=</span> <span class="mi">20</span>

<span class="c1"># pick some random images from test set</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="n">test_inds</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="n">low</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">high</span><span class="o">=</span><span class="n">test_images</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
                              <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">minibatch_size</span><span class="p">,))</span>
<span class="n">test_inputs</span> <span class="o">=</span> <span class="n">test_images</span><span class="p">[</span><span class="n">test_inds</span><span class="p">]</span>

<span class="c1"># flatten images so we can pass them as vectors to the input node</span>
<span class="n">test_inputs</span> <span class="o">=</span> <span class="n">test_inputs</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">net_input_shape</span><span class="p">))</span>

<span class="c1"># unlike in Keras, NengoDl simulations always run over time.</span>
<span class="c1"># so we need to add the time dimension to our data (even though</span>
<span class="c1"># in this case we&#39;ll just run for a single timestep).</span>
<span class="n">test_inputs</span> <span class="o">=</span> <span class="n">test_inputs</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">,</span> <span class="p">:]</span>
</pre></div>
</div>
</div>
<p>Now we are ready to run the simulation.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[10]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="k">with</span> <span class="n">nengo_dl</span><span class="o">.</span><span class="n">Simulator</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">minibatch_size</span><span class="o">=</span><span class="n">minibatch_size</span><span class="p">)</span> <span class="k">as</span> <span class="n">sim</span><span class="p">:</span>
    <span class="n">sim</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="p">{</span><span class="n">input_node</span><span class="p">:</span> <span class="n">test_inputs</span><span class="p">})</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Build finished in 0:00:00
Optimization finished in 0:00:00
Construction finished in 0:00:00
</pre></div></div>
</div>
<p>We can see the results of the simulation using the <code class="docutils literal notranslate"><span class="pre">Probe</span></code> that we added to capture the output from the <code class="docutils literal notranslate"><span class="pre">TensorNode</span></code>. We use it as a key into the <code class="docutils literal notranslate"><span class="pre">data</span></code> attribute of the Simulator.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[11]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">tensornode_output</span> <span class="o">=</span> <span class="n">sim</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">keras_p</span><span class="p">]</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">5</span><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">test_images</span><span class="p">[</span><span class="n">test_inds</span><span class="p">][</span><span class="n">i</span><span class="p">],</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;gray&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s2">&quot;off&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">%s</span><span class="s2"> (</span><span class="si">%s</span><span class="s2">)&quot;</span> <span class="o">%</span> <span class="p">(</span>
        <span class="n">class_names</span><span class="p">[</span><span class="n">test_labels</span><span class="p">[</span><span class="n">test_inds</span><span class="p">][</span><span class="n">i</span><span class="p">]],</span>
        <span class="n">class_names</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">tensornode_output</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="mi">0</span><span class="p">])]));</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/examples_tensorflow-models_22_0.png" src="../_images/examples_tensorflow-models_22_0.png" />
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/examples_tensorflow-models_22_1.png" src="../_images/examples_tensorflow-models_22_1.png" />
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/examples_tensorflow-models_22_2.png" src="../_images/examples_tensorflow-models_22_2.png" />
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/examples_tensorflow-models_22_3.png" src="../_images/examples_tensorflow-models_22_3.png" />
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/examples_tensorflow-models_22_4.png" src="../_images/examples_tensorflow-models_22_4.png" />
</div>
</div>
<p>We can see that the network is doing a pretty good job of classifying the test images (the title shows the correct output, with the networks’ output shown in brackets).</p>
</div>
<div class="section" id="Inserting-a-TensorFlow-Slim-network">
<h2>Inserting a TensorFlow-Slim network<a class="headerlink" href="#Inserting-a-TensorFlow-Slim-network" title="Permalink to this headline">¶</a></h2>
<p>In this example we’ll show how to insert a more complicated network into NengoDL. Specifically, we will use an Inception-v1 network to classify Imagenet images.</p>
<p>TensorFlow provides a number of pre-defined models in the <a class="reference external" href="https://github.com/tensorflow/models">tensorflow/models</a> repository. These are not included when you install TensorFlow, so we need to separately clone that repository and import the components we need.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[12]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="o">!</span>git clone -q https://github.com/tensorflow/models
<span class="n">sys</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="s2">&quot;.&quot;</span><span class="p">,</span> <span class="s2">&quot;models&quot;</span><span class="p">,</span> <span class="s2">&quot;research&quot;</span><span class="p">,</span> <span class="s2">&quot;slim&quot;</span><span class="p">))</span>
<span class="kn">from</span> <span class="nn">datasets</span> <span class="k">import</span> <span class="n">dataset_utils</span><span class="p">,</span> <span class="n">imagenet</span>
<span class="kn">from</span> <span class="nn">nets</span> <span class="k">import</span> <span class="n">inception</span>
<span class="kn">from</span> <span class="nn">preprocessing</span> <span class="k">import</span> <span class="n">inception_preprocessing</span>
</pre></div>
</div>
</div>
<p>As before, we will use a <a class="reference external" href="https://www.nengo.ai/nengo-dl/tensor_node.html">TensorNode</a> to insert our TensorFlow code into Nengo. In this case we’re going to build a TensorNode that encapsulates the <a class="reference external" href="https://arxiv.org/abs/1409.4842">Inception-v1</a> network. However, this same approach could be used for any TensorFlow network.</p>
<p>This Inception-v1 network has been trained to perform image classification on the Imagenet dataset; if we show it an image, it will output a set of probabilities for the 1000 different object types it is trained to classify. So if we show it an image of a tree it should output a high probability for the “tree” class and a low probability for the “car” class.</p>
<p>The first thing we’ll do is download a sample image to test our network with (you could use a different image if you want).</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[13]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">image_string</span> <span class="o">=</span> <span class="n">urlopen</span><span class="p">(</span>
    <span class="s2">&quot;https://upload.wikimedia.org/wikipedia/commons/7/70/&quot;</span>
    <span class="s2">&quot;EnglishCockerSpaniel_simon.jpg&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>
<span class="n">image</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">io</span><span class="o">.</span><span class="n">BytesIO</span><span class="p">(</span><span class="n">image_string</span><span class="p">)))</span>
<span class="n">image_shape</span> <span class="o">=</span> <span class="n">image</span><span class="o">.</span><span class="n">shape</span>

<span class="c1"># display the test image</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;off&#39;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/examples_tensorflow-models_27_0.png" src="../_images/examples_tensorflow-models_27_0.png" />
</div>
</div>
<p>Now we’re ready to create our TensorNode. As in the previous example, we will use a callable class so that we can use <code class="docutils literal notranslate"><span class="pre">pre_build</span></code> and <code class="docutils literal notranslate"><span class="pre">post_build</span></code> methods to help construct the model.</p>
<p>In this case we’ll use the <code class="docutils literal notranslate"><span class="pre">pre_build</span></code> function to download pre-trained weights for the Inception network. Again, if we wanted we could train the network from scratch using the <code class="docutils literal notranslate"><span class="pre">sim.train</span></code> function, but that would take a long time.</p>
<p>In the <code class="docutils literal notranslate"><span class="pre">__call__</span></code> function we apply some pre-processing to transform the TensorNode inputs (stored in the <code class="docutils literal notranslate"><span class="pre">x</span></code> variable) into the form expected by the inception network. Then we call the <code class="docutils literal notranslate"><span class="pre">inception_v1</span></code> method, which will construct all the TensorFlow elements required to implement that network, and return the resulting output Tensor.</p>
<p>We’ll use the <code class="docutils literal notranslate"><span class="pre">post_build</span></code> function to load the pretrained weights into the model, as in the previous example.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[14]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">checkpoints_dir</span> <span class="o">=</span> <span class="s1">&#39;/tmp/checkpoints&#39;</span>


<span class="k">class</span> <span class="nc">InceptionNode</span><span class="p">:</span>
    <span class="k">def</span> <span class="nf">pre_build</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">):</span>
        <span class="c1"># the shape of the inputs to the inception network</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">input_shape</span> <span class="o">=</span> <span class="n">inception</span><span class="o">.</span><span class="n">inception_v1</span><span class="o">.</span><span class="n">default_image_size</span>

        <span class="c1"># download model checkpoint file</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">tf</span><span class="o">.</span><span class="n">gfile</span><span class="o">.</span><span class="n">Exists</span><span class="p">(</span><span class="n">checkpoints_dir</span><span class="p">):</span>
            <span class="n">tf</span><span class="o">.</span><span class="n">gfile</span><span class="o">.</span><span class="n">MakeDirs</span><span class="p">(</span><span class="n">checkpoints_dir</span><span class="p">)</span>
        <span class="n">dataset_utils</span><span class="o">.</span><span class="n">download_and_uncompress_tarball</span><span class="p">(</span>
            <span class="s2">&quot;http://download.tensorflow.org/models/&quot;</span>
            <span class="s2">&quot;inception_v1_2016_08_28.tar.gz&quot;</span><span class="p">,</span>
            <span class="n">checkpoints_dir</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="c1"># convert our input vector to the shape/dtype of the input image</span>
        <span class="n">img</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">uint8</span><span class="p">),</span> <span class="n">image_shape</span><span class="p">)</span>

        <span class="c1"># reshape the image to the shape expected by the</span>
        <span class="c1"># inception network</span>
        <span class="n">img</span> <span class="o">=</span> <span class="n">inception_preprocessing</span><span class="o">.</span><span class="n">preprocess_image</span><span class="p">(</span>
            <span class="n">img</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_shape</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_shape</span><span class="p">,</span> <span class="n">is_training</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="n">img</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>

        <span class="c1"># create inception network</span>
        <span class="k">with</span> <span class="n">slim</span><span class="o">.</span><span class="n">arg_scope</span><span class="p">(</span><span class="n">inception</span><span class="o">.</span><span class="n">inception_v1_arg_scope</span><span class="p">()):</span>
            <span class="n">logits</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">inception</span><span class="o">.</span><span class="n">inception_v1</span><span class="p">(</span><span class="n">img</span><span class="p">,</span>
                                               <span class="n">num_classes</span><span class="o">=</span><span class="mi">1001</span><span class="p">,</span>
                                               <span class="n">is_training</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

        <span class="c1"># return our classification probabilites</span>
        <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">logits</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">post_build</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sess</span><span class="p">,</span> <span class="n">rng</span><span class="p">):</span>
        <span class="c1"># load checkpoint file into model</span>
        <span class="n">init_fn</span> <span class="o">=</span> <span class="n">slim</span><span class="o">.</span><span class="n">assign_from_checkpoint_fn</span><span class="p">(</span>
            <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">checkpoints_dir</span><span class="p">,</span> <span class="s1">&#39;inception_v1.ckpt&#39;</span><span class="p">),</span>
            <span class="n">slim</span><span class="o">.</span><span class="n">get_model_variables</span><span class="p">(</span><span class="s1">&#39;InceptionV1&#39;</span><span class="p">))</span>

        <span class="n">init_fn</span><span class="p">(</span><span class="n">sess</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>Next we create a Nengo Network containing our TensorNode.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[15]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="k">with</span> <span class="n">nengo</span><span class="o">.</span><span class="n">Network</span><span class="p">()</span> <span class="k">as</span> <span class="n">net</span><span class="p">:</span>
    <span class="c1"># create a normal input node to feed in our test image</span>
    <span class="n">input_node</span> <span class="o">=</span> <span class="n">nengo</span><span class="o">.</span><span class="n">Node</span><span class="p">(</span><span class="n">output</span><span class="o">=</span><span class="n">image</span><span class="o">.</span><span class="n">flatten</span><span class="p">())</span>

    <span class="c1"># create our TensorNode containing the InceptionNode() we defined</span>
    <span class="c1"># above.  we also need to specify size_in (the dimensionality of</span>
    <span class="c1"># our input vectors, the flattened images) and size_out (the number</span>
    <span class="c1"># of classification classes output by the inception network)</span>
    <span class="n">incep_node</span> <span class="o">=</span> <span class="n">nengo_dl</span><span class="o">.</span><span class="n">TensorNode</span><span class="p">(</span>
        <span class="n">InceptionNode</span><span class="p">(),</span> <span class="n">size_in</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">image_shape</span><span class="p">),</span> <span class="n">size_out</span><span class="o">=</span><span class="mi">1001</span><span class="p">)</span>

    <span class="c1"># connect up our input to our inception node</span>
    <span class="n">nengo</span><span class="o">.</span><span class="n">Connection</span><span class="p">(</span><span class="n">input_node</span><span class="p">,</span> <span class="n">incep_node</span><span class="p">,</span> <span class="n">synapse</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>

    <span class="c1"># add some probes to collect data</span>
    <span class="n">input_p</span> <span class="o">=</span> <span class="n">nengo</span><span class="o">.</span><span class="n">Probe</span><span class="p">(</span><span class="n">input_node</span><span class="p">)</span>
    <span class="n">incep_p</span> <span class="o">=</span> <span class="n">nengo</span><span class="o">.</span><span class="n">Probe</span><span class="p">(</span><span class="n">incep_node</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>As with the previous example, at this point we could connect up the output of <code class="docutils literal notranslate"><span class="pre">incep_node</span></code> to any other part of our network, if this was part of a larger model. But to keep this example simple we’ll stop here.</p>
<p>All that’s left is to run our network, using our example image as input, and check the output.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[16]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># run the network for one timestep</span>
<span class="k">with</span> <span class="n">nengo_dl</span><span class="o">.</span><span class="n">Simulator</span><span class="p">(</span><span class="n">net</span><span class="p">)</span> <span class="k">as</span> <span class="n">sim</span><span class="p">:</span>
    <span class="n">sim</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

<span class="c1"># sort the output labels based on the classification probabilites</span>
<span class="c1"># output from the network</span>
<span class="n">probabilities</span> <span class="o">=</span> <span class="n">sim</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">incep_p</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
<span class="n">sorted_inds</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">sorted</span><span class="p">(</span><span class="nb">enumerate</span><span class="p">(</span><span class="o">-</span><span class="n">probabilities</span><span class="p">),</span>
                                    <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">])]</span>

<span class="c1"># print top 5 classes</span>
<span class="n">names</span> <span class="o">=</span> <span class="n">imagenet</span><span class="o">.</span><span class="n">create_readable_names_for_imagenet_labels</span><span class="p">()</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">5</span><span class="p">):</span>
    <span class="n">index</span> <span class="o">=</span> <span class="n">sorted_inds</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Probability </span><span class="si">%0.2f%%</span><span class="s1"> =&gt; [</span><span class="si">%s</span><span class="s1">]&#39;</span> <span class="o">%</span> <span class="p">(</span>
        <span class="n">probabilities</span><span class="p">[</span><span class="n">index</span><span class="p">]</span> <span class="o">*</span> <span class="mi">100</span><span class="p">,</span> <span class="n">names</span><span class="p">[</span><span class="n">index</span><span class="p">]))</span>

<span class="c1"># display the test image</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">sim</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">input_p</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">image_shape</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">uint8</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;off&#39;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Build finished in 0:00:00
Optimization finished in 0:00:00
&gt;&gt; Downloading inception_v1_2016_08_28.tar.gz 100.0%
Successfully downloaded inception_v1_2016_08_28.tar.gz 24642554 bytes.
Construction finished in 0:00:08
Probability 44.95% =&gt; [cocker spaniel, English cocker spaniel, cocker]
Probability 22.56% =&gt; [Sussex spaniel]
Probability 10.18% =&gt; [Irish setter, red setter]
Probability 4.48% =&gt; [Welsh springer spaniel]
Probability 3.42% =&gt; [clumber, clumber spaniel]
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/examples_tensorflow-models_33_1.png" src="../_images/examples_tensorflow-models_33_1.png" />
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[17]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># delete the models repo we cloned</span>
<span class="k">def</span> <span class="nf">onerror</span><span class="p">(</span><span class="n">func</span><span class="p">,</span> <span class="n">path</span><span class="p">,</span> <span class="n">exc_info</span><span class="p">):</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">access</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="n">os</span><span class="o">.</span><span class="n">W_OK</span><span class="p">):</span>
        <span class="n">os</span><span class="o">.</span><span class="n">chmod</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="n">stat</span><span class="o">.</span><span class="n">S_IWUSR</span><span class="p">)</span>
        <span class="n">func</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="n">exc_info</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>


<span class="n">shutil</span><span class="o">.</span><span class="n">rmtree</span><span class="p">(</span><span class="s2">&quot;models&quot;</span><span class="p">,</span> <span class="n">onerror</span><span class="o">=</span><span class="n">onerror</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>


            </div>
          </div>
        </div>
      </div>

    </div>
  </div>
</div><footer class="text-light footer-main gradient-bottom">
  <p class="small text-center mb-0">
    <a class="no-hover-line" href="https://appliedbrainresearch.com">
      <img
        src="https://appliedbrainresearch.com/img/logo-blue-notext.svg"
        height="48"
      />
    </a>
    <a href="https://www.nengo.ai/">What is Nengo?</a>
    <a href="https://www.nengo.ai/examples/">Examples</a>
    <a href="https://www.nengo.ai/documentation/">Documentation</a>
    <a href="https://www.nengo.ai/getting-started/">Getting started</a>
    <a href="https://www.nengo.ai/privacy/">Privacy</a>
  </p>
  <p class="small text-center mb-0">&copy; Applied Brain Research</p>
</footer>
<script>
  function switchVersion(select) {
    var option = select.selectedOptions[0];
    if (option.hasAttribute("value")) {
      window.location = option.value;
    }
  }
</script>

<script>
  var elements = document.querySelectorAll('.sidenav');
  Stickyfill.add(elements);
</script>
<script>
  ScrollReveal().reveal(".fade-in", {
      scale: 0.85,
      duration: 1000,
      delay: 250,
      interval: 50
  });
</script>
<script>
  $('a.toggle-sidenav').on('click', function(e) {
    e.preventDefault();
    if ( $(this).hasClass('active') ) {
      $(this).removeClass('active');
      $('.sidenav').removeClass('open');
    } else {
      $(this).addClass('active');
      $('.sidenav').addClass('open');
    }
  });
</script>
<script>
  var lists = document.querySelectorAll('.toctree ul');
  lists.forEach((ul) => {
      ul.classList.add("nav");
  });
  var links = document.querySelectorAll('.toctree a');
  links.forEach((link) => {
      link.classList.add("nav-link");
  });
  $("body").scrollspy({target: ".sidenav"});
</script>
  </body>
</html>